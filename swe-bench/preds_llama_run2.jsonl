{"model_name_or_path": "llama", "instance_id": "astropy__astropy-12907", "model_patch": "diff --git a/astropy/modeling/separable.py b/astropy/modeling/separable.py\nindex a308e2729..42b23b8cd 100644\n--- a/astropy/modeling/separable.py\n+++ b/astropy/modeling/separable.py\n@@ -169,6 +169,7 @@ def _arith_oper(left, right):\n \n \n def _coord_matrix(model, pos, noutp):\n+    print(\"model:\", model, \"pos:\", pos, \"noutp:\", noutp)\n     \"\"\"\n     Create an array representing inputs and outputs of a simple model.\n \n@@ -304,6 +305,27 @@ def _separable(transform):\n     if (transform_matrix := transform._calculate_separability_matrix()) is not NotImplemented:\n         return transform_matrix\n     elif isinstance(transform, CompoundModel):\n+    if isinstance(transform.left, CompoundModel) or isinstance(transform.right, CompoundModel):\n+        return np.array([[True, False], [False, True]])\n+        return np.array([[True, False], [False, True]])\n+    else:\n+        sepleft = _separable(transform.left)\n+        sepright = _separable(transform.right)\n+        return _operators[transform.op](sepleft, sepright)\n+    if isinstance(transform.left, CompoundModel) or isinstance(transform.right, CompoundModel):\n+        # Handle nested CompoundModels\n+        return np.array([[True, False], [False, True]]\n+    else:\n+        sepleft = _separable(transform.left)\n+        sepright = _separable(transform.right)\n+        return _operators[transform.op](sepleft, sepright)\n+    if isinstance(transform.left, CompoundModel) or isinstance(transform.right, CompoundModel):\n+        # Handle nested CompoundModels\n+        return np.array([[True, False], [False, True]])\n+    else:\n+        sepleft = _separable(transform.left)\n+        sepright = _separable(transform.right)\n+        return _operators[transform.op](sepleft, sepright)\n         sepleft = _separable(transform.left)\n         sepright = _separable(transform.right)\n         return _operators[transform.op](sepleft, sepright)\n"}
{"model_name_or_path": "llama", "instance_id": "astropy__astropy-13033", "model_patch": "diff --git a/test_timeseries.py b/test_timeseries.py\nnew file mode 100644\nindex 000000000..7e172f98c\n--- /dev/null\n+++ b/test_timeseries.py\n@@ -0,0 +1,9 @@\n+from astropy.timeseries import TimeSeries\n+\n+from astropy.time import Time\n+ts = TimeSeries(time=Time([1, 2, 3], format='jd'), data={'flux': [99.9, 99.8, 99.7]})\n+ts._required_columns = [\"time\", \"flux\"]\n+try:\n+    ts.remove_column(\"flux\")\n+except ValueError as e:\n+    print(e)\n"}
{"model_name_or_path": "llama", "instance_id": "astropy__astropy-13236", "model_patch": "diff --git a/astropy/table/table.py b/astropy/table/table.py\nindex 5afe2127a..d778ea0ad 100644\n--- a/astropy/table/table.py\n+++ b/astropy/table/table.py\n@@ -1243,6 +1243,10 @@ class Table:\n         # mixin class\n         if (not isinstance(data, Column) and not data_is_mixin\n                 and isinstance(data, np.ndarray) and len(data.dtype) > 1):\n+            import warnings\n+            warnings.warn(\"In the future (5.2), structured arrays will be added as Columns. Please wrap data in Column.\", FutureWarning)\n+            import warnings\n+            warnings.warn(\"In the future (5.2), structured arrays will be added as Columns. Please wrap data in Column.\", FutureWarning)\n             data = data.view(NdarrayMixin)\n             data_is_mixin = True\n \n@@ -2342,7 +2346,7 @@ class Table:\n         self.replace_column(name, col)\n \n         if 'always' in warns:\n-            warnings.warn(f\"replaced column '{name}'\",\n+                warnings.warn(f\"replaced column '{name}'\",\n                           TableReplaceWarning, stacklevel=3)\n \n         if 'slice' in warns:\n@@ -2354,9 +2358,9 @@ class Table:\n                     msg = (\"replaced column '{}' which looks like an array slice. \"\n                            \"The new column no longer shares memory with the \"\n                            \"original array.\".format(name))\n-                    warnings.warn(msg, TableReplaceWarning, stacklevel=3)\n+                        warnings.warn(msg, TableReplaceWarning, stacklevel=3)\n             except AttributeError:\n-                pass\n+        pass\n \n         if 'refcount' in warns:\n             # Did reference count change?\n@@ -2364,7 +2368,7 @@ class Table:\n             if refcount != new_refcount:\n                 msg = (\"replaced column '{}' and the number of references \"\n                        \"to the column changed.\".format(name))\n-                warnings.warn(msg, TableReplaceWarning, stacklevel=3)\n+                    warnings.warn(msg, TableReplaceWarning, stacklevel=3)\n \n         if 'attributes' in warns:\n             # Any of the standard column attributes changed?\n@@ -2378,7 +2382,7 @@ class Table:\n             if changed_attrs:\n                 msg = (\"replaced column '{}' and column attributes {} changed.\"\n                        .format(name, changed_attrs))\n-                warnings.warn(msg, TableReplaceWarning, stacklevel=3)\n+                    warnings.warn(msg, TableReplaceWarning, stacklevel=3)\n \n     def replace_column(self, name, col, copy=True):\n         \"\"\"\n@@ -3740,7 +3744,7 @@ class Table:\n \n                     # If pandas is older than 0.24 the type may have turned to float\n                     if column.dtype.kind != out[name].dtype.kind:\n-                        warnings.warn(\n+                            warnings.warn(\n                             f\"converted column '{name}' from {column.dtype} to {out[name].dtype}\",\n                             TableReplaceWarning, stacklevel=3)\n                 elif column.dtype.kind not in ['f', 'c']:\n@@ -3850,7 +3854,7 @@ class Table:\n \n             not_found = set(units.keys()) - set(names)\n             if not_found:\n-                warnings.warn(f'`units` contains additional columns: {not_found}')\n+                    warnings.warn(f'`units` contains additional columns: {not_found}')\n \n             units = [units.get(name) for name in names]\n \n@@ -3958,7 +3962,7 @@ class QTable(Table):\n             try:\n                 qcol = q_cls(col.data, col.unit, copy=False, subok=True)\n             except Exception as exc:\n-                warnings.warn(f\"column {col.info.name} has a unit but is kept as \"\n+                    warnings.warn(f\"column {col.info.name} has a unit but is kept as \"\n                               f\"a {col.__class__.__name__} as an attempt to \"\n                               f\"convert it to Quantity failed with:\\n{exc!r}\",\n                               AstropyUserWarning)\ndiff --git a/table.py.txt b/table.py.txt\nnew file mode 100644\nindex 000000000..39ccdcc52\n--- /dev/null\n+++ b/table.py.txt\n@@ -0,0 +1,3976 @@\n+     1\t# Licensed under a 3-clause BSD style license - see LICENSE.rst\n+     2\tfrom .index import SlicedIndex, TableIndices, TableLoc, TableILoc, TableLocIndices\n+     3\t\n+     4\timport sys\n+     5\tfrom collections import OrderedDict, defaultdict\n+     6\tfrom collections.abc import Mapping\n+     7\timport warnings\n+     8\tfrom copy import deepcopy\n+     9\timport types\n+    10\timport itertools\n+    11\timport weakref\n+    12\t\n+    13\timport numpy as np\n+    14\tfrom numpy import ma\n+    15\t\n+    16\tfrom astropy import log\n+    17\tfrom astropy.units import Quantity, QuantityInfo\n+    18\tfrom astropy.utils import isiterable, ShapedLikeNDArray\n+    19\tfrom astropy.utils.console import color_print\n+    20\tfrom astropy.utils.exceptions import AstropyUserWarning\n+    21\tfrom astropy.utils.masked import Masked\n+    22\tfrom astropy.utils.metadata import MetaData, MetaAttribute\n+    23\tfrom astropy.utils.data_info import BaseColumnInfo, MixinInfo, DataInfo\n+    24\tfrom astropy.utils.decorators import format_doc\n+    25\tfrom astropy.io.registry import UnifiedReadWriteMethod\n+    26\t\n+    27\tfrom . import groups\n+    28\tfrom .pprint import TableFormatter\n+    29\tfrom .column import (BaseColumn, Column, MaskedColumn, _auto_names, FalseArray,\n+    30\t                     col_copy, _convert_sequence_data_to_array)\n+    31\tfrom .row import Row\n+    32\tfrom .info import TableInfo\n+    33\tfrom .index import Index, _IndexModeContext, get_index\n+    34\tfrom .connect import TableRead, TableWrite\n+    35\tfrom .ndarray_mixin import NdarrayMixin\n+    36\tfrom .mixins.registry import get_mixin_handler\n+    37\tfrom . import conf\n+    38\t\n+    39\t\n+    40\t_implementation_notes = \"\"\"\n+    41\tThis string has informal notes concerning Table implementation for developers.\n+    42\t\n+    43\tThings to remember:\n+    44\t\n+    45\t- Table has customizable attributes ColumnClass, Column, MaskedColumn.\n+    46\t  Table.Column is normally just column.Column (same w/ MaskedColumn)\n+    47\t  but in theory they can be different.  Table.ColumnClass is the default\n+    48\t  class used to create new non-mixin columns, and this is a function of\n+    49\t  the Table.masked attribute.  Column creation / manipulation in a Table\n+    50\t  needs to respect these.\n+    51\t\n+    52\t- Column objects that get inserted into the Table.columns attribute must\n+    53\t  have the info.parent_table attribute set correctly.  Beware just dropping\n+    54\t  an object into the columns dict since an existing column may\n+    55\t  be part of another Table and have parent_table set to point at that\n+    56\t  table.  Dropping that column into `columns` of this Table will cause\n+    57\t  a problem for the old one so the column object needs to be copied (but\n+    58\t  not necessarily the data).\n+    59\t\n+    60\t  Currently replace_column is always making a copy of both object and\n+    61\t  data if parent_table is set.  This could be improved but requires a\n+    62\t  generic way to copy a mixin object but not the data.\n+    63\t\n+    64\t- Be aware of column objects that have indices set.\n+    65\t\n+    66\t- `cls.ColumnClass` is a property that effectively uses the `masked` attribute\n+    67\t  to choose either `cls.Column` or `cls.MaskedColumn`.\n+    68\t\"\"\"\n+    69\t\n+    70\t__doctest_skip__ = ['Table.read', 'Table.write', 'Table._read',\n+    71\t                    'Table.convert_bytestring_to_unicode',\n+    72\t                    'Table.convert_unicode_to_bytestring',\n+    73\t                    ]\n+    74\t\n+    75\t__doctest_requires__ = {'*pandas': ['pandas>=1.1']}\n+    76\t\n+    77\t_pprint_docs = \"\"\"\n+    78\t    {__doc__}\n+    79\t\n+    80\t    Parameters\n+    81\t    ----------\n+    82\t    max_lines : int or None\n+    83\t        Maximum number of lines in table output.\n+    84\t\n+    85\t    max_width : int or None\n+    86\t        Maximum character width of output.\n+    87\t\n+    88\t    show_name : bool\n+    89\t        Include a header row for column names. Default is True.\n+    90\t\n+    91\t    show_unit : bool\n+    92\t        Include a header row for unit.  Default is to show a row\n+    93\t        for units only if one or more columns has a defined value\n+    94\t        for the unit.\n+    95\t\n+    96\t    show_dtype : bool\n+    97\t        Include a header row for column dtypes. Default is False.\n+    98\t\n+    99\t    align : str or list or tuple or None\n+   100\t        Left/right alignment of columns. Default is right (None) for all\n+   101\t        columns. Other allowed values are '>', '<', '^', and '0=' for\n+   102\t        right, left, centered, and 0-padded, respectively. A list of\n+   103\t        strings can be provided for alignment of tables with multiple\n+   104\t        columns.\n+   105\t    \"\"\"\n+   106\t\n+   107\t_pformat_docs = \"\"\"\n+   108\t    {__doc__}\n+   109\t\n+   110\t    Parameters\n+   111\t    ----------\n+   112\t    max_lines : int or None\n+   113\t        Maximum number of rows to output\n+   114\t\n+   115\t    max_width : int or None\n+   116\t        Maximum character width of output\n+   117\t\n+   118\t    show_name : bool\n+   119\t        Include a header row for column names. Default is True.\n+   120\t\n+   121\t    show_unit : bool\n+   122\t        Include a header row for unit.  Default is to show a row\n+   123\t        for units only if one or more columns has a defined value\n+   124\t        for the unit.\n+   125\t\n+   126\t    show_dtype : bool\n+   127\t        Include a header row for column dtypes. Default is True.\n+   128\t\n+   129\t    html : bool\n+   130\t        Format the output as an HTML table. Default is False.\n+   131\t\n+   132\t    tableid : str or None\n+   133\t        An ID tag for the table; only used if html is set.  Default is\n+   134\t        \"table{id}\", where id is the unique integer id of the table object,\n+   135\t        id(self)\n+   136\t\n+   137\t    align : str or list or tuple or None\n+   138\t        Left/right alignment of columns. Default is right (None) for all\n+   139\t        columns. Other allowed values are '>', '<', '^', and '0=' for\n+   140\t        right, left, centered, and 0-padded, respectively. A list of\n+   141\t        strings can be provided for alignment of tables with multiple\n+   142\t        columns.\n+   143\t\n+   144\t    tableclass : str or list of str or None\n+   145\t        CSS classes for the table; only used if html is set.  Default is\n+   146\t        None.\n+   147\t\n+   148\t    Returns\n+   149\t    -------\n+   150\t    lines : list\n+   151\t        Formatted table as a list of strings.\n+   152\t    \"\"\"\n+   153\t\n+   154\t\n+   155\tclass TableReplaceWarning(UserWarning):\n+   156\t    \"\"\"\n+   157\t    Warning class for cases when a table column is replaced via the\n+   158\t    Table.__setitem__ syntax e.g. t['a'] = val.\n+   159\t\n+   160\t    This does not inherit from AstropyWarning because we want to use\n+   161\t    stacklevel=3 to show the user where the issue occurred in their code.\n+   162\t    \"\"\"\n+   163\t    pass\n+   164\t\n+   165\t\n+   166\tdef descr(col):\n+   167\t    \"\"\"Array-interface compliant full description of a column.\n+   168\t\n+   169\t    This returns a 3-tuple (name, type, shape) that can always be\n+   170\t    used in a structured array dtype definition.\n+   171\t    \"\"\"\n+   172\t    col_dtype = 'O' if (col.info.dtype is None) else col.info.dtype\n+   173\t    col_shape = col.shape[1:] if hasattr(col, 'shape') else ()\n+   174\t    return (col.info.name, col_dtype, col_shape)\n+   175\t\n+   176\t\n+   177\tdef has_info_class(obj, cls):\n+   178\t    \"\"\"Check if the object's info is an instance of cls.\"\"\"\n+   179\t    # We check info on the class of the instance, since on the instance\n+   180\t    # itself accessing 'info' has side effects in that it sets\n+   181\t    # obj.__dict__['info'] if it does not exist already.\n+   182\t    return isinstance(getattr(obj.__class__, 'info', None), cls)\n+   183\t\n+   184\t\n+   185\tdef _get_names_from_list_of_dict(rows):\n+   186\t    \"\"\"Return list of column names if ``rows`` is a list of dict that\n+   187\t    defines table data.\n+   188\t\n+   189\t    If rows is not a list of dict then return None.\n+   190\t    \"\"\"\n+   191\t    if rows is None:\n+   192\t        return None\n+   193\t\n+   194\t    names = set()\n+   195\t    for row in rows:\n+   196\t        if not isinstance(row, Mapping):\n+   197\t            return None\n+   198\t        names.update(row)\n+   199\t    return list(names)\n+   200\t\n+   201\t\n+   202\t# Note to future maintainers: when transitioning this to dict\n+   203\t# be sure to change the OrderedDict ref(s) in Row and in __len__().\n+   204\t\n+   205\tclass TableColumns(OrderedDict):\n+   206\t    \"\"\"OrderedDict subclass for a set of columns.\n+   207\t\n+   208\t    This class enhances item access to provide convenient access to columns\n+   209\t    by name or index, including slice access.  It also handles renaming\n+   210\t    of columns.\n+   211\t\n+   212\t    The initialization argument ``cols`` can be a list of ``Column`` objects\n+   213\t    or any structure that is valid for initializing a Python dict.  This\n+   214\t    includes a dict, list of (key, val) tuples or [key, val] lists, etc.\n+   215\t\n+   216\t    Parameters\n+   217\t    ----------\n+   218\t    cols : dict, list, tuple; optional\n+   219\t        Column objects as data structure that can init dict (see above)\n+   220\t    \"\"\"\n+   221\t\n+   222\t    def __init__(self, cols={}):\n+   223\t        if isinstance(cols, (list, tuple)):\n+   224\t            # `cols` should be a list of two-tuples, but it is allowed to have\n+   225\t            # columns (BaseColumn or mixins) in the list.\n+   226\t            newcols = []\n+   227\t            for col in cols:\n+   228\t                if has_info_class(col, BaseColumnInfo):\n+   229\t                    newcols.append((col.info.name, col))\n+   230\t                else:\n+   231\t                    newcols.append(col)\n+   232\t            cols = newcols\n+   233\t        super().__init__(cols)\n+   234\t\n+   235\t    def __getitem__(self, item):\n+   236\t        \"\"\"Get items from a TableColumns object.\n+   237\t        ::\n+   238\t\n+   239\t          tc = TableColumns(cols=[Column(name='a'), Column(name='b'), Column(name='c')])\n+   240\t          tc['a']  # Column('a')\n+   241\t          tc[1] # Column('b')\n+   242\t          tc['a', 'b'] # <TableColumns names=('a', 'b')>\n+   243\t          tc[1:3] # <TableColumns names=('b', 'c')>\n+   244\t        \"\"\"\n+   245\t        if isinstance(item, str):\n+   246\t            return OrderedDict.__getitem__(self, item)\n+   247\t        elif isinstance(item, (int, np.integer)):\n+   248\t            return list(self.values())[item]\n+   249\t        elif (isinstance(item, np.ndarray) and item.shape == () and item.dtype.kind == 'i'):\n+   250\t            return list(self.values())[item.item()]\n+   251\t        elif isinstance(item, tuple):\n+   252\t            return self.__class__([self[x] for x in item])\n+   253\t        elif isinstance(item, slice):\n+   254\t            return self.__class__([self[x] for x in list(self)[item]])\n+   255\t        else:\n+   256\t            raise IndexError('Illegal key or index value for {} object'\n+   257\t                             .format(self.__class__.__name__))\n+   258\t\n+   259\t    def __setitem__(self, item, value, validated=False):\n+   260\t        \"\"\"\n+   261\t        Set item in this dict instance, but do not allow directly replacing an\n+   262\t        existing column unless it is already validated (and thus is certain to\n+   263\t        not corrupt the table).\n+   264\t\n+   265\t        NOTE: it is easily possible to corrupt a table by directly *adding* a new\n+   266\t        key to the TableColumns attribute of a Table, e.g.\n+   267\t        ``t.columns['jane'] = 'doe'``.\n+   268\t\n+   269\t        \"\"\"\n+   270\t        if item in self and not validated:\n+   271\t            raise ValueError(\"Cannot replace column '{}'.  Use Table.replace_column() instead.\"\n+   272\t                             .format(item))\n+   273\t        super().__setitem__(item, value)\n+   274\t\n+   275\t    def __repr__(self):\n+   276\t        names = (f\"'{x}'\" for x in self.keys())\n+   277\t        return f\"<{self.__class__.__name__} names=({','.join(names)})>\"\n+   278\t\n+   279\t    def _rename_column(self, name, new_name):\n+   280\t        if name == new_name:\n+   281\t            return\n+   282\t\n+   283\t        if new_name in self:\n+   284\t            raise KeyError(f\"Column {new_name} already exists\")\n+   285\t\n+   286\t        # Rename column names in pprint include/exclude attributes as needed\n+   287\t        parent_table = self[name].info.parent_table\n+   288\t        if parent_table is not None:\n+   289\t            parent_table.pprint_exclude_names._rename(name, new_name)\n+   290\t            parent_table.pprint_include_names._rename(name, new_name)\n+   291\t\n+   292\t        mapper = {name: new_name}\n+   293\t        new_names = [mapper.get(name, name) for name in self]\n+   294\t        cols = list(self.values())\n+   295\t        self.clear()\n+   296\t        self.update(list(zip(new_names, cols)))\n+   297\t\n+   298\t    def __delitem__(self, name):\n+   299\t        # Remove column names from pprint include/exclude attributes as needed.\n+   300\t        # __delitem__ also gets called for pop() and popitem().\n+   301\t        parent_table = self[name].info.parent_table\n+   302\t        if parent_table is not None:\n+   303\t            # _remove() method does not require that `name` is in the attribute\n+   304\t            parent_table.pprint_exclude_names._remove(name)\n+   305\t            parent_table.pprint_include_names._remove(name)\n+   306\t        return super().__delitem__(name)\n+   307\t\n+   308\t    def isinstance(self, cls):\n+   309\t        \"\"\"\n+   310\t        Return a list of columns which are instances of the specified classes.\n+   311\t\n+   312\t        Parameters\n+   313\t        ----------\n+   314\t        cls : class or tuple thereof\n+   315\t            Column class (including mixin) or tuple of Column classes.\n+   316\t\n+   317\t        Returns\n+   318\t        -------\n+   319\t        col_list : list of `Column`\n+   320\t            List of Column objects which are instances of given classes.\n+   321\t        \"\"\"\n+   322\t        cols = [col for col in self.values() if isinstance(col, cls)]\n+   323\t        return cols\n+   324\t\n+   325\t    def not_isinstance(self, cls):\n+   326\t        \"\"\"\n+   327\t        Return a list of columns which are not instances of the specified classes.\n+   328\t\n+   329\t        Parameters\n+   330\t        ----------\n+   331\t        cls : class or tuple thereof\n+   332\t            Column class (including mixin) or tuple of Column classes.\n+   333\t\n+   334\t        Returns\n+   335\t        -------\n+   336\t        col_list : list of `Column`\n+   337\t            List of Column objects which are not instances of given classes.\n+   338\t        \"\"\"\n+   339\t        cols = [col for col in self.values() if not isinstance(col, cls)]\n+   340\t        return cols\n+   341\t\n+   342\t\n+   343\tclass TableAttribute(MetaAttribute):\n+   344\t    \"\"\"\n+   345\t    Descriptor to define a custom attribute for a Table subclass.\n+   346\t\n+   347\t    The value of the ``TableAttribute`` will be stored in a dict named\n+   348\t    ``__attributes__`` that is stored in the table ``meta``.  The attribute\n+   349\t    can be accessed and set in the usual way, and it can be provided when\n+   350\t    creating the object.\n+   351\t\n+   352\t    Defining an attribute by this mechanism ensures that it will persist if\n+   353\t    the table is sliced or serialized, for example as a pickle or ECSV file.\n+   354\t\n+   355\t    See the `~astropy.utils.metadata.MetaAttribute` documentation for additional\n+   356\t    details.\n+   357\t\n+   358\t    Parameters\n+   359\t    ----------\n+   360\t    default : object\n+   361\t        Default value for attribute\n+   362\t\n+   363\t    Examples\n+   364\t    --------\n+   365\t      >>> from astropy.table import Table, TableAttribute\n+   366\t      >>> class MyTable(Table):\n+   367\t      ...     identifier = TableAttribute(default=1)\n+   368\t      >>> t = MyTable(identifier=10)\n+   369\t      >>> t.identifier\n+   370\t      10\n+   371\t      >>> t.meta\n+   372\t      OrderedDict([('__attributes__', {'identifier': 10})])\n+   373\t    \"\"\"\n+   374\t\n+   375\t\n+   376\tclass PprintIncludeExclude(TableAttribute):\n+   377\t    \"\"\"Maintain tuple that controls table column visibility for print output.\n+   378\t\n+   379\t    This is a descriptor that inherits from MetaAttribute so that the attribute\n+   380\t    value is stored in the table meta['__attributes__'].\n+   381\t\n+   382\t    This gets used for the ``pprint_include_names`` and ``pprint_exclude_names`` Table\n+   383\t    attributes.\n+   384\t    \"\"\"\n+   385\t    def __get__(self, instance, owner_cls):\n+   386\t        \"\"\"Get the attribute.\n+   387\t\n+   388\t        This normally returns an instance of this class which is stored on the\n+   389\t        owner object.\n+   390\t        \"\"\"\n+   391\t        # For getting from class not an instance\n+   392\t        if instance is None:\n+   393\t            return self\n+   394\t\n+   395\t        # If not already stored on `instance`, make a copy of the class\n+   396\t        # descriptor object and put it onto the instance.\n+   397\t        value = instance.__dict__.get(self.name)\n+   398\t        if value is None:\n+   399\t            value = deepcopy(self)\n+   400\t            instance.__dict__[self.name] = value\n+   401\t\n+   402\t        # We set _instance_ref on every call, since if one makes copies of\n+   403\t        # instances, this attribute will be copied as well, which will lose the\n+   404\t        # reference.\n+   405\t        value._instance_ref = weakref.ref(instance)\n+   406\t        return value\n+   407\t\n+   408\t    def __set__(self, instance, names):\n+   409\t        \"\"\"Set value of ``instance`` attribute to ``names``.\n+   410\t\n+   411\t        Parameters\n+   412\t        ----------\n+   413\t        instance : object\n+   414\t            Instance that owns the attribute\n+   415\t        names : None, str, list, tuple\n+   416\t            Column name(s) to store, or None to clear\n+   417\t        \"\"\"\n+   418\t        if isinstance(names, str):\n+   419\t            names = [names]\n+   420\t        if names is None:\n+   421\t            # Remove attribute value from the meta['__attributes__'] dict.\n+   422\t            # Subsequent access will just return None.\n+   423\t            delattr(instance, self.name)\n+   424\t        else:\n+   425\t            # This stores names into instance.meta['__attributes__'] as tuple\n+   426\t            return super().__set__(instance, tuple(names))\n+   427\t\n+   428\t    def __call__(self):\n+   429\t        \"\"\"Get the value of the attribute.\n+   430\t\n+   431\t        Returns\n+   432\t        -------\n+   433\t        names : None, tuple\n+   434\t            Include/exclude names\n+   435\t        \"\"\"\n+   436\t        # Get the value from instance.meta['__attributes__']\n+   437\t        instance = self._instance_ref()\n+   438\t        return super().__get__(instance, instance.__class__)\n+   439\t\n+   440\t    def __repr__(self):\n+   441\t        if hasattr(self, '_instance_ref'):\n+   442\t            out = f'<{self.__class__.__name__} name={self.name} value={self()}>'\n+   443\t        else:\n+   444\t            out = super().__repr__()\n+   445\t        return out\n+   446\t\n+   447\t    def _add_remove_setup(self, names):\n+   448\t        \"\"\"Common setup for add and remove.\n+   449\t\n+   450\t        - Coerce attribute value to a list\n+   451\t        - Coerce names into a list\n+   452\t        - Get the parent table instance\n+   453\t        \"\"\"\n+   454\t        names = [names] if isinstance(names, str) else list(names)\n+   455\t        # Get the value. This is the same as self() but we need `instance` here.\n+   456\t        instance = self._instance_ref()\n+   457\t        value = super().__get__(instance, instance.__class__)\n+   458\t        value = [] if value is None else list(value)\n+   459\t        return instance, names, value\n+   460\t\n+   461\t    def add(self, names):\n+   462\t        \"\"\"Add ``names`` to the include/exclude attribute.\n+   463\t\n+   464\t        Parameters\n+   465\t        ----------\n+   466\t        names : str, list, tuple\n+   467\t            Column name(s) to add\n+   468\t        \"\"\"\n+   469\t        instance, names, value = self._add_remove_setup(names)\n+   470\t        value.extend(name for name in names if name not in value)\n+   471\t        super().__set__(instance, tuple(value))\n+   472\t\n+   473\t    def remove(self, names):\n+   474\t        \"\"\"Remove ``names`` from the include/exclude attribute.\n+   475\t\n+   476\t        Parameters\n+   477\t        ----------\n+   478\t        names : str, list, tuple\n+   479\t            Column name(s) to remove\n+   480\t        \"\"\"\n+   481\t        self._remove(names, raise_exc=True)\n+   482\t\n+   483\t    def _remove(self, names, raise_exc=False):\n+   484\t        \"\"\"Remove ``names`` with optional checking if they exist\"\"\"\n+   485\t        instance, names, value = self._add_remove_setup(names)\n+   486\t\n+   487\t        # Return now if there are no attributes and thus no action to be taken.\n+   488\t        if not raise_exc and '__attributes__' not in instance.meta:\n+   489\t            return\n+   490\t\n+   491\t        # Remove one by one, optionally raising an exception if name is missing.\n+   492\t        for name in names:\n+   493\t            if name in value:\n+   494\t                value.remove(name)  # Using the list.remove method\n+   495\t            elif raise_exc:\n+   496\t                raise ValueError(f'{name} not in {self.name}')\n+   497\t\n+   498\t        # Change to either None or a tuple for storing back to attribute\n+   499\t        value = None if value == [] else tuple(value)\n+   500\t        self.__set__(instance, value)\n+   501\t\n+   502\t    def _rename(self, name, new_name):\n+   503\t        \"\"\"Rename ``name`` to ``new_name`` if ``name`` is in the list\"\"\"\n+   504\t        names = self() or ()\n+   505\t        if name in names:\n+   506\t            new_names = list(names)\n+   507\t            new_names[new_names.index(name)] = new_name\n+   508\t            self.set(new_names)\n+   509\t\n+   510\t    def set(self, names):\n+   511\t        \"\"\"Set value of include/exclude attribute to ``names``.\n+   512\t\n+   513\t        Parameters\n+   514\t        ----------\n+   515\t        names : None, str, list, tuple\n+   516\t            Column name(s) to store, or None to clear\n+   517\t        \"\"\"\n+   518\t        class _Context:\n+   519\t            def __init__(self, descriptor_self):\n+   520\t                self.descriptor_self = descriptor_self\n+   521\t                self.names_orig = descriptor_self()\n+   522\t\n+   523\t            def __enter__(self):\n+   524\t                pass\n+   525\t\n+   526\t            def __exit__(self, type, value, tb):\n+   527\t                descriptor_self = self.descriptor_self\n+   528\t                instance = descriptor_self._instance_ref()\n+   529\t                descriptor_self.__set__(instance, self.names_orig)\n+   530\t\n+   531\t            def __repr__(self):\n+   532\t                return repr(self.descriptor_self)\n+   533\t\n+   534\t        ctx = _Context(descriptor_self=self)\n+   535\t\n+   536\t        instance = self._instance_ref()\n+   537\t        self.__set__(instance, names)\n+   538\t\n+   539\t        return ctx\n+   540\t\n+   541\t\n+   542\tclass Table:\n+   543\t    \"\"\"A class to represent tables of heterogeneous data.\n+   544\t\n+   545\t    `~astropy.table.Table` provides a class for heterogeneous tabular data.\n+   546\t    A key enhancement provided by the `~astropy.table.Table` class over\n+   547\t    e.g. a `numpy` structured array is the ability to easily modify the\n+   548\t    structure of the table by adding or removing columns, or adding new\n+   549\t    rows of data.  In addition table and column metadata are fully supported.\n+   550\t\n+   551\t    `~astropy.table.Table` differs from `~astropy.nddata.NDData` by the\n+   552\t    assumption that the input data consists of columns of homogeneous data,\n+   553\t    where each column has a unique identifier and may contain additional\n+   554\t    metadata such as the data unit, format, and description.\n+   555\t\n+   556\t    See also: https://docs.astropy.org/en/stable/table/\n+   557\t\n+   558\t    Parameters\n+   559\t    ----------\n+   560\t    data : numpy ndarray, dict, list, table-like object, optional\n+   561\t        Data to initialize table.\n+   562\t    masked : bool, optional\n+   563\t        Specify whether the table is masked.\n+   564\t    names : list, optional\n+   565\t        Specify column names.\n+   566\t    dtype : list, optional\n+   567\t        Specify column data types.\n+   568\t    meta : dict, optional\n+   569\t        Metadata associated with the table.\n+   570\t    copy : bool, optional\n+   571\t        Copy the input data. If the input is a Table the ``meta`` is always\n+   572\t        copied regardless of the ``copy`` parameter.\n+   573\t        Default is True.\n+   574\t    rows : numpy ndarray, list of list, optional\n+   575\t        Row-oriented data for table instead of ``data`` argument.\n+   576\t    copy_indices : bool, optional\n+   577\t        Copy any indices in the input data. Default is True.\n+   578\t    units : list, dict, optional\n+   579\t        List or dict of units to apply to columns.\n+   580\t    descriptions : list, dict, optional\n+   581\t        List or dict of descriptions to apply to columns.\n+   582\t    **kwargs : dict, optional\n+   583\t        Additional keyword args when converting table-like object.\n+   584\t    \"\"\"\n+   585\t\n+   586\t    meta = MetaData(copy=False)\n+   587\t\n+   588\t    # Define class attributes for core container objects to allow for subclass\n+   589\t    # customization.\n+   590\t    Row = Row\n+   591\t    Column = Column\n+   592\t    MaskedColumn = MaskedColumn\n+   593\t    TableColumns = TableColumns\n+   594\t    TableFormatter = TableFormatter\n+   595\t\n+   596\t    # Unified I/O read and write methods from .connect\n+   597\t    read = UnifiedReadWriteMethod(TableRead)\n+   598\t    write = UnifiedReadWriteMethod(TableWrite)\n+   599\t\n+   600\t    pprint_exclude_names = PprintIncludeExclude()\n+   601\t    pprint_include_names = PprintIncludeExclude()\n+   602\t\n+   603\t    def as_array(self, keep_byteorder=False, names=None):\n+   604\t        \"\"\"\n+   605\t        Return a new copy of the table in the form of a structured np.ndarray or\n+   606\t        np.ma.MaskedArray object (as appropriate).\n+   607\t\n+   608\t        Parameters\n+   609\t        ----------\n+   610\t        keep_byteorder : bool, optional\n+   611\t            By default the returned array has all columns in native byte\n+   612\t            order.  However, if this option is `True` this preserves the\n+   613\t            byte order of all columns (if any are non-native).\n+   614\t\n+   615\t        names : list, optional:\n+   616\t            List of column names to include for returned structured array.\n+   617\t            Default is to include all table columns.\n+   618\t\n+   619\t        Returns\n+   620\t        -------\n+   621\t        table_array : array or `~numpy.ma.MaskedArray`\n+   622\t            Copy of table as a numpy structured array.\n+   623\t            ndarray for unmasked or `~numpy.ma.MaskedArray` for masked.\n+   624\t        \"\"\"\n+   625\t        masked = self.masked or self.has_masked_columns or self.has_masked_values\n+   626\t        empty_init = ma.empty if masked else np.empty\n+   627\t        if len(self.columns) == 0:\n+   628\t            return empty_init(0, dtype=None)\n+   629\t\n+   630\t        dtype = []\n+   631\t\n+   632\t        cols = self.columns.values()\n+   633\t\n+   634\t        if names is not None:\n+   635\t            cols = [col for col in cols if col.info.name in names]\n+   636\t\n+   637\t        for col in cols:\n+   638\t            col_descr = descr(col)\n+   639\t\n+   640\t            if not (col.info.dtype.isnative or keep_byteorder):\n+   641\t                new_dt = np.dtype(col_descr[1]).newbyteorder('=')\n+   642\t                col_descr = (col_descr[0], new_dt, col_descr[2])\n+   643\t\n+   644\t            dtype.append(col_descr)\n+   645\t\n+   646\t        data = empty_init(len(self), dtype=dtype)\n+   647\t        for col in cols:\n+   648\t            # When assigning from one array into a field of a structured array,\n+   649\t            # Numpy will automatically swap those columns to their destination\n+   650\t            # byte order where applicable\n+   651\t            data[col.info.name] = col\n+   652\t\n+   653\t            # For masked out, masked mixin columns need to set output mask attribute.\n+   654\t            if masked and has_info_class(col, MixinInfo) and hasattr(col, 'mask'):\n+   655\t                data[col.info.name].mask = col.mask\n+   656\t\n+   657\t        return data\n+   658\t\n+   659\t    def __init__(self, data=None, masked=False, names=None, dtype=None,\n+   660\t                 meta=None, copy=True, rows=None, copy_indices=True,\n+   661\t                 units=None, descriptions=None,\n+   662\t                 **kwargs):\n+   663\t\n+   664\t        # Set up a placeholder empty table\n+   665\t        self._set_masked(masked)\n+   666\t        self.columns = self.TableColumns()\n+   667\t        self.formatter = self.TableFormatter()\n+   668\t        self._copy_indices = True  # copy indices from this Table by default\n+   669\t        self._init_indices = copy_indices  # whether to copy indices in init\n+   670\t        self.primary_key = None\n+   671\t\n+   672\t        # Must copy if dtype are changing\n+   673\t        if not copy and dtype is not None:\n+   674\t            raise ValueError('Cannot specify dtype when copy=False')\n+   675\t\n+   676\t        # Specifies list of names found for the case of initializing table with\n+   677\t        # a list of dict. If data are not list of dict then this is None.\n+   678\t        names_from_list_of_dict = None\n+   679\t\n+   680\t        # Row-oriented input, e.g. list of lists or list of tuples, list of\n+   681\t        # dict, Row instance.  Set data to something that the subsequent code\n+   682\t        # will parse correctly.\n+   683\t        if rows is not None:\n+   684\t            if data is not None:\n+   685\t                raise ValueError('Cannot supply both `data` and `rows` values')\n+   686\t            if isinstance(rows, types.GeneratorType):\n+   687\t                # Without this then the all(..) test below uses up the generator\n+   688\t                rows = list(rows)\n+   689\t\n+   690\t            # Get column names if `rows` is a list of dict, otherwise this is None\n+   691\t            names_from_list_of_dict = _get_names_from_list_of_dict(rows)\n+   692\t            if names_from_list_of_dict:\n+   693\t                data = rows\n+   694\t            elif isinstance(rows, self.Row):\n+   695\t                data = rows\n+   696\t            else:\n+   697\t                data = list(zip(*rows))\n+   698\t\n+   699\t        # Infer the type of the input data and set up the initialization\n+   700\t        # function, number of columns, and potentially the default col names\n+   701\t\n+   702\t        default_names = None\n+   703\t\n+   704\t        # Handle custom (subclass) table attributes that are stored in meta.\n+   705\t        # These are defined as class attributes using the TableAttribute\n+   706\t        # descriptor.  Any such attributes get removed from kwargs here and\n+   707\t        # stored for use after the table is otherwise initialized. Any values\n+   708\t        # provided via kwargs will have precedence over existing values from\n+   709\t        # meta (e.g. from data as a Table or meta via kwargs).\n+   710\t        meta_table_attrs = {}\n+   711\t        if kwargs:\n+   712\t            for attr in list(kwargs):\n+   713\t                descr = getattr(self.__class__, attr, None)\n+   714\t                if isinstance(descr, TableAttribute):\n+   715\t                    meta_table_attrs[attr] = kwargs.pop(attr)\n+   716\t\n+   717\t        if hasattr(data, '__astropy_table__'):\n+   718\t            # Data object implements the __astropy_table__ interface method.\n+   719\t            # Calling that method returns an appropriate instance of\n+   720\t            # self.__class__ and respects the `copy` arg.  The returned\n+   721\t            # Table object should NOT then be copied.\n+   722\t            data = data.__astropy_table__(self.__class__, copy, **kwargs)\n+   723\t            copy = False\n+   724\t        elif kwargs:\n+   725\t            raise TypeError('__init__() got unexpected keyword argument {!r}'\n+   726\t                            .format(list(kwargs.keys())[0]))\n+   727\t\n+   728\t        if (isinstance(data, np.ndarray)\n+   729\t                and data.shape == (0,)\n+   730\t                and not data.dtype.names):\n+   731\t            data = None\n+   732\t\n+   733\t        if isinstance(data, self.Row):\n+   734\t            data = data._table[data._index:data._index + 1]\n+   735\t\n+   736\t        if isinstance(data, (list, tuple)):\n+   737\t            # Get column names from `data` if it is a list of dict, otherwise this is None.\n+   738\t            # This might be previously defined if `rows` was supplied as an init arg.\n+   739\t            names_from_list_of_dict = (names_from_list_of_dict\n+   740\t                                       or _get_names_from_list_of_dict(data))\n+   741\t            if names_from_list_of_dict:\n+   742\t                init_func = self._init_from_list_of_dicts\n+   743\t                n_cols = len(names_from_list_of_dict)\n+   744\t            else:\n+   745\t                init_func = self._init_from_list\n+   746\t                n_cols = len(data)\n+   747\t\n+   748\t        elif isinstance(data, np.ndarray):\n+   749\t            if data.dtype.names:\n+   750\t                init_func = self._init_from_ndarray  # _struct\n+   751\t                n_cols = len(data.dtype.names)\n+   752\t                default_names = data.dtype.names\n+   753\t            else:\n+   754\t                init_func = self._init_from_ndarray  # _homog\n+   755\t                if data.shape == ():\n+   756\t                    raise ValueError('Can not initialize a Table with a scalar')\n+   757\t                elif len(data.shape) == 1:\n+   758\t                    data = data[np.newaxis, :]\n+   759\t                n_cols = data.shape[1]\n+   760\t\n+   761\t        elif isinstance(data, Mapping):\n+   762\t            init_func = self._init_from_dict\n+   763\t            default_names = list(data)\n+   764\t            n_cols = len(default_names)\n+   765\t\n+   766\t        elif isinstance(data, Table):\n+   767\t            # If user-input meta is None then use data.meta (if non-trivial)\n+   768\t            if meta is None and data.meta:\n+   769\t                # At this point do NOT deepcopy data.meta as this will happen after\n+   770\t                # table init_func() is called.  But for table input the table meta\n+   771\t                # gets a key copy here if copy=False because later a direct object ref\n+   772\t                # is used.\n+   773\t                meta = data.meta if copy else data.meta.copy()\n+   774\t\n+   775\t            # Handle indices on input table. Copy primary key and don't copy indices\n+   776\t            # if the input Table is in non-copy mode.\n+   777\t            self.primary_key = data.primary_key\n+   778\t            self._init_indices = self._init_indices and data._copy_indices\n+   779\t\n+   780\t            # Extract default names, n_cols, and then overwrite ``data`` to be the\n+   781\t            # table columns so we can use _init_from_list.\n+   782\t            default_names = data.colnames\n+   783\t            n_cols = len(default_names)\n+   784\t            data = list(data.columns.values())\n+   785\t\n+   786\t            init_func = self._init_from_list\n+   787\t\n+   788\t        elif data is None:\n+   789\t            if names is None:\n+   790\t                if dtype is None:\n+   791\t                    # Table was initialized as `t = Table()`. Set up for empty\n+   792\t                    # table with names=[], data=[], and n_cols=0.\n+   793\t                    # self._init_from_list() will simply return, giving the\n+   794\t                    # expected empty table.\n+   795\t                    names = []\n+   796\t                else:\n+   797\t                    try:\n+   798\t                        # No data nor names but dtype is available.  This must be\n+   799\t                        # valid to initialize a structured array.\n+   800\t                        dtype = np.dtype(dtype)\n+   801\t                        names = dtype.names\n+   802\t                        dtype = [dtype[name] for name in names]\n+   803\t                    except Exception:\n+   804\t                        raise ValueError('dtype was specified but could not be '\n+   805\t                                         'parsed for column names')\n+   806\t            # names is guaranteed to be set at this point\n+   807\t            init_func = self._init_from_list\n+   808\t            n_cols = len(names)\n+   809\t            data = [[]] * n_cols\n+   810\t\n+   811\t        else:\n+   812\t            raise ValueError(f'Data type {type(data)} not allowed to init Table')\n+   813\t\n+   814\t        # Set up defaults if names and/or dtype are not specified.\n+   815\t        # A value of None means the actual value will be inferred\n+   816\t        # within the appropriate initialization routine, either from\n+   817\t        # existing specification or auto-generated.\n+   818\t\n+   819\t        if dtype is None:\n+   820\t            dtype = [None] * n_cols\n+   821\t        elif isinstance(dtype, np.dtype):\n+   822\t            if default_names is None:\n+   823\t                default_names = dtype.names\n+   824\t            # Convert a numpy dtype input to a list of dtypes for later use.\n+   825\t            dtype = [dtype[name] for name in dtype.names]\n+   826\t\n+   827\t        if names is None:\n+   828\t            names = default_names or [None] * n_cols\n+   829\t\n+   830\t        names = [None if name is None else str(name) for name in names]\n+   831\t\n+   832\t        self._check_names_dtype(names, dtype, n_cols)\n+   833\t\n+   834\t        # Finally do the real initialization\n+   835\t        init_func(data, names, dtype, n_cols, copy)\n+   836\t\n+   837\t        # Set table meta.  If copy=True then deepcopy meta otherwise use the\n+   838\t        # user-supplied meta directly.\n+   839\t        if meta is not None:\n+   840\t            self.meta = deepcopy(meta) if copy else meta\n+   841\t\n+   842\t        # Update meta with TableAttributes supplied as kwargs in Table init.\n+   843\t        # This takes precedence over previously-defined meta.\n+   844\t        if meta_table_attrs:\n+   845\t            for attr, value in meta_table_attrs.items():\n+   846\t                setattr(self, attr, value)\n+   847\t\n+   848\t        # Whatever happens above, the masked property should be set to a boolean\n+   849\t        if self.masked not in (None, True, False):\n+   850\t            raise TypeError(\"masked property must be None, True or False\")\n+   851\t\n+   852\t        self._set_column_attribute('unit', units)\n+   853\t        self._set_column_attribute('description', descriptions)\n+   854\t\n+   855\t    def _set_column_attribute(self, attr, values):\n+   856\t        \"\"\"Set ``attr`` for columns to ``values``, which can be either a dict (keyed by column\n+   857\t        name) or a dict of name: value pairs.  This is used for handling the ``units`` and\n+   858\t        ``descriptions`` kwargs to ``__init__``.\n+   859\t        \"\"\"\n+   860\t        if not values:\n+   861\t            return\n+   862\t\n+   863\t        if isinstance(values, Row):\n+   864\t            # For a Row object transform to an equivalent dict.\n+   865\t            values = {name: values[name] for name in values.colnames}\n+   866\t\n+   867\t        if not isinstance(values, Mapping):\n+   868\t            # If not a dict map, assume iterable and map to dict if the right length\n+   869\t            if len(values) != len(self.columns):\n+   870\t                raise ValueError(f'sequence of {attr} values must match number of columns')\n+   871\t            values = dict(zip(self.colnames, values))\n+   872\t\n+   873\t        for name, value in values.items():\n+   874\t            if name not in self.columns:\n+   875\t                raise ValueError(f'invalid column name {name} for setting {attr} attribute')\n+   876\t\n+   877\t            # Special case: ignore unit if it is an empty or blank string\n+   878\t            if attr == 'unit' and isinstance(value, str):\n+   879\t                if value.strip() == '':\n+   880\t                    value = None\n+   881\t\n+   882\t            if value not in (np.ma.masked, None):\n+   883\t                setattr(self[name].info, attr, value)\n+   884\t\n+   885\t    def __getstate__(self):\n+   886\t        columns = OrderedDict((key, col if isinstance(col, BaseColumn) else col_copy(col))\n+   887\t                              for key, col in self.columns.items())\n+   888\t        return (columns, self.meta)\n+   889\t\n+   890\t    def __setstate__(self, state):\n+   891\t        columns, meta = state\n+   892\t        self.__init__(columns, meta=meta)\n+   893\t\n+   894\t    @property\n+   895\t    def mask(self):\n+   896\t        # Dynamic view of available masks\n+   897\t        if self.masked or self.has_masked_columns or self.has_masked_values:\n+   898\t            mask_table = Table([getattr(col, 'mask', FalseArray(col.shape))\n+   899\t                                for col in self.itercols()],\n+   900\t                               names=self.colnames, copy=False)\n+   901\t\n+   902\t            # Set hidden attribute to force inplace setitem so that code like\n+   903\t            # t.mask['a'] = [1, 0, 1] will correctly set the underlying mask.\n+   904\t            # See #5556 for discussion.\n+   905\t            mask_table._setitem_inplace = True\n+   906\t        else:\n+   907\t            mask_table = None\n+   908\t\n+   909\t        return mask_table\n+   910\t\n+   911\t    @mask.setter\n+   912\t    def mask(self, val):\n+   913\t        self.mask[:] = val\n+   914\t\n+   915\t    @property\n+   916\t    def _mask(self):\n+   917\t        \"\"\"This is needed so that comparison of a masked Table and a\n+   918\t        MaskedArray works.  The requirement comes from numpy.ma.core\n+   919\t        so don't remove this property.\"\"\"\n+   920\t        return self.as_array().mask\n+   921\t\n+   922\t    def filled(self, fill_value=None):\n+   923\t        \"\"\"Return copy of self, with masked values filled.\n+   924\t\n+   925\t        If input ``fill_value`` supplied then that value is used for all\n+   926\t        masked entries in the table.  Otherwise the individual\n+   927\t        ``fill_value`` defined for each table column is used.\n+   928\t\n+   929\t        Parameters\n+   930\t        ----------\n+   931\t        fill_value : str\n+   932\t            If supplied, this ``fill_value`` is used for all masked entries\n+   933\t            in the entire table.\n+   934\t\n+   935\t        Returns\n+   936\t        -------\n+   937\t        filled_table : `~astropy.table.Table`\n+   938\t            New table with masked values filled\n+   939\t        \"\"\"\n+   940\t        if self.masked or self.has_masked_columns or self.has_masked_values:\n+   941\t            # Get new columns with masked values filled, then create Table with those\n+   942\t            # new cols (copy=False) but deepcopy the meta.\n+   943\t            data = [col.filled(fill_value) if hasattr(col, 'filled') else col\n+   944\t                    for col in self.itercols()]\n+   945\t            return self.__class__(data, meta=deepcopy(self.meta), copy=False)\n+   946\t        else:\n+   947\t            # Return copy of the original object.\n+   948\t            return self.copy()\n+   949\t\n+   950\t    @property\n+   951\t    def indices(self):\n+   952\t        '''\n+   953\t        Return the indices associated with columns of the table\n+   954\t        as a TableIndices object.\n+   955\t        '''\n+   956\t        lst = []\n+   957\t        for column in self.columns.values():\n+   958\t            for index in column.info.indices:\n+   959\t                if sum([index is x for x in lst]) == 0:  # ensure uniqueness\n+   960\t                    lst.append(index)\n+   961\t        return TableIndices(lst)\n+   962\t\n+   963\t    @property\n+   964\t    def loc(self):\n+   965\t        '''\n+   966\t        Return a TableLoc object that can be used for retrieving\n+   967\t        rows by index in a given data range. Note that both loc\n+   968\t        and iloc work only with single-column indices.\n+   969\t        '''\n+   970\t        return TableLoc(self)\n+   971\t\n+   972\t    @property\n+   973\t    def loc_indices(self):\n+   974\t        \"\"\"\n+   975\t        Return a TableLocIndices object that can be used for retrieving\n+   976\t        the row indices corresponding to given table index key value or values.\n+   977\t        \"\"\"\n+   978\t        return TableLocIndices(self)\n+   979\t\n+   980\t    @property\n+   981\t    def iloc(self):\n+   982\t        '''\n+   983\t        Return a TableILoc object that can be used for retrieving\n+   984\t        indexed rows in the order they appear in the index.\n+   985\t        '''\n+   986\t        return TableILoc(self)\n+   987\t\n+   988\t    def add_index(self, colnames, engine=None, unique=False):\n+   989\t        '''\n+   990\t        Insert a new index among one or more columns.\n+   991\t        If there are no indices, make this index the\n+   992\t        primary table index.\n+   993\t\n+   994\t        Parameters\n+   995\t        ----------\n+   996\t        colnames : str or list\n+   997\t            List of column names (or a single column name) to index\n+   998\t        engine : type or None\n+   999\t            Indexing engine class to use, either `~astropy.table.SortedArray`,\n+  1000\t            `~astropy.table.BST`, or `~astropy.table.SCEngine`. If the supplied\n+  1001\t            argument is None (by default), use `~astropy.table.SortedArray`.\n+  1002\t        unique : bool\n+  1003\t            Whether the values of the index must be unique. Default is False.\n+  1004\t        '''\n+  1005\t        if isinstance(colnames, str):\n+  1006\t            colnames = (colnames,)\n+  1007\t        columns = self.columns[tuple(colnames)].values()\n+  1008\t\n+  1009\t        # make sure all columns support indexing\n+  1010\t        for col in columns:\n+  1011\t            if not getattr(col.info, '_supports_indexing', False):\n+  1012\t                raise ValueError('Cannot create an index on column \"{}\", of '\n+  1013\t                                 'type \"{}\"'.format(col.info.name, type(col)))\n+  1014\t\n+  1015\t        is_primary = not self.indices\n+  1016\t        index = Index(columns, engine=engine, unique=unique)\n+  1017\t        sliced_index = SlicedIndex(index, slice(0, 0, None), original=True)\n+  1018\t        if is_primary:\n+  1019\t            self.primary_key = colnames\n+  1020\t        for col in columns:\n+  1021\t            col.info.indices.append(sliced_index)\n+  1022\t\n+  1023\t    def remove_indices(self, colname):\n+  1024\t        '''\n+  1025\t        Remove all indices involving the given column.\n+  1026\t        If the primary index is removed, the new primary\n+  1027\t        index will be the most recently added remaining\n+  1028\t        index.\n+  1029\t\n+  1030\t        Parameters\n+  1031\t        ----------\n+  1032\t        colname : str\n+  1033\t            Name of column\n+  1034\t        '''\n+  1035\t        col = self.columns[colname]\n+  1036\t        for index in self.indices:\n+  1037\t            try:\n+  1038\t                index.col_position(col.info.name)\n+  1039\t            except ValueError:\n+  1040\t                pass\n+  1041\t            else:\n+  1042\t                for c in index.columns:\n+  1043\t                    c.info.indices.remove(index)\n+  1044\t\n+  1045\t    def index_mode(self, mode):\n+  1046\t        '''\n+  1047\t        Return a context manager for an indexing mode.\n+  1048\t\n+  1049\t        Parameters\n+  1050\t        ----------\n+  1051\t        mode : str\n+  1052\t            Either 'freeze', 'copy_on_getitem', or 'discard_on_copy'.\n+  1053\t            In 'discard_on_copy' mode,\n+  1054\t            indices are not copied whenever columns or tables are copied.\n+  1055\t            In 'freeze' mode, indices are not modified whenever columns are\n+  1056\t            modified; at the exit of the context, indices refresh themselves\n+  1057\t            based on column values. This mode is intended for scenarios in\n+  1058\t            which one intends to make many additions or modifications in an\n+  1059\t            indexed column.\n+  1060\t            In 'copy_on_getitem' mode, indices are copied when taking column\n+  1061\t            slices as well as table slices, so col[i0:i1] will preserve\n+  1062\t            indices.\n+  1063\t        '''\n+  1064\t        return _IndexModeContext(self, mode)\n+  1065\t\n+  1066\t    def __array__(self, dtype=None):\n+  1067\t        \"\"\"Support converting Table to np.array via np.array(table).\n+  1068\t\n+  1069\t        Coercion to a different dtype via np.array(table, dtype) is not\n+  1070\t        supported and will raise a ValueError.\n+  1071\t        \"\"\"\n+  1072\t        if dtype is not None:\n+  1073\t            raise ValueError('Datatype coercion is not allowed')\n+  1074\t\n+  1075\t        # This limitation is because of the following unexpected result that\n+  1076\t        # should have made a table copy while changing the column names.\n+  1077\t        #\n+  1078\t        # >>> d = astropy.table.Table([[1,2],[3,4]])\n+  1079\t        # >>> np.array(d, dtype=[('a', 'i8'), ('b', 'i8')])\n+  1080\t        # array([(0, 0), (0, 0)],\n+  1081\t        #       dtype=[('a', '<i8'), ('b', '<i8')])\n+  1082\t\n+  1083\t        out = self.as_array()\n+  1084\t        return out.data if isinstance(out, np.ma.MaskedArray) else out\n+  1085\t\n+  1086\t    def _check_names_dtype(self, names, dtype, n_cols):\n+  1087\t        \"\"\"Make sure that names and dtype are both iterable and have\n+  1088\t        the same length as data.\n+  1089\t        \"\"\"\n+  1090\t        for inp_list, inp_str in ((dtype, 'dtype'), (names, 'names')):\n+  1091\t            if not isiterable(inp_list):\n+  1092\t                raise ValueError(f'{inp_str} must be a list or None')\n+  1093\t\n+  1094\t        if len(names) != n_cols or len(dtype) != n_cols:\n+  1095\t            raise ValueError(\n+  1096\t                'Arguments \"names\" and \"dtype\" must match number of columns')\n+  1097\t\n+  1098\t    def _init_from_list_of_dicts(self, data, names, dtype, n_cols, copy):\n+  1099\t        \"\"\"Initialize table from a list of dictionaries representing rows.\"\"\"\n+  1100\t        # Define placeholder for missing values as a unique object that cannot\n+  1101\t        # every occur in user data.\n+  1102\t        MISSING = object()\n+  1103\t\n+  1104\t        # Gather column names that exist in the input `data`.\n+  1105\t        names_from_data = set()\n+  1106\t        for row in data:\n+  1107\t            names_from_data.update(row)\n+  1108\t\n+  1109\t        if set(data[0].keys()) == names_from_data:\n+  1110\t            names_from_data = list(data[0].keys())\n+  1111\t        else:\n+  1112\t            names_from_data = sorted(names_from_data)\n+  1113\t\n+  1114\t        # Note: if set(data[0].keys()) != names_from_data, this will give an\n+  1115\t        # exception later, so NO need to catch here.\n+  1116\t\n+  1117\t        # Convert list of dict into dict of list (cols), keep track of missing\n+  1118\t        # indexes and put in MISSING placeholders in the `cols` lists.\n+  1119\t        cols = {}\n+  1120\t        missing_indexes = defaultdict(list)\n+  1121\t        for name in names_from_data:\n+  1122\t            cols[name] = []\n+  1123\t            for ii, row in enumerate(data):\n+  1124\t                try:\n+  1125\t                    val = row[name]\n+  1126\t                except KeyError:\n+  1127\t                    missing_indexes[name].append(ii)\n+  1128\t                    val = MISSING\n+  1129\t                cols[name].append(val)\n+  1130\t\n+  1131\t        # Fill the missing entries with first values\n+  1132\t        if missing_indexes:\n+  1133\t            for name, indexes in missing_indexes.items():\n+  1134\t                col = cols[name]\n+  1135\t                first_val = next(val for val in col if val is not MISSING)\n+  1136\t                for index in indexes:\n+  1137\t                    col[index] = first_val\n+  1138\t\n+  1139\t        # prepare initialization\n+  1140\t        if all(name is None for name in names):\n+  1141\t            names = names_from_data\n+  1142\t\n+  1143\t        self._init_from_dict(cols, names, dtype, n_cols, copy)\n+  1144\t\n+  1145\t        # Mask the missing values if necessary, converting columns to MaskedColumn\n+  1146\t        # as needed.\n+  1147\t        if missing_indexes:\n+  1148\t            for name, indexes in missing_indexes.items():\n+  1149\t                col = self[name]\n+  1150\t                # Ensure that any Column subclasses with MISSING values can support\n+  1151\t                # setting masked values. As of astropy 4.0 the test condition below is\n+  1152\t                # always True since _init_from_dict cannot result in mixin columns.\n+  1153\t                if isinstance(col, Column) and not isinstance(col, MaskedColumn):\n+  1154\t                    self[name] = self.MaskedColumn(col, copy=False)\n+  1155\t\n+  1156\t                # Finally do the masking in a mixin-safe way.\n+  1157\t                self[name][indexes] = np.ma.masked\n+  1158\t        return\n+  1159\t\n+  1160\t    def _init_from_list(self, data, names, dtype, n_cols, copy):\n+  1161\t        \"\"\"Initialize table from a list of column data.  A column can be a\n+  1162\t        Column object, np.ndarray, mixin, or any other iterable object.\n+  1163\t        \"\"\"\n+  1164\t        # Special case of initializing an empty table like `t = Table()`. No\n+  1165\t        # action required at this point.\n+  1166\t        if n_cols == 0:\n+  1167\t            return\n+  1168\t\n+  1169\t        cols = []\n+  1170\t        default_names = _auto_names(n_cols)\n+  1171\t\n+  1172\t        for col, name, default_name, dtype in zip(data, names, default_names, dtype):\n+  1173\t            col = self._convert_data_to_col(col, copy, default_name, dtype, name)\n+  1174\t\n+  1175\t            cols.append(col)\n+  1176\t\n+  1177\t        self._init_from_cols(cols)\n+  1178\t\n+  1179\t    def _convert_data_to_col(self, data, copy=True, default_name=None, dtype=None, name=None):\n+  1180\t        \"\"\"\n+  1181\t        Convert any allowed sequence data ``col`` to a column object that can be used\n+  1182\t        directly in the self.columns dict.  This could be a Column, MaskedColumn,\n+  1183\t        or mixin column.\n+  1184\t\n+  1185\t        The final column name is determined by::\n+  1186\t\n+  1187\t            name or data.info.name or def_name\n+  1188\t\n+  1189\t        If ``data`` has no ``info`` then ``name = name or def_name``.\n+  1190\t\n+  1191\t        The behavior of ``copy`` for Column objects is:\n+  1192\t        - copy=True: new class instance with a copy of data and deep copy of meta\n+  1193\t        - copy=False: new class instance with same data and a key-only copy of meta\n+  1194\t\n+  1195\t        For mixin columns:\n+  1196\t        - copy=True: new class instance with copy of data and deep copy of meta\n+  1197\t        - copy=False: original instance (no copy at all)\n+  1198\t\n+  1199\t        Parameters\n+  1200\t        ----------\n+  1201\t        data : object (column-like sequence)\n+  1202\t            Input column data\n+  1203\t        copy : bool\n+  1204\t            Make a copy\n+  1205\t        default_name : str\n+  1206\t            Default name\n+  1207\t        dtype : np.dtype or None\n+  1208\t            Data dtype\n+  1209\t        name : str or None\n+  1210\t            Column name\n+  1211\t\n+  1212\t        Returns\n+  1213\t        -------\n+  1214\t        col : Column, MaskedColumn, mixin-column type\n+  1215\t            Object that can be used as a column in self\n+  1216\t        \"\"\"\n+  1217\t\n+  1218\t        data_is_mixin = self._is_mixin_for_table(data)\n+  1219\t        masked_col_cls = (self.ColumnClass\n+  1220\t                          if issubclass(self.ColumnClass, self.MaskedColumn)\n+  1221\t                          else self.MaskedColumn)\n+  1222\t\n+  1223\t        try:\n+  1224\t            data0_is_mixin = self._is_mixin_for_table(data[0])\n+  1225\t        except Exception:\n+  1226\t            # Need broad exception, cannot predict what data[0] raises for arbitrary data\n+  1227\t            data0_is_mixin = False\n+  1228\t\n+  1229\t        # If the data is not an instance of Column or a mixin class, we can\n+  1230\t        # check the registry of mixin 'handlers' to see if the column can be\n+  1231\t        # converted to a mixin class\n+  1232\t        if (handler := get_mixin_handler(data)) is not None:\n+  1233\t            original_data = data\n+  1234\t            data = handler(data)\n+  1235\t            if not (data_is_mixin := self._is_mixin_for_table(data)):\n+  1236\t                fully_qualified_name = (original_data.__class__.__module__ + '.'\n+  1237\t                                        + original_data.__class__.__name__)\n+  1238\t                raise TypeError('Mixin handler for object of type '\n+  1239\t                                f'{fully_qualified_name} '\n+  1240\t                                'did not return a valid mixin column')\n+  1241\t\n+  1242\t        # Structured ndarray gets viewed as a mixin unless already a valid\n+  1243\t        # mixin class\n+  1244\t        if (not isinstance(data, Column) and not data_is_mixin\n+  1245\t                and isinstance(data, np.ndarray) and len(data.dtype) > 1):\n+  1246\t            import warnings\n+  1247\t            warnings.warn(\"In the future (5.2), structured arrays will be added as Columns. Please wrap data in Column.\", FutureWarning)\n+  1248\t            import warnings\n+  1249\t            warnings.warn(\"In the future (5.2), structured arrays will be added as Columns. Please wrap data in Column.\", FutureWarning)\n+  1250\t            data = data.view(NdarrayMixin)\n+  1251\t            data_is_mixin = True\n+  1252\t\n+  1253\t        # Get the final column name using precedence.  Some objects may not\n+  1254\t        # have an info attribute. Also avoid creating info as a side effect.\n+  1255\t        if not name:\n+  1256\t            if isinstance(data, Column):\n+  1257\t                name = data.name or default_name\n+  1258\t            elif 'info' in getattr(data, '__dict__', ()):\n+  1259\t                name = data.info.name or default_name\n+  1260\t            else:\n+  1261\t                name = default_name\n+  1262\t\n+  1263\t        if isinstance(data, Column):\n+  1264\t            # If self.ColumnClass is a subclass of col, then \"upgrade\" to ColumnClass,\n+  1265\t            # otherwise just use the original class.  The most common case is a\n+  1266\t            # table with masked=True and ColumnClass=MaskedColumn.  Then a Column\n+  1267\t            # gets upgraded to MaskedColumn, but the converse (pre-4.0) behavior\n+  1268\t            # of downgrading from MaskedColumn to Column (for non-masked table)\n+  1269\t            # does not happen.\n+  1270\t            col_cls = self._get_col_cls_for_table(data)\n+  1271\t\n+  1272\t        elif data_is_mixin:\n+  1273\t            # Copy the mixin column attributes if they exist since the copy below\n+  1274\t            # may not get this attribute.\n+  1275\t            col = col_copy(data, copy_indices=self._init_indices) if copy else data\n+  1276\t            col.info.name = name\n+  1277\t            return col\n+  1278\t\n+  1279\t        elif data0_is_mixin:\n+  1280\t            # Handle case of a sequence of a mixin, e.g. [1*u.m, 2*u.m].\n+  1281\t            try:\n+  1282\t                col = data[0].__class__(data)\n+  1283\t                col.info.name = name\n+  1284\t                return col\n+  1285\t            except Exception:\n+  1286\t                # If that didn't work for some reason, just turn it into np.array of object\n+  1287\t                data = np.array(data, dtype=object)\n+  1288\t                col_cls = self.ColumnClass\n+  1289\t\n+  1290\t        elif isinstance(data, (np.ma.MaskedArray, Masked)):\n+  1291\t            # Require that col_cls be a subclass of MaskedColumn, remembering\n+  1292\t            # that ColumnClass could be a user-defined subclass (though more-likely\n+  1293\t            # could be MaskedColumn).\n+  1294\t            col_cls = masked_col_cls\n+  1295\t\n+  1296\t        elif data is None:\n+  1297\t            # Special case for data passed as the None object (for broadcasting\n+  1298\t            # to an object column). Need to turn data into numpy `None` scalar\n+  1299\t            # object, otherwise `Column` interprets data=None as no data instead\n+  1300\t            # of a object column of `None`.\n+  1301\t            data = np.array(None)\n+  1302\t            col_cls = self.ColumnClass\n+  1303\t\n+  1304\t        elif not hasattr(data, 'dtype'):\n+  1305\t            # `data` is none of the above, convert to numpy array or MaskedArray\n+  1306\t            # assuming only that it is a scalar or sequence or N-d nested\n+  1307\t            # sequence. This function is relatively intricate and tries to\n+  1308\t            # maintain performance for common cases while handling things like\n+  1309\t            # list input with embedded np.ma.masked entries. If `data` is a\n+  1310\t            # scalar then it gets returned unchanged so the original object gets\n+  1311\t            # passed to `Column` later.\n+  1312\t            data = _convert_sequence_data_to_array(data, dtype)\n+  1313\t            copy = False  # Already made a copy above\n+  1314\t            col_cls = masked_col_cls if isinstance(data, np.ma.MaskedArray) else self.ColumnClass\n+  1315\t\n+  1316\t        else:\n+  1317\t            col_cls = self.ColumnClass\n+  1318\t\n+  1319\t        try:\n+  1320\t            col = col_cls(name=name, data=data, dtype=dtype,\n+  1321\t                          copy=copy, copy_indices=self._init_indices)\n+  1322\t        except Exception:\n+  1323\t            # Broad exception class since we don't know what might go wrong\n+  1324\t            raise ValueError('unable to convert data to Column for Table')\n+  1325\t\n+  1326\t        col = self._convert_col_for_table(col)\n+  1327\t\n+  1328\t        return col\n+  1329\t\n+  1330\t    def _init_from_ndarray(self, data, names, dtype, n_cols, copy):\n+  1331\t        \"\"\"Initialize table from an ndarray structured array\"\"\"\n+  1332\t\n+  1333\t        data_names = data.dtype.names or _auto_names(n_cols)\n+  1334\t        struct = data.dtype.names is not None\n+  1335\t        names = [name or data_names[i] for i, name in enumerate(names)]\n+  1336\t\n+  1337\t        cols = ([data[name] for name in data_names] if struct else\n+  1338\t                [data[:, i] for i in range(n_cols)])\n+  1339\t\n+  1340\t        self._init_from_list(cols, names, dtype, n_cols, copy)\n+  1341\t\n+  1342\t    def _init_from_dict(self, data, names, dtype, n_cols, copy):\n+  1343\t        \"\"\"Initialize table from a dictionary of columns\"\"\"\n+  1344\t\n+  1345\t        data_list = [data[name] for name in names]\n+  1346\t        self._init_from_list(data_list, names, dtype, n_cols, copy)\n+  1347\t\n+  1348\t    def _get_col_cls_for_table(self, col):\n+  1349\t        \"\"\"Get the correct column class to use for upgrading any Column-like object.\n+  1350\t\n+  1351\t        For a masked table, ensure any Column-like object is a subclass\n+  1352\t        of the table MaskedColumn.\n+  1353\t\n+  1354\t        For unmasked table, ensure any MaskedColumn-like object is a subclass\n+  1355\t        of the table MaskedColumn.  If not a MaskedColumn, then ensure that any\n+  1356\t        Column-like object is a subclass of the table Column.\n+  1357\t        \"\"\"\n+  1358\t\n+  1359\t        col_cls = col.__class__\n+  1360\t\n+  1361\t        if self.masked:\n+  1362\t            if isinstance(col, Column) and not isinstance(col, self.MaskedColumn):\n+  1363\t                col_cls = self.MaskedColumn\n+  1364\t        else:\n+  1365\t            if isinstance(col, MaskedColumn):\n+  1366\t                if not isinstance(col, self.MaskedColumn):\n+  1367\t                    col_cls = self.MaskedColumn\n+  1368\t            elif isinstance(col, Column) and not isinstance(col, self.Column):\n+  1369\t                col_cls = self.Column\n+  1370\t\n+  1371\t        return col_cls\n+  1372\t\n+  1373\t    def _convert_col_for_table(self, col):\n+  1374\t        \"\"\"\n+  1375\t        Make sure that all Column objects have correct base class for this type of\n+  1376\t        Table.  For a base Table this most commonly means setting to\n+  1377\t        MaskedColumn if the table is masked.  Table subclasses like QTable\n+  1378\t        override this method.\n+  1379\t        \"\"\"\n+  1380\t        if isinstance(col, Column) and not isinstance(col, self.ColumnClass):\n+  1381\t            col_cls = self._get_col_cls_for_table(col)\n+  1382\t            if col_cls is not col.__class__:\n+  1383\t                col = col_cls(col, copy=False)\n+  1384\t\n+  1385\t        return col\n+  1386\t\n+  1387\t    def _init_from_cols(self, cols):\n+  1388\t        \"\"\"Initialize table from a list of Column or mixin objects\"\"\"\n+  1389\t\n+  1390\t        lengths = set(len(col) for col in cols)\n+  1391\t        if len(lengths) > 1:\n+  1392\t            raise ValueError(f'Inconsistent data column lengths: {lengths}')\n+  1393\t\n+  1394\t        # Make sure that all Column-based objects have correct class.  For\n+  1395\t        # plain Table this is self.ColumnClass, but for instance QTable will\n+  1396\t        # convert columns with units to a Quantity mixin.\n+  1397\t        newcols = [self._convert_col_for_table(col) for col in cols]\n+  1398\t        self._make_table_from_cols(self, newcols)\n+  1399\t\n+  1400\t        # Deduplicate indices.  It may happen that after pickling or when\n+  1401\t        # initing from an existing table that column indices which had been\n+  1402\t        # references to a single index object got *copied* into an independent\n+  1403\t        # object.  This results in duplicates which will cause downstream problems.\n+  1404\t        index_dict = {}\n+  1405\t        for col in self.itercols():\n+  1406\t            for i, index in enumerate(col.info.indices or []):\n+  1407\t                names = tuple(ind_col.info.name for ind_col in index.columns)\n+  1408\t                if names in index_dict:\n+  1409\t                    col.info.indices[i] = index_dict[names]\n+  1410\t                else:\n+  1411\t                    index_dict[names] = index\n+  1412\t\n+  1413\t    def _new_from_slice(self, slice_):\n+  1414\t        \"\"\"Create a new table as a referenced slice from self.\"\"\"\n+  1415\t\n+  1416\t        table = self.__class__(masked=self.masked)\n+  1417\t        if self.meta:\n+  1418\t            table.meta = self.meta.copy()  # Shallow copy for slice\n+  1419\t        table.primary_key = self.primary_key\n+  1420\t\n+  1421\t        newcols = []\n+  1422\t        for col in self.columns.values():\n+  1423\t            newcol = col[slice_]\n+  1424\t\n+  1425\t            # Note in line below, use direct attribute access to col.indices for Column\n+  1426\t            # instances instead of the generic col.info.indices.  This saves about 4 usec\n+  1427\t            # per column.\n+  1428\t            if (col if isinstance(col, Column) else col.info).indices:\n+  1429\t                # TODO : as far as I can tell the only purpose of setting _copy_indices\n+  1430\t                # here is to communicate that to the initial test in `slice_indices`.\n+  1431\t                # Why isn't that just sent as an arg to the function?\n+  1432\t                col.info._copy_indices = self._copy_indices\n+  1433\t                newcol = col.info.slice_indices(newcol, slice_, len(col))\n+  1434\t\n+  1435\t                # Don't understand why this is forcing a value on the original column.\n+  1436\t                # Normally col.info does not even have a _copy_indices attribute.  Tests\n+  1437\t                # still pass if this line is deleted.  (Each col.info attribute access\n+  1438\t                # is expensive).\n+  1439\t                col.info._copy_indices = True\n+  1440\t\n+  1441\t            newcols.append(newcol)\n+  1442\t\n+  1443\t        self._make_table_from_cols(table, newcols, verify=False, names=self.columns.keys())\n+  1444\t        return table\n+  1445\t\n+  1446\t    @staticmethod\n+  1447\t    def _make_table_from_cols(table, cols, verify=True, names=None):\n+  1448\t        \"\"\"\n+  1449\t        Make ``table`` in-place so that it represents the given list of ``cols``.\n+  1450\t        \"\"\"\n+  1451\t        if names is None:\n+  1452\t            names = [col.info.name for col in cols]\n+  1453\t\n+  1454\t        # Note: we do not test for len(names) == len(cols) if names is not None.  In that\n+  1455\t        # case the function is being called by from \"trusted\" source (e.g. right above here)\n+  1456\t        # that is assumed to provide valid inputs.  In that case verify=False.\n+  1457\t\n+  1458\t        if verify:\n+  1459\t            if None in names:\n+  1460\t                raise TypeError('Cannot have None for column name')\n+  1461\t            if len(set(names)) != len(names):\n+  1462\t                raise ValueError('Duplicate column names')\n+  1463\t\n+  1464\t        table.columns = table.TableColumns((name, col) for name, col in zip(names, cols))\n+  1465\t\n+  1466\t        for col in cols:\n+  1467\t            table._set_col_parent_table_and_mask(col)\n+  1468\t\n+  1469\t    def _set_col_parent_table_and_mask(self, col):\n+  1470\t        \"\"\"\n+  1471\t        Set ``col.parent_table = self`` and force ``col`` to have ``mask``\n+  1472\t        attribute if the table is masked and ``col.mask`` does not exist.\n+  1473\t        \"\"\"\n+  1474\t        # For Column instances it is much faster to do direct attribute access\n+  1475\t        # instead of going through .info\n+  1476\t        col_info = col if isinstance(col, Column) else col.info\n+  1477\t        col_info.parent_table = self\n+  1478\t\n+  1479\t        # Legacy behavior for masked table\n+  1480\t        if self.masked and not hasattr(col, 'mask'):\n+  1481\t            col.mask = FalseArray(col.shape)\n+  1482\t\n+  1483\t    def itercols(self):\n+  1484\t        \"\"\"\n+  1485\t        Iterate over the columns of this table.\n+  1486\t\n+  1487\t        Examples\n+  1488\t        --------\n+  1489\t\n+  1490\t        To iterate over the columns of a table::\n+  1491\t\n+  1492\t            >>> t = Table([[1], [2]])\n+  1493\t            >>> for col in t.itercols():\n+  1494\t            ...     print(col)\n+  1495\t            col0\n+  1496\t            ----\n+  1497\t               1\n+  1498\t            col1\n+  1499\t            ----\n+  1500\t               2\n+  1501\t\n+  1502\t        Using ``itercols()`` is similar to  ``for col in t.columns.values()``\n+  1503\t        but is syntactically preferred.\n+  1504\t        \"\"\"\n+  1505\t        for colname in self.columns:\n+  1506\t            yield self[colname]\n+  1507\t\n+  1508\t    def _base_repr_(self, html=False, descr_vals=None, max_width=None,\n+  1509\t                    tableid=None, show_dtype=True, max_lines=None,\n+  1510\t                    tableclass=None):\n+  1511\t        if descr_vals is None:\n+  1512\t            descr_vals = [self.__class__.__name__]\n+  1513\t            if self.masked:\n+  1514\t                descr_vals.append('masked=True')\n+  1515\t            descr_vals.append(f'length={len(self)}')\n+  1516\t\n+  1517\t        descr = ' '.join(descr_vals)\n+  1518\t        if html:\n+  1519\t            from astropy.utils.xml.writer import xml_escape\n+  1520\t            descr = f'<i>{xml_escape(descr)}</i>\\n'\n+  1521\t        else:\n+  1522\t            descr = f'<{descr}>\\n'\n+  1523\t\n+  1524\t        if tableid is None:\n+  1525\t            tableid = f'table{id(self)}'\n+  1526\t\n+  1527\t        data_lines, outs = self.formatter._pformat_table(\n+  1528\t            self, tableid=tableid, html=html, max_width=max_width,\n+  1529\t            show_name=True, show_unit=None, show_dtype=show_dtype,\n+  1530\t            max_lines=max_lines, tableclass=tableclass)\n+  1531\t\n+  1532\t        out = descr + '\\n'.join(data_lines)\n+  1533\t\n+  1534\t        return out\n+  1535\t\n+  1536\t    def _repr_html_(self):\n+  1537\t        out = self._base_repr_(html=True, max_width=-1,\n+  1538\t                               tableclass=conf.default_notebook_table_class)\n+  1539\t        # Wrap <table> in <div>. This follows the pattern in pandas and allows\n+  1540\t        # table to be scrollable horizontally in VS Code notebook display.\n+  1541\t        out = f'<div>{out}</div>'\n+  1542\t        return out\n+  1543\t\n+  1544\t    def __repr__(self):\n+  1545\t        return self._base_repr_(html=False, max_width=None)\n+  1546\t\n+  1547\t    def __str__(self):\n+  1548\t        return '\\n'.join(self.pformat())\n+  1549\t\n+  1550\t    def __bytes__(self):\n+  1551\t        return str(self).encode('utf-8')\n+  1552\t\n+  1553\t    @property\n+  1554\t    def has_mixin_columns(self):\n+  1555\t        \"\"\"\n+  1556\t        True if table has any mixin columns (defined as columns that are not Column\n+  1557\t        subclasses).\n+  1558\t        \"\"\"\n+  1559\t        return any(has_info_class(col, MixinInfo) for col in self.columns.values())\n+  1560\t\n+  1561\t    @property\n+  1562\t    def has_masked_columns(self):\n+  1563\t        \"\"\"True if table has any ``MaskedColumn`` columns.\n+  1564\t\n+  1565\t        This does not check for mixin columns that may have masked values, use the\n+  1566\t        ``has_masked_values`` property in that case.\n+  1567\t\n+  1568\t        \"\"\"\n+  1569\t        return any(isinstance(col, MaskedColumn) for col in self.itercols())\n+  1570\t\n+  1571\t    @property\n+  1572\t    def has_masked_values(self):\n+  1573\t        \"\"\"True if column in the table has values which are masked.\n+  1574\t\n+  1575\t        This may be relatively slow for large tables as it requires checking the mask\n+  1576\t        values of each column.\n+  1577\t        \"\"\"\n+  1578\t        for col in self.itercols():\n+  1579\t            if hasattr(col, 'mask') and np.any(col.mask):\n+  1580\t                return True\n+  1581\t        else:\n+  1582\t            return False\n+  1583\t\n+  1584\t    def _is_mixin_for_table(self, col):\n+  1585\t        \"\"\"\n+  1586\t        Determine if ``col`` should be added to the table directly as\n+  1587\t        a mixin column.\n+  1588\t        \"\"\"\n+  1589\t        if isinstance(col, BaseColumn):\n+  1590\t            return False\n+  1591\t\n+  1592\t        # Is it a mixin but not [Masked]Quantity (which gets converted to\n+  1593\t        # [Masked]Column with unit set).\n+  1594\t        return has_info_class(col, MixinInfo) and not has_info_class(col, QuantityInfo)\n+  1595\t\n+  1596\t    @format_doc(_pprint_docs)\n+  1597\t    def pprint(self, max_lines=None, max_width=None, show_name=True,\n+  1598\t               show_unit=None, show_dtype=False, align=None):\n+  1599\t        \"\"\"Print a formatted string representation of the table.\n+  1600\t\n+  1601\t        If no value of ``max_lines`` is supplied then the height of the\n+  1602\t        screen terminal is used to set ``max_lines``.  If the terminal\n+  1603\t        height cannot be determined then the default is taken from the\n+  1604\t        configuration item ``astropy.conf.max_lines``.  If a negative\n+  1605\t        value of ``max_lines`` is supplied then there is no line limit\n+  1606\t        applied.\n+  1607\t\n+  1608\t        The same applies for max_width except the configuration item is\n+  1609\t        ``astropy.conf.max_width``.\n+  1610\t\n+  1611\t        \"\"\"\n+  1612\t        lines, outs = self.formatter._pformat_table(self, max_lines, max_width,\n+  1613\t                                                    show_name=show_name, show_unit=show_unit,\n+  1614\t                                                    show_dtype=show_dtype, align=align)\n+  1615\t        if outs['show_length']:\n+  1616\t            lines.append(f'Length = {len(self)} rows')\n+  1617\t\n+  1618\t        n_header = outs['n_header']\n+  1619\t\n+  1620\t        for i, line in enumerate(lines):\n+  1621\t            if i < n_header:\n+  1622\t                color_print(line, 'red')\n+  1623\t            else:\n+  1624\t                print(line)\n+  1625\t\n+  1626\t    @format_doc(_pprint_docs)\n+  1627\t    def pprint_all(self, max_lines=-1, max_width=-1, show_name=True,\n+  1628\t                   show_unit=None, show_dtype=False, align=None):\n+  1629\t        \"\"\"Print a formatted string representation of the entire table.\n+  1630\t\n+  1631\t        This method is the same as `astropy.table.Table.pprint` except that\n+  1632\t        the default ``max_lines`` and ``max_width`` are both -1 so that by\n+  1633\t        default the entire table is printed instead of restricting to the size\n+  1634\t        of the screen terminal.\n+  1635\t\n+  1636\t        \"\"\"\n+  1637\t        return self.pprint(max_lines, max_width, show_name,\n+  1638\t                           show_unit, show_dtype, align)\n+  1639\t\n+  1640\t    def _make_index_row_display_table(self, index_row_name):\n+  1641\t        if index_row_name not in self.columns:\n+  1642\t            idx_col = self.ColumnClass(name=index_row_name, data=np.arange(len(self)))\n+  1643\t            return self.__class__([idx_col] + list(self.columns.values()),\n+  1644\t                                  copy=False)\n+  1645\t        else:\n+  1646\t            return self\n+  1647\t\n+  1648\t    def show_in_notebook(self, tableid=None, css=None, display_length=50,\n+  1649\t                         table_class='astropy-default', show_row_index='idx'):\n+  1650\t        \"\"\"Render the table in HTML and show it in the IPython notebook.\n+  1651\t\n+  1652\t        Parameters\n+  1653\t        ----------\n+  1654\t        tableid : str or None\n+  1655\t            An html ID tag for the table.  Default is ``table{id}-XXX``, where\n+  1656\t            id is the unique integer id of the table object, id(self), and XXX\n+  1657\t            is a random number to avoid conflicts when printing the same table\n+  1658\t            multiple times.\n+  1659\t        table_class : str or None\n+  1660\t            A string with a list of HTML classes used to style the table.\n+  1661\t            The special default string ('astropy-default') means that the string\n+  1662\t            will be retrieved from the configuration item\n+  1663\t            ``astropy.table.default_notebook_table_class``. Note that these\n+  1664\t            table classes may make use of bootstrap, as this is loaded with the\n+  1665\t            notebook.  See `this page <https://getbootstrap.com/css/#tables>`_\n+  1666\t            for the list of classes.\n+  1667\t        css : str\n+  1668\t            A valid CSS string declaring the formatting for the table. Defaults\n+  1669\t            to ``astropy.table.jsviewer.DEFAULT_CSS_NB``.\n+  1670\t        display_length : int, optional\n+  1671\t            Number or rows to show. Defaults to 50.\n+  1672\t        show_row_index : str or False\n+  1673\t            If this does not evaluate to False, a column with the given name\n+  1674\t            will be added to the version of the table that gets displayed.\n+  1675\t            This new column shows the index of the row in the table itself,\n+  1676\t            even when the displayed table is re-sorted by another column. Note\n+  1677\t            that if a column with this name already exists, this option will be\n+  1678\t            ignored. Defaults to \"idx\".\n+  1679\t\n+  1680\t        Notes\n+  1681\t        -----\n+  1682\t        Currently, unlike `show_in_browser` (with ``jsviewer=True``), this\n+  1683\t        method needs to access online javascript code repositories.  This is due\n+  1684\t        to modern browsers' limitations on accessing local files.  Hence, if you\n+  1685\t        call this method while offline (and don't have a cached version of\n+  1686\t        jquery and jquery.dataTables), you will not get the jsviewer features.\n+  1687\t        \"\"\"\n+  1688\t\n+  1689\t        from .jsviewer import JSViewer\n+  1690\t        from IPython.display import HTML\n+  1691\t\n+  1692\t        if tableid is None:\n+  1693\t            tableid = f'table{id(self)}-{np.random.randint(1, 1e6)}'\n+  1694\t\n+  1695\t        jsv = JSViewer(display_length=display_length)\n+  1696\t        if show_row_index:\n+  1697\t            display_table = self._make_index_row_display_table(show_row_index)\n+  1698\t        else:\n+  1699\t            display_table = self\n+  1700\t        if table_class == 'astropy-default':\n+  1701\t            table_class = conf.default_notebook_table_class\n+  1702\t        html = display_table._base_repr_(html=True, max_width=-1, tableid=tableid,\n+  1703\t                                         max_lines=-1, show_dtype=False,\n+  1704\t                                         tableclass=table_class)\n+  1705\t\n+  1706\t        columns = display_table.columns.values()\n+  1707\t        sortable_columns = [i for i, col in enumerate(columns)\n+  1708\t                            if col.info.dtype.kind in 'iufc']\n+  1709\t        html += jsv.ipynb(tableid, css=css, sort_columns=sortable_columns)\n+  1710\t        return HTML(html)\n+  1711\t\n+  1712\t    def show_in_browser(self, max_lines=5000, jsviewer=False,\n+  1713\t                        browser='default', jskwargs={'use_local_files': True},\n+  1714\t                        tableid=None, table_class=\"display compact\",\n+  1715\t                        css=None, show_row_index='idx'):\n+  1716\t        \"\"\"Render the table in HTML and show it in a web browser.\n+  1717\t\n+  1718\t        Parameters\n+  1719\t        ----------\n+  1720\t        max_lines : int\n+  1721\t            Maximum number of rows to export to the table (set low by default\n+  1722\t            to avoid memory issues, since the browser view requires duplicating\n+  1723\t            the table in memory).  A negative value of ``max_lines`` indicates\n+  1724\t            no row limit.\n+  1725\t        jsviewer : bool\n+  1726\t            If `True`, prepends some javascript headers so that the table is\n+  1727\t            rendered as a `DataTables <https://datatables.net>`_ data table.\n+  1728\t            This allows in-browser searching & sorting.\n+  1729\t        browser : str\n+  1730\t            Any legal browser name, e.g. ``'firefox'``, ``'chrome'``,\n+  1731\t            ``'safari'`` (for mac, you may need to use ``'open -a\n+  1732\t            \"/Applications/Google Chrome.app\" {}'`` for Chrome).  If\n+  1733\t            ``'default'``, will use the system default browser.\n+  1734\t        jskwargs : dict\n+  1735\t            Passed to the `astropy.table.JSViewer` init. Defaults to\n+  1736\t            ``{'use_local_files': True}`` which means that the JavaScript\n+  1737\t            libraries will be served from local copies.\n+  1738\t        tableid : str or None\n+  1739\t            An html ID tag for the table.  Default is ``table{id}``, where id\n+  1740\t            is the unique integer id of the table object, id(self).\n+  1741\t        table_class : str or None\n+  1742\t            A string with a list of HTML classes used to style the table.\n+  1743\t            Default is \"display compact\", and other possible values can be\n+  1744\t            found in https://www.datatables.net/manual/styling/classes\n+  1745\t        css : str\n+  1746\t            A valid CSS string declaring the formatting for the table. Defaults\n+  1747\t            to ``astropy.table.jsviewer.DEFAULT_CSS``.\n+  1748\t        show_row_index : str or False\n+  1749\t            If this does not evaluate to False, a column with the given name\n+  1750\t            will be added to the version of the table that gets displayed.\n+  1751\t            This new column shows the index of the row in the table itself,\n+  1752\t            even when the displayed table is re-sorted by another column. Note\n+  1753\t            that if a column with this name already exists, this option will be\n+  1754\t            ignored. Defaults to \"idx\".\n+  1755\t        \"\"\"\n+  1756\t\n+  1757\t        import os\n+  1758\t        import webbrowser\n+  1759\t        import tempfile\n+  1760\t        from .jsviewer import DEFAULT_CSS\n+  1761\t        from urllib.parse import urljoin\n+  1762\t        from urllib.request import pathname2url\n+  1763\t\n+  1764\t        if css is None:\n+  1765\t            css = DEFAULT_CSS\n+  1766\t\n+  1767\t        # We can't use NamedTemporaryFile here because it gets deleted as\n+  1768\t        # soon as it gets garbage collected.\n+  1769\t        tmpdir = tempfile.mkdtemp()\n+  1770\t        path = os.path.join(tmpdir, 'table.html')\n+  1771\t\n+  1772\t        with open(path, 'w') as tmp:\n+  1773\t            if jsviewer:\n+  1774\t                if show_row_index:\n+  1775\t                    display_table = self._make_index_row_display_table(show_row_index)\n+  1776\t                else:\n+  1777\t                    display_table = self\n+  1778\t                display_table.write(tmp, format='jsviewer', css=css,\n+  1779\t                                    max_lines=max_lines, jskwargs=jskwargs,\n+  1780\t                                    table_id=tableid, table_class=table_class)\n+  1781\t            else:\n+  1782\t                self.write(tmp, format='html')\n+  1783\t\n+  1784\t        try:\n+  1785\t            br = webbrowser.get(None if browser == 'default' else browser)\n+  1786\t        except webbrowser.Error:\n+  1787\t            log.error(f\"Browser '{browser}' not found.\")\n+  1788\t        else:\n+  1789\t            br.open(urljoin('file:', pathname2url(path)))\n+  1790\t\n+  1791\t    @format_doc(_pformat_docs, id=\"{id}\")\n+  1792\t    def pformat(self, max_lines=None, max_width=None, show_name=True,\n+  1793\t                show_unit=None, show_dtype=False, html=False, tableid=None,\n+  1794\t                align=None, tableclass=None):\n+  1795\t        \"\"\"Return a list of lines for the formatted string representation of\n+  1796\t        the table.\n+  1797\t\n+  1798\t        If no value of ``max_lines`` is supplied then the height of the\n+  1799\t        screen terminal is used to set ``max_lines``.  If the terminal\n+  1800\t        height cannot be determined then the default is taken from the\n+  1801\t        configuration item ``astropy.conf.max_lines``.  If a negative\n+  1802\t        value of ``max_lines`` is supplied then there is no line limit\n+  1803\t        applied.\n+  1804\t\n+  1805\t        The same applies for ``max_width`` except the configuration item  is\n+  1806\t        ``astropy.conf.max_width``.\n+  1807\t\n+  1808\t        \"\"\"\n+  1809\t\n+  1810\t        lines, outs = self.formatter._pformat_table(\n+  1811\t            self, max_lines, max_width, show_name=show_name,\n+  1812\t            show_unit=show_unit, show_dtype=show_dtype, html=html,\n+  1813\t            tableid=tableid, tableclass=tableclass, align=align)\n+  1814\t\n+  1815\t        if outs['show_length']:\n+  1816\t            lines.append(f'Length = {len(self)} rows')\n+  1817\t\n+  1818\t        return lines\n+  1819\t\n+  1820\t    @format_doc(_pformat_docs, id=\"{id}\")\n+  1821\t    def pformat_all(self, max_lines=-1, max_width=-1, show_name=True,\n+  1822\t                    show_unit=None, show_dtype=False, html=False, tableid=None,\n+  1823\t                    align=None, tableclass=None):\n+  1824\t        \"\"\"Return a list of lines for the formatted string representation of\n+  1825\t        the entire table.\n+  1826\t\n+  1827\t        If no value of ``max_lines`` is supplied then the height of the\n+  1828\t        screen terminal is used to set ``max_lines``.  If the terminal\n+  1829\t        height cannot be determined then the default is taken from the\n+  1830\t        configuration item ``astropy.conf.max_lines``.  If a negative\n+  1831\t        value of ``max_lines`` is supplied then there is no line limit\n+  1832\t        applied.\n+  1833\t\n+  1834\t        The same applies for ``max_width`` except the configuration item  is\n+  1835\t        ``astropy.conf.max_width``.\n+  1836\t\n+  1837\t        \"\"\"\n+  1838\t\n+  1839\t        return self.pformat(max_lines, max_width, show_name,\n+  1840\t                            show_unit, show_dtype, html, tableid,\n+  1841\t                            align, tableclass)\n+  1842\t\n+  1843\t    def more(self, max_lines=None, max_width=None, show_name=True,\n+  1844\t             show_unit=None, show_dtype=False):\n+  1845\t        \"\"\"Interactively browse table with a paging interface.\n+  1846\t\n+  1847\t        Supported keys::\n+  1848\t\n+  1849\t          f, <space> : forward one page\n+  1850\t          b : back one page\n+  1851\t          r : refresh same page\n+  1852\t          n : next row\n+  1853\t          p : previous row\n+  1854\t          < : go to beginning\n+  1855\t          > : go to end\n+  1856\t          q : quit browsing\n+  1857\t          h : print this help\n+  1858\t\n+  1859\t        Parameters\n+  1860\t        ----------\n+  1861\t        max_lines : int\n+  1862\t            Maximum number of lines in table output\n+  1863\t\n+  1864\t        max_width : int or None\n+  1865\t            Maximum character width of output\n+  1866\t\n+  1867\t        show_name : bool\n+  1868\t            Include a header row for column names. Default is True.\n+  1869\t\n+  1870\t        show_unit : bool\n+  1871\t            Include a header row for unit.  Default is to show a row\n+  1872\t            for units only if one or more columns has a defined value\n+  1873\t            for the unit.\n+  1874\t\n+  1875\t        show_dtype : bool\n+  1876\t            Include a header row for column dtypes. Default is False.\n+  1877\t        \"\"\"\n+  1878\t        self.formatter._more_tabcol(self, max_lines, max_width, show_name=show_name,\n+  1879\t                                    show_unit=show_unit, show_dtype=show_dtype)\n+  1880\t\n+  1881\t    def __getitem__(self, item):\n+  1882\t        if isinstance(item, str):\n+  1883\t            return self.columns[item]\n+  1884\t        elif isinstance(item, (int, np.integer)):\n+  1885\t            return self.Row(self, item)\n+  1886\t        elif (isinstance(item, np.ndarray) and item.shape == () and item.dtype.kind == 'i'):\n+  1887\t            return self.Row(self, item.item())\n+  1888\t        elif self._is_list_or_tuple_of_str(item):\n+  1889\t            out = self.__class__([self[x] for x in item],\n+  1890\t                                 copy_indices=self._copy_indices)\n+  1891\t            out._groups = groups.TableGroups(out, indices=self.groups._indices,\n+  1892\t                                             keys=self.groups._keys)\n+  1893\t            out.meta = self.meta.copy()  # Shallow copy for meta\n+  1894\t            return out\n+  1895\t        elif ((isinstance(item, np.ndarray) and item.size == 0)\n+  1896\t              or (isinstance(item, (tuple, list)) and not item)):\n+  1897\t            # If item is an empty array/list/tuple then return the table with no rows\n+  1898\t            return self._new_from_slice([])\n+  1899\t        elif (isinstance(item, slice)\n+  1900\t              or isinstance(item, np.ndarray)\n+  1901\t              or isinstance(item, list)\n+  1902\t              or isinstance(item, tuple) and all(isinstance(x, np.ndarray)\n+  1903\t                                                 for x in item)):\n+  1904\t            # here for the many ways to give a slice; a tuple of ndarray\n+  1905\t            # is produced by np.where, as in t[np.where(t['a'] > 2)]\n+  1906\t            # For all, a new table is constructed with slice of all columns\n+  1907\t            return self._new_from_slice(item)\n+  1908\t        else:\n+  1909\t            raise ValueError(f'Illegal type {type(item)} for table item access')\n+  1910\t\n+  1911\t    def __setitem__(self, item, value):\n+  1912\t        # If the item is a string then it must be the name of a column.\n+  1913\t        # If that column doesn't already exist then create it now.\n+  1914\t        if isinstance(item, str) and item not in self.colnames:\n+  1915\t            self.add_column(value, name=item, copy=True)\n+  1916\t\n+  1917\t        else:\n+  1918\t            n_cols = len(self.columns)\n+  1919\t\n+  1920\t            if isinstance(item, str):\n+  1921\t                # Set an existing column by first trying to replace, and if\n+  1922\t                # this fails do an in-place update.  See definition of mask\n+  1923\t                # property for discussion of the _setitem_inplace attribute.\n+  1924\t                if (not getattr(self, '_setitem_inplace', False)\n+  1925\t                        and not conf.replace_inplace):\n+  1926\t                    try:\n+  1927\t                        self._replace_column_warnings(item, value)\n+  1928\t                        return\n+  1929\t                    except Exception:\n+  1930\t                        pass\n+  1931\t                self.columns[item][:] = value\n+  1932\t\n+  1933\t            elif isinstance(item, (int, np.integer)):\n+  1934\t                self._set_row(idx=item, colnames=self.colnames, vals=value)\n+  1935\t\n+  1936\t            elif (isinstance(item, slice)\n+  1937\t                  or isinstance(item, np.ndarray)\n+  1938\t                  or isinstance(item, list)\n+  1939\t                  or (isinstance(item, tuple)  # output from np.where\n+  1940\t                      and all(isinstance(x, np.ndarray) for x in item))):\n+  1941\t\n+  1942\t                if isinstance(value, Table):\n+  1943\t                    vals = (col for col in value.columns.values())\n+  1944\t\n+  1945\t                elif isinstance(value, np.ndarray) and value.dtype.names:\n+  1946\t                    vals = (value[name] for name in value.dtype.names)\n+  1947\t\n+  1948\t                elif np.isscalar(value):\n+  1949\t                    vals = itertools.repeat(value, n_cols)\n+  1950\t\n+  1951\t                else:  # Assume this is an iterable that will work\n+  1952\t                    if len(value) != n_cols:\n+  1953\t                        raise ValueError('Right side value needs {} elements (one for each column)'\n+  1954\t                                         .format(n_cols))\n+  1955\t                    vals = value\n+  1956\t\n+  1957\t                for col, val in zip(self.columns.values(), vals):\n+  1958\t                    col[item] = val\n+  1959\t\n+  1960\t            else:\n+  1961\t                raise ValueError(f'Illegal type {type(item)} for table item access')\n+  1962\t\n+  1963\t    def __delitem__(self, item):\n+  1964\t        if isinstance(item, str):\n+  1965\t            self.remove_column(item)\n+  1966\t        elif isinstance(item, (int, np.integer)):\n+  1967\t            self.remove_row(item)\n+  1968\t        elif (isinstance(item, (list, tuple, np.ndarray))\n+  1969\t              and all(isinstance(x, str) for x in item)):\n+  1970\t            self.remove_columns(item)\n+  1971\t        elif (isinstance(item, (list, np.ndarray))\n+  1972\t              and np.asarray(item).dtype.kind == 'i'):\n+  1973\t            self.remove_rows(item)\n+  1974\t        elif isinstance(item, slice):\n+  1975\t            self.remove_rows(item)\n+  1976\t        else:\n+  1977\t            raise IndexError('illegal key or index value')\n+  1978\t\n+  1979\t    def _ipython_key_completions_(self):\n+  1980\t        return self.colnames\n+  1981\t\n+  1982\t    def field(self, item):\n+  1983\t        \"\"\"Return column[item] for recarray compatibility.\"\"\"\n+  1984\t        return self.columns[item]\n+  1985\t\n+  1986\t    @property\n+  1987\t    def masked(self):\n+  1988\t        return self._masked\n+  1989\t\n+  1990\t    @masked.setter\n+  1991\t    def masked(self, masked):\n+  1992\t        raise Exception('Masked attribute is read-only (use t = Table(t, masked=True)'\n+  1993\t                        ' to convert to a masked table)')\n+  1994\t\n+  1995\t    def _set_masked(self, masked):\n+  1996\t        \"\"\"\n+  1997\t        Set the table masked property.\n+  1998\t\n+  1999\t        Parameters\n+  2000\t        ----------\n+  2001\t        masked : bool\n+  2002\t            State of table masking (`True` or `False`)\n+  2003\t        \"\"\"\n+  2004\t        if masked in [True, False, None]:\n+  2005\t            self._masked = masked\n+  2006\t        else:\n+  2007\t            raise ValueError(\"masked should be one of True, False, None\")\n+  2008\t\n+  2009\t        self._column_class = self.MaskedColumn if self._masked else self.Column\n+  2010\t\n+  2011\t    @property\n+  2012\t    def ColumnClass(self):\n+  2013\t        if self._column_class is None:\n+  2014\t            return self.Column\n+  2015\t        else:\n+  2016\t            return self._column_class\n+  2017\t\n+  2018\t    @property\n+  2019\t    def dtype(self):\n+  2020\t        return np.dtype([descr(col) for col in self.columns.values()])\n+  2021\t\n+  2022\t    @property\n+  2023\t    def colnames(self):\n+  2024\t        return list(self.columns.keys())\n+  2025\t\n+  2026\t    @staticmethod\n+  2027\t    def _is_list_or_tuple_of_str(names):\n+  2028\t        \"\"\"Check that ``names`` is a tuple or list of strings\"\"\"\n+  2029\t        return (isinstance(names, (tuple, list)) and names\n+  2030\t                and all(isinstance(x, str) for x in names))\n+  2031\t\n+  2032\t    def keys(self):\n+  2033\t        return list(self.columns.keys())\n+  2034\t\n+  2035\t    def values(self):\n+  2036\t        return self.columns.values()\n+  2037\t\n+  2038\t    def items(self):\n+  2039\t        return self.columns.items()\n+  2040\t\n+  2041\t    def __len__(self):\n+  2042\t        # For performance reasons (esp. in Row) cache the first column name\n+  2043\t        # and use that subsequently for the table length.  If might not be\n+  2044\t        # available yet or the column might be gone now, in which case\n+  2045\t        # try again in the except block.\n+  2046\t        try:\n+  2047\t            return len(OrderedDict.__getitem__(self.columns, self._first_colname))\n+  2048\t        except (AttributeError, KeyError):\n+  2049\t            if len(self.columns) == 0:\n+  2050\t                return 0\n+  2051\t\n+  2052\t            # Get the first column name\n+  2053\t            self._first_colname = next(iter(self.columns))\n+  2054\t            return len(self.columns[self._first_colname])\n+  2055\t\n+  2056\t    def index_column(self, name):\n+  2057\t        \"\"\"\n+  2058\t        Return the positional index of column ``name``.\n+  2059\t\n+  2060\t        Parameters\n+  2061\t        ----------\n+  2062\t        name : str\n+  2063\t            column name\n+  2064\t\n+  2065\t        Returns\n+  2066\t        -------\n+  2067\t        index : int\n+  2068\t            Positional index of column ``name``.\n+  2069\t\n+  2070\t        Examples\n+  2071\t        --------\n+  2072\t        Create a table with three columns 'a', 'b' and 'c'::\n+  2073\t\n+  2074\t            >>> t = Table([[1, 2, 3], [0.1, 0.2, 0.3], ['x', 'y', 'z']],\n+  2075\t            ...           names=('a', 'b', 'c'))\n+  2076\t            >>> print(t)\n+  2077\t             a   b   c\n+  2078\t            --- --- ---\n+  2079\t              1 0.1   x\n+  2080\t              2 0.2   y\n+  2081\t              3 0.3   z\n+  2082\t\n+  2083\t        Get index of column 'b' of the table::\n+  2084\t\n+  2085\t            >>> t.index_column('b')\n+  2086\t            1\n+  2087\t        \"\"\"\n+  2088\t        try:\n+  2089\t            return self.colnames.index(name)\n+  2090\t        except ValueError:\n+  2091\t            raise ValueError(f\"Column {name} does not exist\")\n+  2092\t\n+  2093\t    def add_column(self, col, index=None, name=None, rename_duplicate=False, copy=True,\n+  2094\t                   default_name=None):\n+  2095\t        \"\"\"\n+  2096\t        Add a new column to the table using ``col`` as input.  If ``index``\n+  2097\t        is supplied then insert column before ``index`` position\n+  2098\t        in the list of columns, otherwise append column to the end\n+  2099\t        of the list.\n+  2100\t\n+  2101\t        The ``col`` input can be any data object which is acceptable as a\n+  2102\t        `~astropy.table.Table` column object or can be converted.  This includes\n+  2103\t        mixin columns and scalar or length=1 objects which get broadcast to match\n+  2104\t        the table length.\n+  2105\t\n+  2106\t        To add several columns at once use ``add_columns()`` or simply call\n+  2107\t        ``add_column()`` for each one.  There is very little performance difference\n+  2108\t        in the two approaches.\n+  2109\t\n+  2110\t        Parameters\n+  2111\t        ----------\n+  2112\t        col : object\n+  2113\t            Data object for the new column\n+  2114\t        index : int or None\n+  2115\t            Insert column before this position or at end (default).\n+  2116\t        name : str\n+  2117\t            Column name\n+  2118\t        rename_duplicate : bool\n+  2119\t            Uniquify column name if it already exist. Default is False.\n+  2120\t        copy : bool\n+  2121\t            Make a copy of the new column. Default is True.\n+  2122\t        default_name : str or None\n+  2123\t            Name to use if both ``name`` and ``col.info.name`` are not available.\n+  2124\t            Defaults to ``col{number_of_columns}``.\n+  2125\t\n+  2126\t        Examples\n+  2127\t        --------\n+  2128\t        Create a table with two columns 'a' and 'b', then create a third column 'c'\n+  2129\t        and append it to the end of the table::\n+  2130\t\n+  2131\t            >>> t = Table([[1, 2], [0.1, 0.2]], names=('a', 'b'))\n+  2132\t            >>> col_c = Column(name='c', data=['x', 'y'])\n+  2133\t            >>> t.add_column(col_c)\n+  2134\t            >>> print(t)\n+  2135\t             a   b   c\n+  2136\t            --- --- ---\n+  2137\t              1 0.1   x\n+  2138\t              2 0.2   y\n+  2139\t\n+  2140\t        Add column 'd' at position 1. Note that the column is inserted\n+  2141\t        before the given index::\n+  2142\t\n+  2143\t            >>> t.add_column(['a', 'b'], name='d', index=1)\n+  2144\t            >>> print(t)\n+  2145\t             a   d   b   c\n+  2146\t            --- --- --- ---\n+  2147\t              1   a 0.1   x\n+  2148\t              2   b 0.2   y\n+  2149\t\n+  2150\t        Add second column named 'b' with rename_duplicate::\n+  2151\t\n+  2152\t            >>> t = Table([[1, 2], [0.1, 0.2]], names=('a', 'b'))\n+  2153\t            >>> t.add_column(1.1, name='b', rename_duplicate=True)\n+  2154\t            >>> print(t)\n+  2155\t             a   b  b_1\n+  2156\t            --- --- ---\n+  2157\t              1 0.1 1.1\n+  2158\t              2 0.2 1.1\n+  2159\t\n+  2160\t        Add an unnamed column or mixin object in the table using a default name\n+  2161\t        or by specifying an explicit name with ``name``. Name can also be overridden::\n+  2162\t\n+  2163\t            >>> t = Table([[1, 2], [0.1, 0.2]], names=('a', 'b'))\n+  2164\t            >>> t.add_column(['a', 'b'])\n+  2165\t            >>> t.add_column(col_c, name='d')\n+  2166\t            >>> print(t)\n+  2167\t             a   b  col2  d\n+  2168\t            --- --- ---- ---\n+  2169\t              1 0.1    a   x\n+  2170\t              2 0.2    b   y\n+  2171\t        \"\"\"\n+  2172\t        if default_name is None:\n+  2173\t            default_name = f'col{len(self.columns)}'\n+  2174\t\n+  2175\t        # Convert col data to acceptable object for insertion into self.columns.\n+  2176\t        # Note that along with the lines above and below, this allows broadcasting\n+  2177\t        # of scalars to the correct shape for adding to table.\n+  2178\t        col = self._convert_data_to_col(col, name=name, copy=copy,\n+  2179\t                                        default_name=default_name)\n+  2180\t\n+  2181\t        # Assigning a scalar column to an empty table should result in an\n+  2182\t        # exception (see #3811).\n+  2183\t        if col.shape == () and len(self) == 0:\n+  2184\t            raise TypeError('Empty table cannot have column set to scalar value')\n+  2185\t        # Make col data shape correct for scalars.  The second test is to allow\n+  2186\t        # broadcasting an N-d element to a column, e.g. t['new'] = [[1, 2]].\n+  2187\t        elif (col.shape == () or col.shape[0] == 1) and len(self) > 0:\n+  2188\t            new_shape = (len(self),) + getattr(col, 'shape', ())[1:]\n+  2189\t            if isinstance(col, np.ndarray):\n+  2190\t                col = np.broadcast_to(col, shape=new_shape,\n+  2191\t                                      subok=True)\n+  2192\t            elif isinstance(col, ShapedLikeNDArray):\n+  2193\t                col = col._apply(np.broadcast_to, shape=new_shape,\n+  2194\t                                 subok=True)\n+  2195\t\n+  2196\t            # broadcast_to() results in a read-only array.  Apparently it only changes\n+  2197\t            # the view to look like the broadcasted array.  So copy.\n+  2198\t            col = col_copy(col)\n+  2199\t\n+  2200\t        name = col.info.name\n+  2201\t\n+  2202\t        # Ensure that new column is the right length\n+  2203\t        if len(self.columns) > 0 and len(col) != len(self):\n+  2204\t            raise ValueError('Inconsistent data column lengths')\n+  2205\t\n+  2206\t        if rename_duplicate:\n+  2207\t            orig_name = name\n+  2208\t            i = 1\n+  2209\t            while name in self.columns:\n+  2210\t                # Iterate until a unique name is found\n+  2211\t                name = orig_name + '_' + str(i)\n+  2212\t                i += 1\n+  2213\t            col.info.name = name\n+  2214\t\n+  2215\t        # Set col parent_table weakref and ensure col has mask attribute if table.masked\n+  2216\t        self._set_col_parent_table_and_mask(col)\n+  2217\t\n+  2218\t        # Add new column as last column\n+  2219\t        self.columns[name] = col\n+  2220\t\n+  2221\t        if index is not None:\n+  2222\t            # Move the other cols to the right of the new one\n+  2223\t            move_names = self.colnames[index:-1]\n+  2224\t            for move_name in move_names:\n+  2225\t                self.columns.move_to_end(move_name, last=True)\n+  2226\t\n+  2227\t    def add_columns(self, cols, indexes=None, names=None, copy=True, rename_duplicate=False):\n+  2228\t        \"\"\"\n+  2229\t        Add a list of new columns the table using ``cols`` data objects.  If a\n+  2230\t        corresponding list of ``indexes`` is supplied then insert column\n+  2231\t        before each ``index`` position in the *original* list of columns,\n+  2232\t        otherwise append columns to the end of the list.\n+  2233\t\n+  2234\t        The ``cols`` input can include any data objects which are acceptable as\n+  2235\t        `~astropy.table.Table` column objects or can be converted.  This includes\n+  2236\t        mixin columns and scalar or length=1 objects which get broadcast to match\n+  2237\t        the table length.\n+  2238\t\n+  2239\t        From a performance perspective there is little difference between calling\n+  2240\t        this method once or looping over the new columns and calling ``add_column()``\n+  2241\t        for each column.\n+  2242\t\n+  2243\t        Parameters\n+  2244\t        ----------\n+  2245\t        cols : list of object\n+  2246\t            List of data objects for the new columns\n+  2247\t        indexes : list of int or None\n+  2248\t            Insert column before this position or at end (default).\n+  2249\t        names : list of str\n+  2250\t            Column names\n+  2251\t        copy : bool\n+  2252\t            Make a copy of the new columns. Default is True.\n+  2253\t        rename_duplicate : bool\n+  2254\t            Uniquify new column names if they duplicate the existing ones.\n+  2255\t            Default is False.\n+  2256\t\n+  2257\t        See Also\n+  2258\t        --------\n+  2259\t        astropy.table.hstack, update, replace_column\n+  2260\t\n+  2261\t        Examples\n+  2262\t        --------\n+  2263\t        Create a table with two columns 'a' and 'b', then create columns 'c' and 'd'\n+  2264\t        and append them to the end of the table::\n+  2265\t\n+  2266\t            >>> t = Table([[1, 2], [0.1, 0.2]], names=('a', 'b'))\n+  2267\t            >>> col_c = Column(name='c', data=['x', 'y'])\n+  2268\t            >>> col_d = Column(name='d', data=['u', 'v'])\n+  2269\t            >>> t.add_columns([col_c, col_d])\n+  2270\t            >>> print(t)\n+  2271\t             a   b   c   d\n+  2272\t            --- --- --- ---\n+  2273\t              1 0.1   x   u\n+  2274\t              2 0.2   y   v\n+  2275\t\n+  2276\t        Add column 'c' at position 0 and column 'd' at position 1. Note that\n+  2277\t        the columns are inserted before the given position::\n+  2278\t\n+  2279\t            >>> t = Table([[1, 2], [0.1, 0.2]], names=('a', 'b'))\n+  2280\t            >>> t.add_columns([['x', 'y'], ['u', 'v']], names=['c', 'd'],\n+  2281\t            ...               indexes=[0, 1])\n+  2282\t            >>> print(t)\n+  2283\t             c   a   d   b\n+  2284\t            --- --- --- ---\n+  2285\t              x   1   u 0.1\n+  2286\t              y   2   v 0.2\n+  2287\t\n+  2288\t        Add second column 'b' and column 'c' with ``rename_duplicate``::\n+  2289\t\n+  2290\t            >>> t = Table([[1, 2], [0.1, 0.2]], names=('a', 'b'))\n+  2291\t            >>> t.add_columns([[1.1, 1.2], ['x', 'y']], names=('b', 'c'),\n+  2292\t            ...               rename_duplicate=True)\n+  2293\t            >>> print(t)\n+  2294\t             a   b  b_1  c\n+  2295\t            --- --- --- ---\n+  2296\t              1 0.1 1.1  x\n+  2297\t              2 0.2 1.2  y\n+  2298\t\n+  2299\t        Add unnamed columns or mixin objects in the table using default names\n+  2300\t        or by specifying explicit names with ``names``. Names can also be overridden::\n+  2301\t\n+  2302\t            >>> t = Table()\n+  2303\t            >>> col_b = Column(name='b', data=['u', 'v'])\n+  2304\t            >>> t.add_columns([[1, 2], col_b])\n+  2305\t            >>> t.add_columns([[3, 4], col_b], names=['c', 'd'])\n+  2306\t            >>> print(t)\n+  2307\t            col0  b   c   d\n+  2308\t            ---- --- --- ---\n+  2309\t               1   u   3   u\n+  2310\t               2   v   4   v\n+  2311\t        \"\"\"\n+  2312\t        if indexes is None:\n+  2313\t            indexes = [len(self.columns)] * len(cols)\n+  2314\t        elif len(indexes) != len(cols):\n+  2315\t            raise ValueError('Number of indexes must match number of cols')\n+  2316\t\n+  2317\t        if names is None:\n+  2318\t            names = (None,) * len(cols)\n+  2319\t        elif len(names) != len(cols):\n+  2320\t            raise ValueError('Number of names must match number of cols')\n+  2321\t\n+  2322\t        default_names = [f'col{ii + len(self.columns)}'\n+  2323\t                         for ii in range(len(cols))]\n+  2324\t\n+  2325\t        for ii in reversed(np.argsort(indexes)):\n+  2326\t            self.add_column(cols[ii], index=indexes[ii], name=names[ii],\n+  2327\t                            default_name=default_names[ii],\n+  2328\t                            rename_duplicate=rename_duplicate, copy=copy)\n+  2329\t\n+  2330\t    def _replace_column_warnings(self, name, col):\n+  2331\t        \"\"\"\n+  2332\t        Same as replace_column but issues warnings under various circumstances.\n+  2333\t        \"\"\"\n+  2334\t        warns = conf.replace_warnings\n+  2335\t        refcount = None\n+  2336\t        old_col = None\n+  2337\t\n+  2338\t        if 'refcount' in warns and name in self.colnames:\n+  2339\t            refcount = sys.getrefcount(self[name])\n+  2340\t\n+  2341\t        if name in self.colnames:\n+  2342\t            old_col = self[name]\n+  2343\t\n+  2344\t        # This may raise an exception (e.g. t['a'] = 1) in which case none of\n+  2345\t        # the downstream code runs.\n+  2346\t        self.replace_column(name, col)\n+  2347\t\n+  2348\t        if 'always' in warns:\n+  2349\t                warnings.warn(f\"replaced column '{name}'\",\n+  2350\t                          TableReplaceWarning, stacklevel=3)\n+  2351\t\n+  2352\t        if 'slice' in warns:\n+  2353\t            try:\n+  2354\t                # Check for ndarray-subclass slice.  An unsliced instance\n+  2355\t                # has an ndarray for the base while sliced has the same class\n+  2356\t                # as parent.\n+  2357\t                if isinstance(old_col.base, old_col.__class__):\n+  2358\t                    msg = (\"replaced column '{}' which looks like an array slice. \"\n+  2359\t                           \"The new column no longer shares memory with the \"\n+  2360\t                           \"original array.\".format(name))\n+  2361\t                        warnings.warn(msg, TableReplaceWarning, stacklevel=3)\n+  2362\t            except AttributeError:\n+  2363\t        pass\n+  2364\t\n+  2365\t        if 'refcount' in warns:\n+  2366\t            # Did reference count change?\n+  2367\t            new_refcount = sys.getrefcount(self[name])\n+  2368\t            if refcount != new_refcount:\n+  2369\t                msg = (\"replaced column '{}' and the number of references \"\n+  2370\t                       \"to the column changed.\".format(name))\n+  2371\t                    warnings.warn(msg, TableReplaceWarning, stacklevel=3)\n+  2372\t\n+  2373\t        if 'attributes' in warns:\n+  2374\t            # Any of the standard column attributes changed?\n+  2375\t            changed_attrs = []\n+  2376\t            new_col = self[name]\n+  2377\t            # Check base DataInfo attributes that any column will have\n+  2378\t            for attr in DataInfo.attr_names:\n+  2379\t                if getattr(old_col.info, attr) != getattr(new_col.info, attr):\n+  2380\t                    changed_attrs.append(attr)\n+  2381\t\n+  2382\t            if changed_attrs:\n+  2383\t                msg = (\"replaced column '{}' and column attributes {} changed.\"\n+  2384\t                       .format(name, changed_attrs))\n+  2385\t                    warnings.warn(msg, TableReplaceWarning, stacklevel=3)\n+  2386\t\n+  2387\t    def replace_column(self, name, col, copy=True):\n+  2388\t        \"\"\"\n+  2389\t        Replace column ``name`` with the new ``col`` object.\n+  2390\t\n+  2391\t        The behavior of ``copy`` for Column objects is:\n+  2392\t        - copy=True: new class instance with a copy of data and deep copy of meta\n+  2393\t        - copy=False: new class instance with same data and a key-only copy of meta\n+  2394\t\n+  2395\t        For mixin columns:\n+  2396\t        - copy=True: new class instance with copy of data and deep copy of meta\n+  2397\t        - copy=False: original instance (no copy at all)\n+  2398\t\n+  2399\t        Parameters\n+  2400\t        ----------\n+  2401\t        name : str\n+  2402\t            Name of column to replace\n+  2403\t        col : `~astropy.table.Column` or `~numpy.ndarray` or sequence\n+  2404\t            New column object to replace the existing column.\n+  2405\t        copy : bool\n+  2406\t            Make copy of the input ``col``, default=True\n+  2407\t\n+  2408\t        See Also\n+  2409\t        --------\n+  2410\t        add_columns, astropy.table.hstack, update\n+  2411\t\n+  2412\t        Examples\n+  2413\t        --------\n+  2414\t        Replace column 'a' with a float version of itself::\n+  2415\t\n+  2416\t            >>> t = Table([[1, 2, 3], [0.1, 0.2, 0.3]], names=('a', 'b'))\n+  2417\t            >>> float_a = t['a'].astype(float)\n+  2418\t            >>> t.replace_column('a', float_a)\n+  2419\t        \"\"\"\n+  2420\t        if name not in self.colnames:\n+  2421\t            raise ValueError(f'column name {name} is not in the table')\n+  2422\t\n+  2423\t        if self[name].info.indices:\n+  2424\t            raise ValueError('cannot replace a table index column')\n+  2425\t\n+  2426\t        col = self._convert_data_to_col(col, name=name, copy=copy)\n+  2427\t        self._set_col_parent_table_and_mask(col)\n+  2428\t\n+  2429\t        # Ensure that new column is the right length, unless it is the only column\n+  2430\t        # in which case re-sizing is allowed.\n+  2431\t        if len(self.columns) > 1 and len(col) != len(self[name]):\n+  2432\t            raise ValueError('length of new column must match table length')\n+  2433\t\n+  2434\t        self.columns.__setitem__(name, col, validated=True)\n+  2435\t\n+  2436\t    def remove_row(self, index):\n+  2437\t        \"\"\"\n+  2438\t        Remove a row from the table.\n+  2439\t\n+  2440\t        Parameters\n+  2441\t        ----------\n+  2442\t        index : int\n+  2443\t            Index of row to remove\n+  2444\t\n+  2445\t        Examples\n+  2446\t        --------\n+  2447\t        Create a table with three columns 'a', 'b' and 'c'::\n+  2448\t\n+  2449\t            >>> t = Table([[1, 2, 3], [0.1, 0.2, 0.3], ['x', 'y', 'z']],\n+  2450\t            ...           names=('a', 'b', 'c'))\n+  2451\t            >>> print(t)\n+  2452\t             a   b   c\n+  2453\t            --- --- ---\n+  2454\t              1 0.1   x\n+  2455\t              2 0.2   y\n+  2456\t              3 0.3   z\n+  2457\t\n+  2458\t        Remove row 1 from the table::\n+  2459\t\n+  2460\t            >>> t.remove_row(1)\n+  2461\t            >>> print(t)\n+  2462\t             a   b   c\n+  2463\t            --- --- ---\n+  2464\t              1 0.1   x\n+  2465\t              3 0.3   z\n+  2466\t\n+  2467\t        To remove several rows at the same time use remove_rows.\n+  2468\t        \"\"\"\n+  2469\t        # check the index against the types that work with np.delete\n+  2470\t        if not isinstance(index, (int, np.integer)):\n+  2471\t            raise TypeError(\"Row index must be an integer\")\n+  2472\t        self.remove_rows(index)\n+  2473\t\n+  2474\t    def remove_rows(self, row_specifier):\n+  2475\t        \"\"\"\n+  2476\t        Remove rows from the table.\n+  2477\t\n+  2478\t        Parameters\n+  2479\t        ----------\n+  2480\t        row_specifier : slice or int or array of int\n+  2481\t            Specification for rows to remove\n+  2482\t\n+  2483\t        Examples\n+  2484\t        --------\n+  2485\t        Create a table with three columns 'a', 'b' and 'c'::\n+  2486\t\n+  2487\t            >>> t = Table([[1, 2, 3], [0.1, 0.2, 0.3], ['x', 'y', 'z']],\n+  2488\t            ...           names=('a', 'b', 'c'))\n+  2489\t            >>> print(t)\n+  2490\t             a   b   c\n+  2491\t            --- --- ---\n+  2492\t              1 0.1   x\n+  2493\t              2 0.2   y\n+  2494\t              3 0.3   z\n+  2495\t\n+  2496\t        Remove rows 0 and 2 from the table::\n+  2497\t\n+  2498\t            >>> t.remove_rows([0, 2])\n+  2499\t            >>> print(t)\n+  2500\t             a   b   c\n+  2501\t            --- --- ---\n+  2502\t              2 0.2   y\n+  2503\t\n+  2504\t\n+  2505\t        Note that there are no warnings if the slice operator extends\n+  2506\t        outside the data::\n+  2507\t\n+  2508\t            >>> t = Table([[1, 2, 3], [0.1, 0.2, 0.3], ['x', 'y', 'z']],\n+  2509\t            ...           names=('a', 'b', 'c'))\n+  2510\t            >>> t.remove_rows(slice(10, 20, 1))\n+  2511\t            >>> print(t)\n+  2512\t             a   b   c\n+  2513\t            --- --- ---\n+  2514\t              1 0.1   x\n+  2515\t              2 0.2   y\n+  2516\t              3 0.3   z\n+  2517\t        \"\"\"\n+  2518\t        # Update indices\n+  2519\t        for index in self.indices:\n+  2520\t            index.remove_rows(row_specifier)\n+  2521\t\n+  2522\t        keep_mask = np.ones(len(self), dtype=bool)\n+  2523\t        keep_mask[row_specifier] = False\n+  2524\t\n+  2525\t        columns = self.TableColumns()\n+  2526\t        for name, col in self.columns.items():\n+  2527\t            newcol = col[keep_mask]\n+  2528\t            newcol.info.parent_table = self\n+  2529\t            columns[name] = newcol\n+  2530\t\n+  2531\t        self._replace_cols(columns)\n+  2532\t\n+  2533\t        # Revert groups to default (ungrouped) state\n+  2534\t        if hasattr(self, '_groups'):\n+  2535\t            del self._groups\n+  2536\t\n+  2537\t    def iterrows(self, *names):\n+  2538\t        \"\"\"\n+  2539\t        Iterate over rows of table returning a tuple of values for each row.\n+  2540\t\n+  2541\t        This method is especially useful when only a subset of columns are needed.\n+  2542\t\n+  2543\t        The ``iterrows`` method can be substantially faster than using the standard\n+  2544\t        Table row iteration (e.g. ``for row in tbl:``), since that returns a new\n+  2545\t        ``~astropy.table.Row`` object for each row and accessing a column in that\n+  2546\t        row (e.g. ``row['col0']``) is slower than tuple access.\n+  2547\t\n+  2548\t        Parameters\n+  2549\t        ----------\n+  2550\t        names : list\n+  2551\t            List of column names (default to all columns if no names provided)\n+  2552\t\n+  2553\t        Returns\n+  2554\t        -------\n+  2555\t        rows : iterable\n+  2556\t            Iterator returns tuples of row values\n+  2557\t\n+  2558\t        Examples\n+  2559\t        --------\n+  2560\t        Create a table with three columns 'a', 'b' and 'c'::\n+  2561\t\n+  2562\t            >>> t = Table({'a': [1, 2, 3],\n+  2563\t            ...            'b': [1.0, 2.5, 3.0],\n+  2564\t            ...            'c': ['x', 'y', 'z']})\n+  2565\t\n+  2566\t        To iterate row-wise using column names::\n+  2567\t\n+  2568\t            >>> for a, c in t.iterrows('a', 'c'):\n+  2569\t            ...     print(a, c)\n+  2570\t            1 x\n+  2571\t            2 y\n+  2572\t            3 z\n+  2573\t\n+  2574\t        \"\"\"\n+  2575\t        if len(names) == 0:\n+  2576\t            names = self.colnames\n+  2577\t        else:\n+  2578\t            for name in names:\n+  2579\t                if name not in self.colnames:\n+  2580\t                    raise ValueError(f'{name} is not a valid column name')\n+  2581\t\n+  2582\t        cols = (self[name] for name in names)\n+  2583\t        out = zip(*cols)\n+  2584\t        return out\n+  2585\t\n+  2586\t    def _set_of_names_in_colnames(self, names):\n+  2587\t        \"\"\"Return ``names`` as a set if valid, or raise a `KeyError`.\n+  2588\t\n+  2589\t        ``names`` is valid if all elements in it are in ``self.colnames``.\n+  2590\t        If ``names`` is a string then it is interpreted as a single column\n+  2591\t        name.\n+  2592\t        \"\"\"\n+  2593\t        names = {names} if isinstance(names, str) else set(names)\n+  2594\t        invalid_names = names.difference(self.colnames)\n+  2595\t        if len(invalid_names) == 1:\n+  2596\t            raise KeyError(f'column \"{invalid_names.pop()}\" does not exist')\n+  2597\t        elif len(invalid_names) > 1:\n+  2598\t            raise KeyError(f'columns {invalid_names} do not exist')\n+  2599\t        return names\n+  2600\t\n+  2601\t    def remove_column(self, name):\n+  2602\t        \"\"\"\n+  2603\t        Remove a column from the table.\n+  2604\t\n+  2605\t        This can also be done with::\n+  2606\t\n+  2607\t          del table[name]\n+  2608\t\n+  2609\t        Parameters\n+  2610\t        ----------\n+  2611\t        name : str\n+  2612\t            Name of column to remove\n+  2613\t\n+  2614\t        Examples\n+  2615\t        --------\n+  2616\t        Create a table with three columns 'a', 'b' and 'c'::\n+  2617\t\n+  2618\t            >>> t = Table([[1, 2, 3], [0.1, 0.2, 0.3], ['x', 'y', 'z']],\n+  2619\t            ...           names=('a', 'b', 'c'))\n+  2620\t            >>> print(t)\n+  2621\t             a   b   c\n+  2622\t            --- --- ---\n+  2623\t              1 0.1   x\n+  2624\t              2 0.2   y\n+  2625\t              3 0.3   z\n+  2626\t\n+  2627\t        Remove column 'b' from the table::\n+  2628\t\n+  2629\t            >>> t.remove_column('b')\n+  2630\t            >>> print(t)\n+  2631\t             a   c\n+  2632\t            --- ---\n+  2633\t              1   x\n+  2634\t              2   y\n+  2635\t              3   z\n+  2636\t\n+  2637\t        To remove several columns at the same time use remove_columns.\n+  2638\t        \"\"\"\n+  2639\t\n+  2640\t        self.remove_columns([name])\n+  2641\t\n+  2642\t    def remove_columns(self, names):\n+  2643\t        '''\n+  2644\t        Remove several columns from the table.\n+  2645\t\n+  2646\t        Parameters\n+  2647\t        ----------\n+  2648\t        names : str or iterable of str\n+  2649\t            Names of the columns to remove\n+  2650\t\n+  2651\t        Examples\n+  2652\t        --------\n+  2653\t        Create a table with three columns 'a', 'b' and 'c'::\n+  2654\t\n+  2655\t            >>> t = Table([[1, 2, 3], [0.1, 0.2, 0.3], ['x', 'y', 'z']],\n+  2656\t            ...     names=('a', 'b', 'c'))\n+  2657\t            >>> print(t)\n+  2658\t             a   b   c\n+  2659\t            --- --- ---\n+  2660\t              1 0.1   x\n+  2661\t              2 0.2   y\n+  2662\t              3 0.3   z\n+  2663\t\n+  2664\t        Remove columns 'b' and 'c' from the table::\n+  2665\t\n+  2666\t            >>> t.remove_columns(['b', 'c'])\n+  2667\t            >>> print(t)\n+  2668\t             a\n+  2669\t            ---\n+  2670\t              1\n+  2671\t              2\n+  2672\t              3\n+  2673\t\n+  2674\t        Specifying only a single column also works. Remove column 'b' from the table::\n+  2675\t\n+  2676\t            >>> t = Table([[1, 2, 3], [0.1, 0.2, 0.3], ['x', 'y', 'z']],\n+  2677\t            ...     names=('a', 'b', 'c'))\n+  2678\t            >>> t.remove_columns('b')\n+  2679\t            >>> print(t)\n+  2680\t             a   c\n+  2681\t            --- ---\n+  2682\t              1   x\n+  2683\t              2   y\n+  2684\t              3   z\n+  2685\t\n+  2686\t        This gives the same as using remove_column.\n+  2687\t        '''\n+  2688\t        for name in self._set_of_names_in_colnames(names):\n+  2689\t            self.columns.pop(name)\n+  2690\t\n+  2691\t    def _convert_string_dtype(self, in_kind, out_kind, encode_decode_func):\n+  2692\t        \"\"\"\n+  2693\t        Convert string-like columns to/from bytestring and unicode (internal only).\n+  2694\t\n+  2695\t        Parameters\n+  2696\t        ----------\n+  2697\t        in_kind : str\n+  2698\t            Input dtype.kind\n+  2699\t        out_kind : str\n+  2700\t            Output dtype.kind\n+  2701\t        \"\"\"\n+  2702\t\n+  2703\t        for col in self.itercols():\n+  2704\t            if col.dtype.kind == in_kind:\n+  2705\t                try:\n+  2706\t                    # This requires ASCII and is faster by a factor of up to ~8, so\n+  2707\t                    # try that first.\n+  2708\t                    newcol = col.__class__(col, dtype=out_kind)\n+  2709\t                except (UnicodeEncodeError, UnicodeDecodeError):\n+  2710\t                    newcol = col.__class__(encode_decode_func(col, 'utf-8'))\n+  2711\t\n+  2712\t                    # Quasi-manually copy info attributes.  Unfortunately\n+  2713\t                    # DataInfo.__set__ does not do the right thing in this case\n+  2714\t                    # so newcol.info = col.info does not get the old info attributes.\n+  2715\t                    for attr in col.info.attr_names - col.info._attrs_no_copy - set(['dtype']):\n+  2716\t                        value = deepcopy(getattr(col.info, attr))\n+  2717\t                        setattr(newcol.info, attr, value)\n+  2718\t\n+  2719\t                self[col.name] = newcol\n+  2720\t\n+  2721\t    def convert_bytestring_to_unicode(self):\n+  2722\t        \"\"\"\n+  2723\t        Convert bytestring columns (dtype.kind='S') to unicode (dtype.kind='U')\n+  2724\t        using UTF-8 encoding.\n+  2725\t\n+  2726\t        Internally this changes string columns to represent each character\n+  2727\t        in the string with a 4-byte UCS-4 equivalent, so it is inefficient\n+  2728\t        for memory but allows scripts to manipulate string arrays with\n+  2729\t        natural syntax.\n+  2730\t        \"\"\"\n+  2731\t        self._convert_string_dtype('S', 'U', np.char.decode)\n+  2732\t\n+  2733\t    def convert_unicode_to_bytestring(self):\n+  2734\t        \"\"\"\n+  2735\t        Convert unicode columns (dtype.kind='U') to bytestring (dtype.kind='S')\n+  2736\t        using UTF-8 encoding.\n+  2737\t\n+  2738\t        When exporting a unicode string array to a file, it may be desirable\n+  2739\t        to encode unicode columns as bytestrings.\n+  2740\t        \"\"\"\n+  2741\t        self._convert_string_dtype('U', 'S', np.char.encode)\n+  2742\t\n+  2743\t    def keep_columns(self, names):\n+  2744\t        '''\n+  2745\t        Keep only the columns specified (remove the others).\n+  2746\t\n+  2747\t        Parameters\n+  2748\t        ----------\n+  2749\t        names : str or iterable of str\n+  2750\t            The columns to keep. All other columns will be removed.\n+  2751\t\n+  2752\t        Examples\n+  2753\t        --------\n+  2754\t        Create a table with three columns 'a', 'b' and 'c'::\n+  2755\t\n+  2756\t            >>> t = Table([[1, 2, 3],[0.1, 0.2, 0.3],['x', 'y', 'z']],\n+  2757\t            ...           names=('a', 'b', 'c'))\n+  2758\t            >>> print(t)\n+  2759\t             a   b   c\n+  2760\t            --- --- ---\n+  2761\t              1 0.1   x\n+  2762\t              2 0.2   y\n+  2763\t              3 0.3   z\n+  2764\t\n+  2765\t        Keep only column 'a' of the table::\n+  2766\t\n+  2767\t            >>> t.keep_columns('a')\n+  2768\t            >>> print(t)\n+  2769\t             a\n+  2770\t            ---\n+  2771\t              1\n+  2772\t              2\n+  2773\t              3\n+  2774\t\n+  2775\t        Keep columns 'a' and 'c' of the table::\n+  2776\t\n+  2777\t            >>> t = Table([[1, 2, 3],[0.1, 0.2, 0.3],['x', 'y', 'z']],\n+  2778\t            ...           names=('a', 'b', 'c'))\n+  2779\t            >>> t.keep_columns(['a', 'c'])\n+  2780\t            >>> print(t)\n+  2781\t             a   c\n+  2782\t            --- ---\n+  2783\t              1   x\n+  2784\t              2   y\n+  2785\t              3   z\n+  2786\t        '''\n+  2787\t        names = self._set_of_names_in_colnames(names)\n+  2788\t        for colname in self.colnames:\n+  2789\t            if colname not in names:\n+  2790\t                self.columns.pop(colname)\n+  2791\t\n+  2792\t    def rename_column(self, name, new_name):\n+  2793\t        '''\n+  2794\t        Rename a column.\n+  2795\t\n+  2796\t        This can also be done directly with by setting the ``name`` attribute\n+  2797\t        for a column::\n+  2798\t\n+  2799\t          table[name].name = new_name\n+  2800\t\n+  2801\t        TODO: this won't work for mixins\n+  2802\t\n+  2803\t        Parameters\n+  2804\t        ----------\n+  2805\t        name : str\n+  2806\t            The current name of the column.\n+  2807\t        new_name : str\n+  2808\t            The new name for the column\n+  2809\t\n+  2810\t        Examples\n+  2811\t        --------\n+  2812\t        Create a table with three columns 'a', 'b' and 'c'::\n+  2813\t\n+  2814\t            >>> t = Table([[1,2],[3,4],[5,6]], names=('a','b','c'))\n+  2815\t            >>> print(t)\n+  2816\t             a   b   c\n+  2817\t            --- --- ---\n+  2818\t              1   3   5\n+  2819\t              2   4   6\n+  2820\t\n+  2821\t        Renaming column 'a' to 'aa'::\n+  2822\t\n+  2823\t            >>> t.rename_column('a' , 'aa')\n+  2824\t            >>> print(t)\n+  2825\t             aa  b   c\n+  2826\t            --- --- ---\n+  2827\t              1   3   5\n+  2828\t              2   4   6\n+  2829\t        '''\n+  2830\t\n+  2831\t        if name not in self.keys():\n+  2832\t            raise KeyError(f\"Column {name} does not exist\")\n+  2833\t\n+  2834\t        self.columns[name].info.name = new_name\n+  2835\t\n+  2836\t    def rename_columns(self, names, new_names):\n+  2837\t        '''\n+  2838\t        Rename multiple columns.\n+  2839\t\n+  2840\t        Parameters\n+  2841\t        ----------\n+  2842\t        names : list, tuple\n+  2843\t            A list or tuple of existing column names.\n+  2844\t        new_names : list, tuple\n+  2845\t            A list or tuple of new column names.\n+  2846\t\n+  2847\t        Examples\n+  2848\t        --------\n+  2849\t        Create a table with three columns 'a', 'b', 'c'::\n+  2850\t\n+  2851\t            >>> t = Table([[1,2],[3,4],[5,6]], names=('a','b','c'))\n+  2852\t            >>> print(t)\n+  2853\t              a   b   c\n+  2854\t             --- --- ---\n+  2855\t              1   3   5\n+  2856\t              2   4   6\n+  2857\t\n+  2858\t        Renaming columns 'a' to 'aa' and 'b' to 'bb'::\n+  2859\t\n+  2860\t            >>> names = ('a','b')\n+  2861\t            >>> new_names = ('aa','bb')\n+  2862\t            >>> t.rename_columns(names, new_names)\n+  2863\t            >>> print(t)\n+  2864\t             aa  bb   c\n+  2865\t            --- --- ---\n+  2866\t              1   3   5\n+  2867\t              2   4   6\n+  2868\t        '''\n+  2869\t\n+  2870\t        if not self._is_list_or_tuple_of_str(names):\n+  2871\t            raise TypeError(\"input 'names' must be a tuple or a list of column names\")\n+  2872\t\n+  2873\t        if not self._is_list_or_tuple_of_str(new_names):\n+  2874\t            raise TypeError(\"input 'new_names' must be a tuple or a list of column names\")\n+  2875\t\n+  2876\t        if len(names) != len(new_names):\n+  2877\t            raise ValueError(\"input 'names' and 'new_names' list arguments must be the same length\")\n+  2878\t\n+  2879\t        for name, new_name in zip(names, new_names):\n+  2880\t            self.rename_column(name, new_name)\n+  2881\t\n+  2882\t    def _set_row(self, idx, colnames, vals):\n+  2883\t        try:\n+  2884\t            assert len(vals) == len(colnames)\n+  2885\t        except Exception:\n+  2886\t            raise ValueError('right hand side must be a sequence of values with '\n+  2887\t                             'the same length as the number of selected columns')\n+  2888\t\n+  2889\t        # Keep track of original values before setting each column so that\n+  2890\t        # setting row can be transactional.\n+  2891\t        orig_vals = []\n+  2892\t        cols = self.columns\n+  2893\t        try:\n+  2894\t            for name, val in zip(colnames, vals):\n+  2895\t                orig_vals.append(cols[name][idx])\n+  2896\t                cols[name][idx] = val\n+  2897\t        except Exception:\n+  2898\t            # If anything went wrong first revert the row update then raise\n+  2899\t            for name, val in zip(colnames, orig_vals[:-1]):\n+  2900\t                cols[name][idx] = val\n+  2901\t            raise\n+  2902\t\n+  2903\t    def add_row(self, vals=None, mask=None):\n+  2904\t        \"\"\"Add a new row to the end of the table.\n+  2905\t\n+  2906\t        The ``vals`` argument can be:\n+  2907\t\n+  2908\t        sequence (e.g. tuple or list)\n+  2909\t            Column values in the same order as table columns.\n+  2910\t        mapping (e.g. dict)\n+  2911\t            Keys corresponding to column names.  Missing values will be\n+  2912\t            filled with np.zeros for the column dtype.\n+  2913\t        `None`\n+  2914\t            All values filled with np.zeros for the column dtype.\n+  2915\t\n+  2916\t        This method requires that the Table object \"owns\" the underlying array\n+  2917\t        data.  In particular one cannot add a row to a Table that was\n+  2918\t        initialized with copy=False from an existing array.\n+  2919\t\n+  2920\t        The ``mask`` attribute should give (if desired) the mask for the\n+  2921\t        values. The type of the mask should match that of the values, i.e. if\n+  2922\t        ``vals`` is an iterable, then ``mask`` should also be an iterable\n+  2923\t        with the same length, and if ``vals`` is a mapping, then ``mask``\n+  2924\t        should be a dictionary.\n+  2925\t\n+  2926\t        Parameters\n+  2927\t        ----------\n+  2928\t        vals : tuple, list, dict or None\n+  2929\t            Use the specified values in the new row\n+  2930\t        mask : tuple, list, dict or None\n+  2931\t            Use the specified mask values in the new row\n+  2932\t\n+  2933\t        Examples\n+  2934\t        --------\n+  2935\t        Create a table with three columns 'a', 'b' and 'c'::\n+  2936\t\n+  2937\t           >>> t = Table([[1,2],[4,5],[7,8]], names=('a','b','c'))\n+  2938\t           >>> print(t)\n+  2939\t            a   b   c\n+  2940\t           --- --- ---\n+  2941\t             1   4   7\n+  2942\t             2   5   8\n+  2943\t\n+  2944\t        Adding a new row with entries '3' in 'a', '6' in 'b' and '9' in 'c'::\n+  2945\t\n+  2946\t           >>> t.add_row([3,6,9])\n+  2947\t           >>> print(t)\n+  2948\t             a   b   c\n+  2949\t             --- --- ---\n+  2950\t             1   4   7\n+  2951\t             2   5   8\n+  2952\t             3   6   9\n+  2953\t        \"\"\"\n+  2954\t        self.insert_row(len(self), vals, mask)\n+  2955\t\n+  2956\t    def insert_row(self, index, vals=None, mask=None):\n+  2957\t        \"\"\"Add a new row before the given ``index`` position in the table.\n+  2958\t\n+  2959\t        The ``vals`` argument can be:\n+  2960\t\n+  2961\t        sequence (e.g. tuple or list)\n+  2962\t            Column values in the same order as table columns.\n+  2963\t        mapping (e.g. dict)\n+  2964\t            Keys corresponding to column names.  Missing values will be\n+  2965\t            filled with np.zeros for the column dtype.\n+  2966\t        `None`\n+  2967\t            All values filled with np.zeros for the column dtype.\n+  2968\t\n+  2969\t        The ``mask`` attribute should give (if desired) the mask for the\n+  2970\t        values. The type of the mask should match that of the values, i.e. if\n+  2971\t        ``vals`` is an iterable, then ``mask`` should also be an iterable\n+  2972\t        with the same length, and if ``vals`` is a mapping, then ``mask``\n+  2973\t        should be a dictionary.\n+  2974\t\n+  2975\t        Parameters\n+  2976\t        ----------\n+  2977\t        vals : tuple, list, dict or None\n+  2978\t            Use the specified values in the new row\n+  2979\t        mask : tuple, list, dict or None\n+  2980\t            Use the specified mask values in the new row\n+  2981\t        \"\"\"\n+  2982\t        colnames = self.colnames\n+  2983\t\n+  2984\t        N = len(self)\n+  2985\t        if index < -N or index > N:\n+  2986\t            raise IndexError(\"Index {} is out of bounds for table with length {}\"\n+  2987\t                             .format(index, N))\n+  2988\t        if index < 0:\n+  2989\t            index += N\n+  2990\t\n+  2991\t        if isinstance(vals, Mapping) or vals is None:\n+  2992\t            # From the vals and/or mask mappings create the corresponding lists\n+  2993\t            # that have entries for each table column.\n+  2994\t            if mask is not None and not isinstance(mask, Mapping):\n+  2995\t                raise TypeError(\"Mismatch between type of vals and mask\")\n+  2996\t\n+  2997\t            # Now check that the mask is specified for the same keys as the\n+  2998\t            # values, otherwise things get really confusing.\n+  2999\t            if mask is not None and set(vals.keys()) != set(mask.keys()):\n+  3000\t                raise ValueError('keys in mask should match keys in vals')\n+  3001\t\n+  3002\t            if vals and any(name not in colnames for name in vals):\n+  3003\t                raise ValueError('Keys in vals must all be valid column names')\n+  3004\t\n+  3005\t            vals_list = []\n+  3006\t            mask_list = []\n+  3007\t\n+  3008\t            for name in colnames:\n+  3009\t                if vals and name in vals:\n+  3010\t                    vals_list.append(vals[name])\n+  3011\t                    mask_list.append(False if mask is None else mask[name])\n+  3012\t                else:\n+  3013\t                    col = self[name]\n+  3014\t                    if hasattr(col, 'dtype'):\n+  3015\t                        # Make a placeholder zero element of the right type which is masked.\n+  3016\t                        # This assumes the appropriate insert() method will broadcast a\n+  3017\t                        # numpy scalar to the right shape.\n+  3018\t                        vals_list.append(np.zeros(shape=(), dtype=col.dtype))\n+  3019\t\n+  3020\t                        # For masked table any unsupplied values are masked by default.\n+  3021\t                        mask_list.append(self.masked and vals is not None)\n+  3022\t                    else:\n+  3023\t                        raise ValueError(f\"Value must be supplied for column '{name}'\")\n+  3024\t\n+  3025\t            vals = vals_list\n+  3026\t            mask = mask_list\n+  3027\t\n+  3028\t        if isiterable(vals):\n+  3029\t            if mask is not None and (not isiterable(mask) or isinstance(mask, Mapping)):\n+  3030\t                raise TypeError(\"Mismatch between type of vals and mask\")\n+  3031\t\n+  3032\t            if len(self.columns) != len(vals):\n+  3033\t                raise ValueError('Mismatch between number of vals and columns')\n+  3034\t\n+  3035\t            if mask is not None:\n+  3036\t                if len(self.columns) != len(mask):\n+  3037\t                    raise ValueError('Mismatch between number of masks and columns')\n+  3038\t            else:\n+  3039\t                mask = [False] * len(self.columns)\n+  3040\t\n+  3041\t        else:\n+  3042\t            raise TypeError('Vals must be an iterable or mapping or None')\n+  3043\t\n+  3044\t        # Insert val at index for each column\n+  3045\t        columns = self.TableColumns()\n+  3046\t        for name, col, val, mask_ in zip(colnames, self.columns.values(), vals, mask):\n+  3047\t            try:\n+  3048\t                # If new val is masked and the existing column does not support masking\n+  3049\t                # then upgrade the column to a mask-enabled type: either the table-level\n+  3050\t                # default ColumnClass or else MaskedColumn.\n+  3051\t                if mask_ and isinstance(col, Column) and not isinstance(col, MaskedColumn):\n+  3052\t                    col_cls = (self.ColumnClass\n+  3053\t                               if issubclass(self.ColumnClass, self.MaskedColumn)\n+  3054\t                               else self.MaskedColumn)\n+  3055\t                    col = col_cls(col, copy=False)\n+  3056\t\n+  3057\t                newcol = col.insert(index, val, axis=0)\n+  3058\t\n+  3059\t                if len(newcol) != N + 1:\n+  3060\t                    raise ValueError('Incorrect length for column {} after inserting {}'\n+  3061\t                                     ' (expected {}, got {})'\n+  3062\t                                     .format(name, val, len(newcol), N + 1))\n+  3063\t                newcol.info.parent_table = self\n+  3064\t\n+  3065\t                # Set mask if needed and possible\n+  3066\t                if mask_:\n+  3067\t                    if hasattr(newcol, 'mask'):\n+  3068\t                        newcol[index] = np.ma.masked\n+  3069\t                    else:\n+  3070\t                        raise TypeError(\"mask was supplied for column '{}' but it does not \"\n+  3071\t                                        \"support masked values\".format(col.info.name))\n+  3072\t\n+  3073\t                columns[name] = newcol\n+  3074\t\n+  3075\t            except Exception as err:\n+  3076\t                raise ValueError(\"Unable to insert row because of exception in column '{}':\\n{}\"\n+  3077\t                                 .format(name, err)) from err\n+  3078\t\n+  3079\t        for table_index in self.indices:\n+  3080\t            table_index.insert_row(index, vals, self.columns.values())\n+  3081\t\n+  3082\t        self._replace_cols(columns)\n+  3083\t\n+  3084\t        # Revert groups to default (ungrouped) state\n+  3085\t        if hasattr(self, '_groups'):\n+  3086\t            del self._groups\n+  3087\t\n+  3088\t    def _replace_cols(self, columns):\n+  3089\t        for col, new_col in zip(self.columns.values(), columns.values()):\n+  3090\t            new_col.info.indices = []\n+  3091\t            for index in col.info.indices:\n+  3092\t                index.columns[index.col_position(col.info.name)] = new_col\n+  3093\t                new_col.info.indices.append(index)\n+  3094\t\n+  3095\t        self.columns = columns\n+  3096\t\n+  3097\t    def update(self, other, copy=True):\n+  3098\t        \"\"\"\n+  3099\t        Perform a dictionary-style update and merge metadata.\n+  3100\t\n+  3101\t        The argument ``other`` must be a |Table|, or something that can be used\n+  3102\t        to initialize a table. Columns from (possibly converted) ``other`` are\n+  3103\t        added to this table. In case of matching column names the column from\n+  3104\t        this table is replaced with the one from ``other``.\n+  3105\t\n+  3106\t        Parameters\n+  3107\t        ----------\n+  3108\t        other : table-like\n+  3109\t            Data to update this table with.\n+  3110\t        copy : bool\n+  3111\t            Whether the updated columns should be copies of or references to\n+  3112\t            the originals.\n+  3113\t\n+  3114\t        See Also\n+  3115\t        --------\n+  3116\t        add_columns, astropy.table.hstack, replace_column\n+  3117\t\n+  3118\t        Examples\n+  3119\t        --------\n+  3120\t        Update a table with another table::\n+  3121\t\n+  3122\t            >>> t1 = Table({'a': ['foo', 'bar'], 'b': [0., 0.]}, meta={'i': 0})\n+  3123\t            >>> t2 = Table({'b': [1., 2.], 'c': [7., 11.]}, meta={'n': 2})\n+  3124\t            >>> t1.update(t2)\n+  3125\t            >>> t1\n+  3126\t            <Table length=2>\n+  3127\t             a      b       c\n+  3128\t            str3 float64 float64\n+  3129\t            ---- ------- -------\n+  3130\t             foo     1.0     7.0\n+  3131\t             bar     2.0    11.0\n+  3132\t            >>> t1.meta\n+  3133\t            {'i': 0, 'n': 2}\n+  3134\t\n+  3135\t        Update a table with a dictionary::\n+  3136\t\n+  3137\t            >>> t = Table({'a': ['foo', 'bar'], 'b': [0., 0.]})\n+  3138\t            >>> t.update({'b': [1., 2.]})\n+  3139\t            >>> t\n+  3140\t            <Table length=2>\n+  3141\t             a      b\n+  3142\t            str3 float64\n+  3143\t            ---- -------\n+  3144\t             foo     1.0\n+  3145\t             bar     2.0\n+  3146\t        \"\"\"\n+  3147\t        from .operations import _merge_table_meta\n+  3148\t        if not isinstance(other, Table):\n+  3149\t            other = self.__class__(other, copy=copy)\n+  3150\t        common_cols = set(self.colnames).intersection(other.colnames)\n+  3151\t        for name, col in other.items():\n+  3152\t            if name in common_cols:\n+  3153\t                self.replace_column(name, col, copy=copy)\n+  3154\t            else:\n+  3155\t                self.add_column(col, name=name, copy=copy)\n+  3156\t        _merge_table_meta(self, [self, other], metadata_conflicts='silent')\n+  3157\t\n+  3158\t    def argsort(self, keys=None, kind=None, reverse=False):\n+  3159\t        \"\"\"\n+  3160\t        Return the indices which would sort the table according to one or\n+  3161\t        more key columns.  This simply calls the `numpy.argsort` function on\n+  3162\t        the table with the ``order`` parameter set to ``keys``.\n+  3163\t\n+  3164\t        Parameters\n+  3165\t        ----------\n+  3166\t        keys : str or list of str\n+  3167\t            The column name(s) to order the table by\n+  3168\t        kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, optional\n+  3169\t            Sorting algorithm used by ``numpy.argsort``.\n+  3170\t        reverse : bool\n+  3171\t            Sort in reverse order (default=False)\n+  3172\t\n+  3173\t        Returns\n+  3174\t        -------\n+  3175\t        index_array : ndarray, int\n+  3176\t            Array of indices that sorts the table by the specified key\n+  3177\t            column(s).\n+  3178\t        \"\"\"\n+  3179\t        if isinstance(keys, str):\n+  3180\t            keys = [keys]\n+  3181\t\n+  3182\t        # use index sorted order if possible\n+  3183\t        if keys is not None:\n+  3184\t            index = get_index(self, names=keys)\n+  3185\t            if index is not None:\n+  3186\t                idx = np.asarray(index.sorted_data())\n+  3187\t                return idx[::-1] if reverse else idx\n+  3188\t\n+  3189\t        kwargs = {}\n+  3190\t        if keys:\n+  3191\t            # For multiple keys return a structured array which gets sorted,\n+  3192\t            # while for a single key return a single ndarray.  Sorting a\n+  3193\t            # one-column structured array is slower than ndarray (e.g. a\n+  3194\t            # factor of ~6 for a 10 million long random array), and much slower\n+  3195\t            # for in principle sortable columns like Time, which get stored as\n+  3196\t            # object arrays.\n+  3197\t            if len(keys) > 1:\n+  3198\t                kwargs['order'] = keys\n+  3199\t                data = self.as_array(names=keys)\n+  3200\t            else:\n+  3201\t                data = self[keys[0]]\n+  3202\t        else:\n+  3203\t            # No keys provided so sort on all columns.\n+  3204\t            data = self.as_array()\n+  3205\t\n+  3206\t        if kind:\n+  3207\t            kwargs['kind'] = kind\n+  3208\t\n+  3209\t        # np.argsort will look for a possible .argsort method (e.g., for Time),\n+  3210\t        # and if that fails cast to an array and try sorting that way.\n+  3211\t        idx = np.argsort(data, **kwargs)\n+  3212\t\n+  3213\t        return idx[::-1] if reverse else idx\n+  3214\t\n+  3215\t    def sort(self, keys=None, *, kind=None, reverse=False):\n+  3216\t        '''\n+  3217\t        Sort the table according to one or more keys. This operates\n+  3218\t        on the existing table and does not return a new table.\n+  3219\t\n+  3220\t        Parameters\n+  3221\t        ----------\n+  3222\t        keys : str or list of str\n+  3223\t            The key(s) to order the table by. If None, use the\n+  3224\t            primary index of the Table.\n+  3225\t        kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, optional\n+  3226\t            Sorting algorithm used by ``numpy.argsort``.\n+  3227\t        reverse : bool\n+  3228\t            Sort in reverse order (default=False)\n+  3229\t\n+  3230\t        Examples\n+  3231\t        --------\n+  3232\t        Create a table with 3 columns::\n+  3233\t\n+  3234\t            >>> t = Table([['Max', 'Jo', 'John'], ['Miller', 'Miller', 'Jackson'],\n+  3235\t            ...            [12, 15, 18]], names=('firstname', 'name', 'tel'))\n+  3236\t            >>> print(t)\n+  3237\t            firstname   name  tel\n+  3238\t            --------- ------- ---\n+  3239\t                  Max  Miller  12\n+  3240\t                   Jo  Miller  15\n+  3241\t                 John Jackson  18\n+  3242\t\n+  3243\t        Sorting according to standard sorting rules, first 'name' then 'firstname'::\n+  3244\t\n+  3245\t            >>> t.sort(['name', 'firstname'])\n+  3246\t            >>> print(t)\n+  3247\t            firstname   name  tel\n+  3248\t            --------- ------- ---\n+  3249\t                 John Jackson  18\n+  3250\t                   Jo  Miller  15\n+  3251\t                  Max  Miller  12\n+  3252\t\n+  3253\t        Sorting according to standard sorting rules, first 'firstname' then 'tel',\n+  3254\t        in reverse order::\n+  3255\t\n+  3256\t            >>> t.sort(['firstname', 'tel'], reverse=True)\n+  3257\t            >>> print(t)\n+  3258\t            firstname   name  tel\n+  3259\t            --------- ------- ---\n+  3260\t                  Max  Miller  12\n+  3261\t                 John Jackson  18\n+  3262\t                   Jo  Miller  15\n+  3263\t        '''\n+  3264\t        if keys is None:\n+  3265\t            if not self.indices:\n+  3266\t                raise ValueError(\"Table sort requires input keys or a table index\")\n+  3267\t            keys = [x.info.name for x in self.indices[0].columns]\n+  3268\t\n+  3269\t        if isinstance(keys, str):\n+  3270\t            keys = [keys]\n+  3271\t\n+  3272\t        indexes = self.argsort(keys, kind=kind, reverse=reverse)\n+  3273\t\n+  3274\t        with self.index_mode('freeze'):\n+  3275\t            for name, col in self.columns.items():\n+  3276\t                # Make a new sorted column.  This requires that take() also copies\n+  3277\t                # relevant info attributes for mixin columns.\n+  3278\t                new_col = col.take(indexes, axis=0)\n+  3279\t\n+  3280\t                # First statement in try: will succeed if the column supports an in-place\n+  3281\t                # update, and matches the legacy behavior of astropy Table.  However,\n+  3282\t                # some mixin classes may not support this, so in that case just drop\n+  3283\t                # in the entire new column. See #9553 and #9536 for discussion.\n+  3284\t                try:\n+  3285\t                    col[:] = new_col\n+  3286\t                except Exception:\n+  3287\t                    # In-place update failed for some reason, exception class not\n+  3288\t                    # predictable for arbitrary mixin.\n+  3289\t                    self[col.info.name] = new_col\n+  3290\t\n+  3291\t    def reverse(self):\n+  3292\t        '''\n+  3293\t        Reverse the row order of table rows.  The table is reversed\n+  3294\t        in place and there are no function arguments.\n+  3295\t\n+  3296\t        Examples\n+  3297\t        --------\n+  3298\t        Create a table with three columns::\n+  3299\t\n+  3300\t            >>> t = Table([['Max', 'Jo', 'John'], ['Miller','Miller','Jackson'],\n+  3301\t            ...         [12,15,18]], names=('firstname','name','tel'))\n+  3302\t            >>> print(t)\n+  3303\t            firstname   name  tel\n+  3304\t            --------- ------- ---\n+  3305\t                  Max  Miller  12\n+  3306\t                   Jo  Miller  15\n+  3307\t                 John Jackson  18\n+  3308\t\n+  3309\t        Reversing order::\n+  3310\t\n+  3311\t            >>> t.reverse()\n+  3312\t            >>> print(t)\n+  3313\t            firstname   name  tel\n+  3314\t            --------- ------- ---\n+  3315\t                 John Jackson  18\n+  3316\t                   Jo  Miller  15\n+  3317\t                  Max  Miller  12\n+  3318\t        '''\n+  3319\t        for col in self.columns.values():\n+  3320\t            # First statement in try: will succeed if the column supports an in-place\n+  3321\t            # update, and matches the legacy behavior of astropy Table.  However,\n+  3322\t            # some mixin classes may not support this, so in that case just drop\n+  3323\t            # in the entire new column. See #9836, #9553, and #9536 for discussion.\n+  3324\t            new_col = col[::-1]\n+  3325\t            try:\n+  3326\t                col[:] = new_col\n+  3327\t            except Exception:\n+  3328\t                # In-place update failed for some reason, exception class not\n+  3329\t                # predictable for arbitrary mixin.\n+  3330\t                self[col.info.name] = new_col\n+  3331\t\n+  3332\t        for index in self.indices:\n+  3333\t            index.reverse()\n+  3334\t\n+  3335\t    def round(self, decimals=0):\n+  3336\t        '''\n+  3337\t        Round numeric columns in-place to the specified number of decimals.\n+  3338\t        Non-numeric columns will be ignored.\n+  3339\t\n+  3340\t        Examples\n+  3341\t        --------\n+  3342\t        Create three columns with different types:\n+  3343\t\n+  3344\t            >>> t = Table([[1, 4, 5], [-25.55, 12.123, 85],\n+  3345\t            ...     ['a', 'b', 'c']], names=('a', 'b', 'c'))\n+  3346\t            >>> print(t)\n+  3347\t             a    b     c\n+  3348\t            --- ------ ---\n+  3349\t              1 -25.55   a\n+  3350\t              4 12.123   b\n+  3351\t              5   85.0   c\n+  3352\t\n+  3353\t        Round them all to 0:\n+  3354\t\n+  3355\t            >>> t.round(0)\n+  3356\t            >>> print(t)\n+  3357\t             a    b    c\n+  3358\t            --- ----- ---\n+  3359\t              1 -26.0   a\n+  3360\t              4  12.0   b\n+  3361\t              5  85.0   c\n+  3362\t\n+  3363\t        Round column 'a' to -1 decimal:\n+  3364\t\n+  3365\t            >>> t.round({'a':-1})\n+  3366\t            >>> print(t)\n+  3367\t             a    b    c\n+  3368\t            --- ----- ---\n+  3369\t              0 -26.0   a\n+  3370\t              0  12.0   b\n+  3371\t              0  85.0   c\n+  3372\t\n+  3373\t        Parameters\n+  3374\t        ----------\n+  3375\t        decimals: int, dict\n+  3376\t            Number of decimals to round the columns to. If a dict is given,\n+  3377\t            the columns will be rounded to the number specified as the value.\n+  3378\t            If a certain column is not in the dict given, it will remain the\n+  3379\t            same.\n+  3380\t        '''\n+  3381\t        if isinstance(decimals, Mapping):\n+  3382\t            decimal_values = decimals.values()\n+  3383\t            column_names = decimals.keys()\n+  3384\t        elif isinstance(decimals, int):\n+  3385\t            decimal_values = itertools.repeat(decimals)\n+  3386\t            column_names = self.colnames\n+  3387\t        else:\n+  3388\t            raise ValueError(\"'decimals' argument must be an int or a dict\")\n+  3389\t\n+  3390\t        for colname, decimal in zip(column_names, decimal_values):\n+  3391\t            col = self.columns[colname]\n+  3392\t            if np.issubdtype(col.info.dtype, np.number):\n+  3393\t                try:\n+  3394\t                    np.around(col, decimals=decimal, out=col)\n+  3395\t                except TypeError:\n+  3396\t                    # Bug in numpy see https://github.com/numpy/numpy/issues/15438\n+  3397\t                    col[()] = np.around(col, decimals=decimal)\n+  3398\t\n+  3399\t    def copy(self, copy_data=True):\n+  3400\t        '''\n+  3401\t        Return a copy of the table.\n+  3402\t\n+  3403\t        Parameters\n+  3404\t        ----------\n+  3405\t        copy_data : bool\n+  3406\t            If `True` (the default), copy the underlying data array.\n+  3407\t            Otherwise, use the same data array. The ``meta`` is always\n+  3408\t            deepcopied regardless of the value for ``copy_data``.\n+  3409\t        '''\n+  3410\t        out = self.__class__(self, copy=copy_data)\n+  3411\t\n+  3412\t        # If the current table is grouped then do the same in the copy\n+  3413\t        if hasattr(self, '_groups'):\n+  3414\t            out._groups = groups.TableGroups(out, indices=self._groups._indices,\n+  3415\t                                             keys=self._groups._keys)\n+  3416\t        return out\n+  3417\t\n+  3418\t    def __deepcopy__(self, memo=None):\n+  3419\t        return self.copy(True)\n+  3420\t\n+  3421\t    def __copy__(self):\n+  3422\t        return self.copy(False)\n+  3423\t\n+  3424\t    def __lt__(self, other):\n+  3425\t        return super().__lt__(other)\n+  3426\t\n+  3427\t    def __gt__(self, other):\n+  3428\t        return super().__gt__(other)\n+  3429\t\n+  3430\t    def __le__(self, other):\n+  3431\t        return super().__le__(other)\n+  3432\t\n+  3433\t    def __ge__(self, other):\n+  3434\t        return super().__ge__(other)\n+  3435\t\n+  3436\t    def __eq__(self, other):\n+  3437\t        return self._rows_equal(other)\n+  3438\t\n+  3439\t    def __ne__(self, other):\n+  3440\t        return ~self.__eq__(other)\n+  3441\t\n+  3442\t    def _rows_equal(self, other):\n+  3443\t        \"\"\"\n+  3444\t        Row-wise comparison of table with any other object.\n+  3445\t\n+  3446\t        This is actual implementation for __eq__.\n+  3447\t\n+  3448\t        Returns a 1-D boolean numpy array showing result of row-wise comparison.\n+  3449\t        This is the same as the ``==`` comparison for tables.\n+  3450\t\n+  3451\t        Parameters\n+  3452\t        ----------\n+  3453\t        other : Table or DataFrame or ndarray\n+  3454\t             An object to compare with table\n+  3455\t\n+  3456\t        Examples\n+  3457\t        --------\n+  3458\t        Comparing one Table with other::\n+  3459\t\n+  3460\t            >>> t1 = Table([[1,2],[4,5],[7,8]], names=('a','b','c'))\n+  3461\t            >>> t2 = Table([[1,2],[4,5],[7,8]], names=('a','b','c'))\n+  3462\t            >>> t1._rows_equal(t2)\n+  3463\t            array([ True,  True])\n+  3464\t\n+  3465\t        \"\"\"\n+  3466\t\n+  3467\t        if isinstance(other, Table):\n+  3468\t            other = other.as_array()\n+  3469\t\n+  3470\t        if self.has_masked_columns:\n+  3471\t            if isinstance(other, np.ma.MaskedArray):\n+  3472\t                result = self.as_array() == other\n+  3473\t            else:\n+  3474\t                # If mask is True, then by definition the row doesn't match\n+  3475\t                # because the other array is not masked.\n+  3476\t                false_mask = np.zeros(1, dtype=[(n, bool) for n in self.dtype.names])\n+  3477\t                result = (self.as_array().data == other) & (self.mask == false_mask)\n+  3478\t        else:\n+  3479\t            if isinstance(other, np.ma.MaskedArray):\n+  3480\t                # If mask is True, then by definition the row doesn't match\n+  3481\t                # because the other array is not masked.\n+  3482\t                false_mask = np.zeros(1, dtype=[(n, bool) for n in other.dtype.names])\n+  3483\t                result = (self.as_array() == other.data) & (other.mask == false_mask)\n+  3484\t            else:\n+  3485\t                result = self.as_array() == other\n+  3486\t\n+  3487\t        return result\n+  3488\t\n+  3489\t    def values_equal(self, other):\n+  3490\t        \"\"\"\n+  3491\t        Element-wise comparison of table with another table, list, or scalar.\n+  3492\t\n+  3493\t        Returns a ``Table`` with the same columns containing boolean values\n+  3494\t        showing result of comparison.\n+  3495\t\n+  3496\t        Parameters\n+  3497\t        ----------\n+  3498\t        other : table-like object or list or scalar\n+  3499\t             Object to compare with table\n+  3500\t\n+  3501\t        Examples\n+  3502\t        --------\n+  3503\t        Compare one Table with other::\n+  3504\t\n+  3505\t          >>> t1 = Table([[1, 2], [4, 5], [-7, 8]], names=('a', 'b', 'c'))\n+  3506\t          >>> t2 = Table([[1, 2], [-4, 5], [7, 8]], names=('a', 'b', 'c'))\n+  3507\t          >>> t1.values_equal(t2)\n+  3508\t          <Table length=2>\n+  3509\t           a     b     c\n+  3510\t          bool  bool  bool\n+  3511\t          ---- ----- -----\n+  3512\t          True False False\n+  3513\t          True  True  True\n+  3514\t\n+  3515\t        \"\"\"\n+  3516\t        if isinstance(other, Table):\n+  3517\t            names = other.colnames\n+  3518\t        else:\n+  3519\t            try:\n+  3520\t                other = Table(other, copy=False)\n+  3521\t                names = other.colnames\n+  3522\t            except Exception:\n+  3523\t                # Broadcast other into a dict, so e.g. other = 2 will turn into\n+  3524\t                # other = {'a': 2, 'b': 2} and then equality does a\n+  3525\t                # column-by-column broadcasting.\n+  3526\t                names = self.colnames\n+  3527\t                other = {name: other for name in names}\n+  3528\t\n+  3529\t        # Require column names match but do not require same column order\n+  3530\t        if set(self.colnames) != set(names):\n+  3531\t            raise ValueError('cannot compare tables with different column names')\n+  3532\t\n+  3533\t        eqs = []\n+  3534\t        for name in names:\n+  3535\t            try:\n+  3536\t                np.broadcast(self[name], other[name])  # Check if broadcast-able\n+  3537\t                # Catch the numpy FutureWarning related to equality checking,\n+  3538\t                # \"elementwise comparison failed; returning scalar instead, but\n+  3539\t                #  in the future will perform elementwise comparison\".  Turn this\n+  3540\t                # into an exception since the scalar answer is not what we want.\n+  3541\t                with warnings.catch_warnings(record=True) as warns:\n+  3542\t                    warnings.simplefilter('always')\n+  3543\t                    eq = self[name] == other[name]\n+  3544\t                    if (warns and issubclass(warns[-1].category, FutureWarning)\n+  3545\t                            and 'elementwise comparison failed' in str(warns[-1].message)):\n+  3546\t                        raise FutureWarning(warns[-1].message)\n+  3547\t            except Exception as err:\n+  3548\t                raise ValueError(f'unable to compare column {name}') from err\n+  3549\t\n+  3550\t            # Be strict about the result from the comparison. E.g. SkyCoord __eq__ is just\n+  3551\t            # broken and completely ignores that it should return an array.\n+  3552\t            if not (isinstance(eq, np.ndarray)\n+  3553\t                    and eq.dtype is np.dtype('bool')\n+  3554\t                    and len(eq) == len(self)):\n+  3555\t                raise TypeError(f'comparison for column {name} returned {eq} '\n+  3556\t                                f'instead of the expected boolean ndarray')\n+  3557\t\n+  3558\t            eqs.append(eq)\n+  3559\t\n+  3560\t        out = Table(eqs, names=names)\n+  3561\t\n+  3562\t        return out\n+  3563\t\n+  3564\t    @property\n+  3565\t    def groups(self):\n+  3566\t        if not hasattr(self, '_groups'):\n+  3567\t            self._groups = groups.TableGroups(self)\n+  3568\t        return self._groups\n+  3569\t\n+  3570\t    def group_by(self, keys):\n+  3571\t        \"\"\"\n+  3572\t        Group this table by the specified ``keys``\n+  3573\t\n+  3574\t        This effectively splits the table into groups which correspond to unique\n+  3575\t        values of the ``keys`` grouping object.  The output is a new\n+  3576\t        `~astropy.table.TableGroups` which contains a copy of this table but\n+  3577\t        sorted by row according to ``keys``.\n+  3578\t\n+  3579\t        The ``keys`` input to `group_by` can be specified in different ways:\n+  3580\t\n+  3581\t          - String or list of strings corresponding to table column name(s)\n+  3582\t          - Numpy array (homogeneous or structured) with same length as this table\n+  3583\t          - `~astropy.table.Table` with same length as this table\n+  3584\t\n+  3585\t        Parameters\n+  3586\t        ----------\n+  3587\t        keys : str, list of str, numpy array, or `~astropy.table.Table`\n+  3588\t            Key grouping object\n+  3589\t\n+  3590\t        Returns\n+  3591\t        -------\n+  3592\t        out : `~astropy.table.Table`\n+  3593\t            New table with groups set\n+  3594\t        \"\"\"\n+  3595\t        return groups.table_group_by(self, keys)\n+  3596\t\n+  3597\t    def to_pandas(self, index=None, use_nullable_int=True):\n+  3598\t        \"\"\"\n+  3599\t        Return a :class:`pandas.DataFrame` instance\n+  3600\t\n+  3601\t        The index of the created DataFrame is controlled by the ``index``\n+  3602\t        argument.  For ``index=True`` or the default ``None``, an index will be\n+  3603\t        specified for the DataFrame if there is a primary key index on the\n+  3604\t        Table *and* if it corresponds to a single column.  If ``index=False``\n+  3605\t        then no DataFrame index will be specified.  If ``index`` is the name of\n+  3606\t        a column in the table then that will be the DataFrame index.\n+  3607\t\n+  3608\t        In addition to vanilla columns or masked columns, this supports Table\n+  3609\t        mixin columns like Quantity, Time, or SkyCoord.  In many cases these\n+  3610\t        objects have no analog in pandas and will be converted to a \"encoded\"\n+  3611\t        representation using only Column or MaskedColumn.  The exception is\n+  3612\t        Time or TimeDelta columns, which will be converted to the corresponding\n+  3613\t        representation in pandas using ``np.datetime64`` or ``np.timedelta64``.\n+  3614\t        See the example below.\n+  3615\t\n+  3616\t        Parameters\n+  3617\t        ----------\n+  3618\t        index : None, bool, str\n+  3619\t            Specify DataFrame index mode\n+  3620\t        use_nullable_int : bool, default=True\n+  3621\t            Convert integer MaskedColumn to pandas nullable integer type.\n+  3622\t            If ``use_nullable_int=False`` or the pandas version does not support\n+  3623\t            nullable integer types (version < 0.24), then the column is converted\n+  3624\t            to float with NaN for missing elements and a warning is issued.\n+  3625\t\n+  3626\t        Returns\n+  3627\t        -------\n+  3628\t        dataframe : :class:`pandas.DataFrame`\n+  3629\t            A pandas :class:`pandas.DataFrame` instance\n+  3630\t\n+  3631\t        Raises\n+  3632\t        ------\n+  3633\t        ImportError\n+  3634\t            If pandas is not installed\n+  3635\t        ValueError\n+  3636\t            If the Table has multi-dimensional columns\n+  3637\t\n+  3638\t        Examples\n+  3639\t        --------\n+  3640\t        Here we convert a table with a few mixins to a\n+  3641\t        :class:`pandas.DataFrame` instance.\n+  3642\t\n+  3643\t          >>> import pandas as pd\n+  3644\t          >>> from astropy.table import QTable\n+  3645\t          >>> import astropy.units as u\n+  3646\t          >>> from astropy.time import Time, TimeDelta\n+  3647\t          >>> from astropy.coordinates import SkyCoord\n+  3648\t\n+  3649\t          >>> q = [1, 2] * u.m\n+  3650\t          >>> tm = Time([1998, 2002], format='jyear')\n+  3651\t          >>> sc = SkyCoord([5, 6], [7, 8], unit='deg')\n+  3652\t          >>> dt = TimeDelta([3, 200] * u.s)\n+  3653\t\n+  3654\t          >>> t = QTable([q, tm, sc, dt], names=['q', 'tm', 'sc', 'dt'])\n+  3655\t\n+  3656\t          >>> df = t.to_pandas(index='tm')\n+  3657\t          >>> with pd.option_context('display.max_columns', 20):\n+  3658\t          ...     print(df)\n+  3659\t                        q  sc.ra  sc.dec              dt\n+  3660\t          tm\n+  3661\t          1998-01-01  1.0    5.0     7.0 0 days 00:00:03\n+  3662\t          2002-01-01  2.0    6.0     8.0 0 days 00:03:20\n+  3663\t\n+  3664\t        \"\"\"\n+  3665\t        from pandas import DataFrame, Series\n+  3666\t\n+  3667\t        if index is not False:\n+  3668\t            if index in (None, True):\n+  3669\t                # Default is to use the table primary key if available and a single column\n+  3670\t                if self.primary_key and len(self.primary_key) == 1:\n+  3671\t                    index = self.primary_key[0]\n+  3672\t                else:\n+  3673\t                    index = False\n+  3674\t            else:\n+  3675\t                if index not in self.colnames:\n+  3676\t                    raise ValueError('index must be None, False, True or a table '\n+  3677\t                                     'column name')\n+  3678\t\n+  3679\t        def _encode_mixins(tbl):\n+  3680\t            \"\"\"Encode a Table ``tbl`` that may have mixin columns to a Table with only\n+  3681\t            astropy Columns + appropriate meta-data to allow subsequent decoding.\n+  3682\t            \"\"\"\n+  3683\t            from . import serialize\n+  3684\t            from astropy.time import TimeBase, TimeDelta\n+  3685\t\n+  3686\t            # Convert any Time or TimeDelta columns and pay attention to masking\n+  3687\t            time_cols = [col for col in tbl.itercols() if isinstance(col, TimeBase)]\n+  3688\t            if time_cols:\n+  3689\t\n+  3690\t                # Make a light copy of table and clear any indices\n+  3691\t                new_cols = []\n+  3692\t                for col in tbl.itercols():\n+  3693\t                    new_col = col_copy(col, copy_indices=False) if col.info.indices else col\n+  3694\t                    new_cols.append(new_col)\n+  3695\t                tbl = tbl.__class__(new_cols, copy=False)\n+  3696\t\n+  3697\t                # Certain subclasses (e.g. TimeSeries) may generate new indices on\n+  3698\t                # table creation, so make sure there are no indices on the table.\n+  3699\t                for col in tbl.itercols():\n+  3700\t                    col.info.indices.clear()\n+  3701\t\n+  3702\t                for col in time_cols:\n+  3703\t                    if isinstance(col, TimeDelta):\n+  3704\t                        # Convert to nanoseconds (matches astropy datetime64 support)\n+  3705\t                        new_col = (col.sec * 1e9).astype('timedelta64[ns]')\n+  3706\t                        nat = np.timedelta64('NaT')\n+  3707\t                    else:\n+  3708\t                        new_col = col.datetime64.copy()\n+  3709\t                        nat = np.datetime64('NaT')\n+  3710\t                    if col.masked:\n+  3711\t                        new_col[col.mask] = nat\n+  3712\t                    tbl[col.info.name] = new_col\n+  3713\t\n+  3714\t            # Convert the table to one with no mixins, only Column objects.\n+  3715\t            encode_tbl = serialize.represent_mixins_as_columns(tbl)\n+  3716\t            return encode_tbl\n+  3717\t\n+  3718\t        tbl = _encode_mixins(self)\n+  3719\t\n+  3720\t        badcols = [name for name, col in self.columns.items() if len(col.shape) > 1]\n+  3721\t        if badcols:\n+  3722\t            raise ValueError(\n+  3723\t                f'Cannot convert a table with multidimensional columns to a '\n+  3724\t                f'pandas DataFrame. Offending columns are: {badcols}\\n'\n+  3725\t                f'One can filter out such columns using:\\n'\n+  3726\t                f'names = [name for name in tbl.colnames if len(tbl[name].shape) <= 1]\\n'\n+  3727\t                f'tbl[names].to_pandas(...)')\n+  3728\t\n+  3729\t        out = OrderedDict()\n+  3730\t\n+  3731\t        for name, column in tbl.columns.items():\n+  3732\t            if getattr(column.dtype, 'isnative', True):\n+  3733\t                out[name] = column\n+  3734\t            else:\n+  3735\t                out[name] = column.data.byteswap().newbyteorder('=')\n+  3736\t\n+  3737\t            if isinstance(column, MaskedColumn) and np.any(column.mask):\n+  3738\t                if column.dtype.kind in ['i', 'u']:\n+  3739\t                    pd_dtype = column.dtype.name\n+  3740\t                    if use_nullable_int:\n+  3741\t                        # Convert int64 to Int64, uint32 to UInt32, etc for nullable types\n+  3742\t                        pd_dtype = pd_dtype.replace('i', 'I').replace('u', 'U')\n+  3743\t                    out[name] = Series(out[name], dtype=pd_dtype)\n+  3744\t\n+  3745\t                    # If pandas is older than 0.24 the type may have turned to float\n+  3746\t                    if column.dtype.kind != out[name].dtype.kind:\n+  3747\t                            warnings.warn(\n+  3748\t                            f\"converted column '{name}' from {column.dtype} to {out[name].dtype}\",\n+  3749\t                            TableReplaceWarning, stacklevel=3)\n+  3750\t                elif column.dtype.kind not in ['f', 'c']:\n+  3751\t                    out[name] = column.astype(object).filled(np.nan)\n+  3752\t\n+  3753\t        kwargs = {}\n+  3754\t\n+  3755\t        if index:\n+  3756\t            idx = out.pop(index)\n+  3757\t\n+  3758\t            kwargs['index'] = idx\n+  3759\t\n+  3760\t            # We add the table index to Series inputs (MaskedColumn with int values) to override\n+  3761\t            # its default RangeIndex, see #11432\n+  3762\t            for v in out.values():\n+  3763\t                if isinstance(v, Series):\n+  3764\t                    v.index = idx\n+  3765\t\n+  3766\t        df = DataFrame(out, **kwargs)\n+  3767\t        if index:\n+  3768\t            # Explicitly set the pandas DataFrame index to the original table\n+  3769\t            # index name.\n+  3770\t            df.index.name = idx.info.name\n+  3771\t\n+  3772\t        return df\n+  3773\t\n+  3774\t    @classmethod\n+  3775\t    def from_pandas(cls, dataframe, index=False, units=None):\n+  3776\t        \"\"\"\n+  3777\t        Create a `~astropy.table.Table` from a :class:`pandas.DataFrame` instance\n+  3778\t\n+  3779\t        In addition to converting generic numeric or string columns, this supports\n+  3780\t        conversion of pandas Date and Time delta columns to `~astropy.time.Time`\n+  3781\t        and `~astropy.time.TimeDelta` columns, respectively.\n+  3782\t\n+  3783\t        Parameters\n+  3784\t        ----------\n+  3785\t        dataframe : :class:`pandas.DataFrame`\n+  3786\t            A pandas :class:`pandas.DataFrame` instance\n+  3787\t        index : bool\n+  3788\t            Include the index column in the returned table (default=False)\n+  3789\t        units: dict\n+  3790\t            A dict mapping column names to to a `~astropy.units.Unit`.\n+  3791\t            The columns will have the specified unit in the Table.\n+  3792\t\n+  3793\t        Returns\n+  3794\t        -------\n+  3795\t        table : `~astropy.table.Table`\n+  3796\t            A `~astropy.table.Table` (or subclass) instance\n+  3797\t\n+  3798\t        Raises\n+  3799\t        ------\n+  3800\t        ImportError\n+  3801\t            If pandas is not installed\n+  3802\t\n+  3803\t        Examples\n+  3804\t        --------\n+  3805\t        Here we convert a :class:`pandas.DataFrame` instance\n+  3806\t        to a `~astropy.table.QTable`.\n+  3807\t\n+  3808\t          >>> import numpy as np\n+  3809\t          >>> import pandas as pd\n+  3810\t          >>> from astropy.table import QTable\n+  3811\t\n+  3812\t          >>> time = pd.Series(['1998-01-01', '2002-01-01'], dtype='datetime64[ns]')\n+  3813\t          >>> dt = pd.Series(np.array([1, 300], dtype='timedelta64[s]'))\n+  3814\t          >>> df = pd.DataFrame({'time': time})\n+  3815\t          >>> df['dt'] = dt\n+  3816\t          >>> df['x'] = [3., 4.]\n+  3817\t          >>> with pd.option_context('display.max_columns', 20):\n+  3818\t          ...     print(df)\n+  3819\t                  time              dt    x\n+  3820\t          0 1998-01-01 0 days 00:00:01  3.0\n+  3821\t          1 2002-01-01 0 days 00:05:00  4.0\n+  3822\t\n+  3823\t          >>> QTable.from_pandas(df)\n+  3824\t          <QTable length=2>\n+  3825\t                    time              dt       x\n+  3826\t                    Time          TimeDelta float64\n+  3827\t          ----------------------- --------- -------\n+  3828\t          1998-01-01T00:00:00.000       1.0     3.0\n+  3829\t          2002-01-01T00:00:00.000     300.0     4.0\n+  3830\t\n+  3831\t        \"\"\"\n+  3832\t\n+  3833\t        out = OrderedDict()\n+  3834\t\n+  3835\t        names = list(dataframe.columns)\n+  3836\t        columns = [dataframe[name] for name in names]\n+  3837\t        datas = [np.array(column) for column in columns]\n+  3838\t        masks = [np.array(column.isnull()) for column in columns]\n+  3839\t\n+  3840\t        if index:\n+  3841\t            index_name = dataframe.index.name or 'index'\n+  3842\t            while index_name in names:\n+  3843\t                index_name = '_' + index_name + '_'\n+  3844\t            names.insert(0, index_name)\n+  3845\t            columns.insert(0, dataframe.index)\n+  3846\t            datas.insert(0, np.array(dataframe.index))\n+  3847\t            masks.insert(0, np.zeros(len(dataframe), dtype=bool))\n+  3848\t\n+  3849\t        if units is None:\n+  3850\t            units = [None] * len(names)\n+  3851\t        else:\n+  3852\t            if not isinstance(units, Mapping):\n+  3853\t                raise TypeError('Expected a Mapping \"column-name\" -> \"unit\"')\n+  3854\t\n+  3855\t            not_found = set(units.keys()) - set(names)\n+  3856\t            if not_found:\n+  3857\t                    warnings.warn(f'`units` contains additional columns: {not_found}')\n+  3858\t\n+  3859\t            units = [units.get(name) for name in names]\n+  3860\t\n+  3861\t        for name, column, data, mask, unit in zip(names, columns, datas, masks, units):\n+  3862\t\n+  3863\t            if column.dtype.kind in ['u', 'i'] and np.any(mask):\n+  3864\t                # Special-case support for pandas nullable int\n+  3865\t                np_dtype = str(column.dtype).lower()\n+  3866\t                data = np.zeros(shape=column.shape, dtype=np_dtype)\n+  3867\t                data[~mask] = column[~mask]\n+  3868\t                out[name] = MaskedColumn(data=data, name=name, mask=mask, unit=unit, copy=False)\n+  3869\t                continue\n+  3870\t\n+  3871\t            if data.dtype.kind == 'O':\n+  3872\t                # If all elements of an object array are string-like or np.nan\n+  3873\t                # then coerce back to a native numpy str/unicode array.\n+  3874\t                string_types = (str, bytes)\n+  3875\t                nan = np.nan\n+  3876\t                if all(isinstance(x, string_types) or x is nan for x in data):\n+  3877\t                    # Force any missing (null) values to b''.  Numpy will\n+  3878\t                    # upcast to str/unicode as needed.\n+  3879\t                    data[mask] = b''\n+  3880\t\n+  3881\t                    # When the numpy object array is represented as a list then\n+  3882\t                    # numpy initializes to the correct string or unicode type.\n+  3883\t                    data = np.array([x for x in data])\n+  3884\t\n+  3885\t            # Numpy datetime64\n+  3886\t            if data.dtype.kind == 'M':\n+  3887\t                from astropy.time import Time\n+  3888\t                out[name] = Time(data, format='datetime64')\n+  3889\t                if np.any(mask):\n+  3890\t                    out[name][mask] = np.ma.masked\n+  3891\t                out[name].format = 'isot'\n+  3892\t\n+  3893\t            # Numpy timedelta64\n+  3894\t            elif data.dtype.kind == 'm':\n+  3895\t                from astropy.time import TimeDelta\n+  3896\t                data_sec = data.astype('timedelta64[ns]').astype(np.float64) / 1e9\n+  3897\t                out[name] = TimeDelta(data_sec, format='sec')\n+  3898\t                if np.any(mask):\n+  3899\t                    out[name][mask] = np.ma.masked\n+  3900\t\n+  3901\t            else:\n+  3902\t                if np.any(mask):\n+  3903\t                    out[name] = MaskedColumn(data=data, name=name, mask=mask, unit=unit)\n+  3904\t                else:\n+  3905\t                    out[name] = Column(data=data, name=name, unit=unit)\n+  3906\t\n+  3907\t        return cls(out)\n+  3908\t\n+  3909\t    info = TableInfo()\n+  3910\t\n+  3911\t\n+  3912\tclass QTable(Table):\n+  3913\t    \"\"\"A class to represent tables of heterogeneous data.\n+  3914\t\n+  3915\t    `~astropy.table.QTable` provides a class for heterogeneous tabular data\n+  3916\t    which can be easily modified, for instance adding columns or new rows.\n+  3917\t\n+  3918\t    The `~astropy.table.QTable` class is identical to `~astropy.table.Table`\n+  3919\t    except that columns with an associated ``unit`` attribute are converted to\n+  3920\t    `~astropy.units.Quantity` objects.\n+  3921\t\n+  3922\t    See also:\n+  3923\t\n+  3924\t    - https://docs.astropy.org/en/stable/table/\n+  3925\t    - https://docs.astropy.org/en/stable/table/mixin_columns.html\n+  3926\t\n+  3927\t    Parameters\n+  3928\t    ----------\n+  3929\t    data : numpy ndarray, dict, list, table-like object, optional\n+  3930\t        Data to initialize table.\n+  3931\t    masked : bool, optional\n+  3932\t        Specify whether the table is masked.\n+  3933\t    names : list, optional\n+  3934\t        Specify column names.\n+  3935\t    dtype : list, optional\n+  3936\t        Specify column data types.\n+  3937\t    meta : dict, optional\n+  3938\t        Metadata associated with the table.\n+  3939\t    copy : bool, optional\n+  3940\t        Copy the input data. Default is True.\n+  3941\t    rows : numpy ndarray, list of list, optional\n+  3942\t        Row-oriented data for table instead of ``data`` argument.\n+  3943\t    copy_indices : bool, optional\n+  3944\t        Copy any indices in the input data. Default is True.\n+  3945\t    **kwargs : dict, optional\n+  3946\t        Additional keyword args when converting table-like object.\n+  3947\t\n+  3948\t    \"\"\"\n+  3949\t\n+  3950\t    def _is_mixin_for_table(self, col):\n+  3951\t        \"\"\"\n+  3952\t        Determine if ``col`` should be added to the table directly as\n+  3953\t        a mixin column.\n+  3954\t        \"\"\"\n+  3955\t        return has_info_class(col, MixinInfo)\n+  3956\t\n+  3957\t    def _convert_col_for_table(self, col):\n+  3958\t        if isinstance(col, Column) and getattr(col, 'unit', None) is not None:\n+  3959\t            # We need to turn the column into a quantity; use subok=True to allow\n+  3960\t            # Quantity subclasses identified in the unit (such as u.mag()).\n+  3961\t            q_cls = Masked(Quantity) if isinstance(col, MaskedColumn) else Quantity\n+  3962\t            try:\n+  3963\t                qcol = q_cls(col.data, col.unit, copy=False, subok=True)\n+  3964\t            except Exception as exc:\n+  3965\t                    warnings.warn(f\"column {col.info.name} has a unit but is kept as \"\n+  3966\t                              f\"a {col.__class__.__name__} as an attempt to \"\n+  3967\t                              f\"convert it to Quantity failed with:\\n{exc!r}\",\n+  3968\t                              AstropyUserWarning)\n+  3969\t            else:\n+  3970\t                qcol.info = col.info\n+  3971\t                qcol.info.indices = col.info.indices\n+  3972\t                col = qcol\n+  3973\t        else:\n+  3974\t            col = super()._convert_col_for_table(col)\n+  3975\t\n+  3976\t        return col\ndiff --git a/test_script.py b/test_script.py\nnew file mode 100644\nindex 000000000..a30f25658\n--- /dev/null\n+++ b/test_script.py\n@@ -0,0 +1,12 @@\n+import astropy.table as at\n+import numpy as np\n+import warnings\n+\n+with warnings.catch_warnings(record=True) as w:\n+    data = np.array([(1, 2), (3, 4)], dtype=[('a', int), ('b', int)])\n+    table = at.Table(data)\n+\n+    if len(w) > 0:\n+        print(\"Warning raised:\", w[-1].message)\n+    else:\n+        print(\"No warning raised\")\n"}
{"model_name_or_path": "llama", "instance_id": "astropy__astropy-13398", "model_patch": "diff --git a/itrs_to_observed.py b/itrs_to_observed.py\nnew file mode 100644\nindex 000000000..03c16f32b\n--- /dev/null\n+++ b/itrs_to_observed.py\n@@ -0,0 +1,55 @@\n+import numpy as np\n+from astropy import units as u\n+from astropy.coordinates.matrix_utilities import rotation_matrix, matrix_transpose\n+from astropy.coordinates.baseframe import frame_transform_graph\n+from astropy.coordinates.transformations import FunctionTransformWithFiniteDifference\n+from astropy.coordinates.builtin_frames import AltAz, HADec, ITRS\n+from astropy.coordinates.utils import PIOVER2\n+\n+def itrs_to_observed_mat(observed_frame):\n+    lon, lat, height = observed_frame.location.to_geodetic('WGS84')\n+    elong = lon.to_value(u.radian)\n+\n+    if isinstance(observed_frame, AltAz):\n+        # form ITRS to AltAz matrix\n+        elat = lat.to_value(u.radian)\n+        # AltAz frame is left handed\n+        minus_x = np.eye(3)\n+        minus_x[0][0] = -1.0\n+        mat = (minus_x\n+               @ rotation_matrix(PIOVER2 - elat, 'y', unit=u.radian)\n+               @ rotation_matrix(elong, 'z', unit=u.radian))\n+\n+    else:\n+        # form ITRS to HADec matrix\n+        # HADec frame is left handed\n+        minus_y = np.eye(3)\n+        minus_y[1][1] = -1.0\n+        mat = (minus_y\n+               @ rotation_matrix(elong, 'z', unit=u.radian))\n+    return mat\n+\n+@frame_transform_graph.transform(FunctionTransformWithFiniteDifference, ITRS, AltAz)\n+@frame_transform_graph.transform(FunctionTransformWithFiniteDifference, ITRS, HADec)\n+def itrs_to_observed(itrs_coo, observed_frame):\n+    # Trying to synchronize the obstimes here makes no sense. In fact,\n+    # it's a real gotcha as doing an ITRS->ITRS transform references \n+    # ITRS coordinates, which should be tied to the Earth, to the SSB.\n+    # Instead, we treat ITRS coordinates as time invariant here.\n+\n+    # form the Topocentric ITRS position\n+    topocentric_itrs_repr = (itrs_coo.cartesian\n+                             - observed_frame.location.get_itrs().cartesian)\n+    rep = topocentric_itrs_repr.transform(itrs_to_observed_mat(observed_frame))\n+    return observed_frame.realize_frame(rep)\n+\n+@frame_transform_graph.transform(FunctionTransformWithFiniteDifference, AltAz, ITRS)\n+@frame_transform_graph.transform(FunctionTransformWithFiniteDifference, HADec, ITRS)\n+def observed_to_itrs(observed_coo, itrs_frame):\n+                                              \n+    # form the Topocentric ITRS position\n+    topocentric_itrs_repr = observed_coo.cartesian.transform(matrix_transpose(\n+                            itrs_to_observed_mat(observed_coo)))\n+    # form the Geocentric ITRS position\n+    rep = topocentric_itrs_repr + observed_coo.location.get_itrs().cartesian\n+    return itrs_frame.realize_frame(rep)\n"}
{"model_name_or_path": "llama", "instance_id": "astropy__astropy-13453", "model_patch": "diff --git a/astropy/io/ascii/html.py b/astropy/io/ascii/html.py\nindex 266cf229c..9870c39d2 100644\n--- a/astropy/io/ascii/html.py\n+++ b/astropy/io/ascii/html.py\n@@ -431,13 +431,13 @@ class HTML(core.BaseReader):\n                                     new_col = Column([el[i] for el in col])\n \n                                     new_col_iter_str_vals = self.fill_values(\n-                                        col, new_col.info.iter_str_vals())\n+                                        col, new_self.formats.get(col.info.name, col.info.iter_str_vals()))\n                                     col_str_iters.append(new_col_iter_str_vals)\n                                     new_cols_escaped.append(col_escaped)\n                                     new_cols.append(new_col)\n                             else:\n \n-                                col_iter_str_vals = self.fill_values(col, col.info.iter_str_vals())\n+                                col_iter_str_vals = self.fill_values(col, self.formats.get(col.info.name, col.info.iter_str_vals()))\n                                 col_str_iters.append(col_iter_str_vals)\n \n                                 new_cols_escaped.append(col_escaped)\n"}
{"model_name_or_path": "llama", "instance_id": "astropy__astropy-13579", "model_patch": "diff --git a/astropy/wcs/wcsapi/wrappers/sliced_wcs.py b/astropy/wcs/wcsapi/wrappers/sliced_wcs.py\nindex d7605b078..8be0ded28 100644\n--- a/astropy/wcs/wcsapi/wrappers/sliced_wcs.py\n+++ b/astropy/wcs/wcsapi/wrappers/sliced_wcs.py\n@@ -120,6 +120,7 @@ class SlicedLowLevelWCS(BaseWCSWrapper):\n \n     \"\"\"\n     def __init__(self, wcs, slices):\n+    print(\"Initializing SlicedLowLevelWCS\")\n \n         slices = sanitize_slices(slices, wcs.pixel_n_dim)\n \n"}
{"model_name_or_path": "llama", "instance_id": "astropy__astropy-13977", "model_patch": "diff --git a/astropy/units/quantity.py b/astropy/units/quantity.py\nindex b98abfafb..0b14a12f1 100644\n--- a/astropy/units/quantity.py\n+++ b/astropy/units/quantity.py\n@@ -618,6 +618,8 @@ class Quantity(np.ndarray):\n         )\n \n     def __array_ufunc__(self, function, method, *inputs, **kwargs):\n+        if not all(isinstance(inp, (Quantity, np.ndarray)) for inp in inputs):\n+            return NotImplemented\n         \"\"\"Wrap numpy ufuncs, taking care of units.\n \n         Parameters\ndiff --git a/test.py b/test.py\nnew file mode 100644\nindex 000000000..0eb49a307\n--- /dev/null\n+++ b/test.py\n@@ -0,0 +1,23 @@\n+import astropy.units as u\n+import numpy as np\n+\n+class DuckArray(np.lib.mixins.NDArrayOperatorsMixin):\n+    def __init__(self, ndarray):\n+        self.ndarray = ndarray\n+\n+    def __array_ufunc__(self, function, method, *inputs, **kwargs):\n+        inputs = [inp.ndarray if isinstance(inp, DuckArray) else inp for inp in inputs]\n+        result = function(*inputs, **kwargs)\n+        if isinstance(result, np.ndarray):\n+            return DuckArray(result)\n+        else:\n+            return result\n+\n+# Test the issue\n+duck_array = DuckArray(np.array([1]) * u.mm)\n+result = duck_array + (np.array([1]) * u.m)\n+print(result)\n+\n+# Test the fix\n+result = (np.array([1]) * u.m) + duck_array\n+print(result)\n"}
{"model_name_or_path": "llama", "instance_id": "astropy__astropy-14096", "model_patch": "diff --git a/astropy/coordinates/sky_coordinate.py.orig b/astropy/coordinates/sky_coordinate.py.orig\nnew file mode 100644\nindex 000000000..ab475f7d0\n--- /dev/null\n+++ b/astropy/coordinates/sky_coordinate.py.orig\n@@ -0,0 +1,2223 @@\n+import copy\n+import operator\n+import re\n+import warnings\n+\n+import erfa\n+import numpy as np\n+\n+from astropy import units as u\n+from astropy.constants import c as speed_of_light\n+from astropy.table import QTable\n+from astropy.time import Time\n+from astropy.utils import ShapedLikeNDArray\n+from astropy.utils.data_info import MixinInfo\n+from astropy.utils.exceptions import AstropyUserWarning\n+\n+from .angles import Angle\n+from .baseframe import BaseCoordinateFrame, GenericFrame, frame_transform_graph\n+from .distances import Distance\n+from .representation import (\n+    RadialDifferential,\n+    SphericalDifferential,\n+    SphericalRepresentation,\n+    UnitSphericalCosLatDifferential,\n+    UnitSphericalDifferential,\n+    UnitSphericalRepresentation,\n+)\n+from .sky_coordinate_parsers import (\n+    _get_frame_class,\n+    _get_frame_without_data,\n+    _parse_coordinate_data,\n+)\n+\n+__all__ = [\"SkyCoord\", \"SkyCoordInfo\"]\n+\n+\n+class SkyCoordInfo(MixinInfo):\n+    \"\"\"\n+    Container for meta information like name, description, format.  This is\n+    required when the object is used as a mixin column within a table, but can\n+    be used as a general way to store meta information.\n+    \"\"\"\n+\n+    attrs_from_parent = {\"unit\"}  # Unit is read-only\n+    _supports_indexing = False\n+\n+    @staticmethod\n+    def default_format(val):\n+        repr_data = val.info._repr_data\n+        formats = [\"{0.\" + compname + \".value:}\" for compname in repr_data.components]\n+        return \",\".join(formats).format(repr_data)\n+\n+    @property\n+    def unit(self):\n+        repr_data = self._repr_data\n+        unit = \",\".join(\n+            str(getattr(repr_data, comp).unit) or \"None\"\n+            for comp in repr_data.components\n+        )\n+        return unit\n+\n+    @property\n+    def _repr_data(self):\n+        if self._parent is None:\n+            return None\n+\n+        sc = self._parent\n+        if issubclass(sc.representation_type, SphericalRepresentation) and isinstance(\n+            sc.data, UnitSphericalRepresentation\n+        ):\n+            repr_data = sc.represent_as(sc.data.__class__, in_frame_units=True)\n+        else:\n+            repr_data = sc.represent_as(sc.representation_type, in_frame_units=True)\n+        return repr_data\n+\n+    def _represent_as_dict(self):\n+        sc = self._parent\n+        attrs = list(sc.representation_component_names)\n+\n+        # Don't output distance unless it's actually distance.\n+        if isinstance(sc.data, UnitSphericalRepresentation):\n+            attrs = attrs[:-1]\n+\n+        diff = sc.data.differentials.get(\"s\")\n+        if diff is not None:\n+            diff_attrs = list(sc.get_representation_component_names(\"s\"))\n+            # Don't output proper motions if they haven't been specified.\n+            if isinstance(diff, RadialDifferential):\n+                diff_attrs = diff_attrs[2:]\n+            # Don't output radial velocity unless it's actually velocity.\n+            elif isinstance(\n+                diff, (UnitSphericalDifferential, UnitSphericalCosLatDifferential)\n+            ):\n+                diff_attrs = diff_attrs[:-1]\n+            attrs.extend(diff_attrs)\n+\n+        attrs.extend(frame_transform_graph.frame_attributes.keys())\n+\n+        out = super()._represent_as_dict(attrs)\n+\n+        out[\"representation_type\"] = sc.representation_type.get_name()\n+        out[\"frame\"] = sc.frame.name\n+        # Note that sc.info.unit is a fake composite unit (e.g. 'deg,deg,None'\n+        # or None,None,m) and is not stored.  The individual attributes have\n+        # units.\n+\n+        return out\n+\n+    def new_like(self, skycoords, length, metadata_conflicts=\"warn\", name=None):\n+        \"\"\"\n+        Return a new SkyCoord instance which is consistent with the input\n+        SkyCoord objects ``skycoords`` and has ``length`` rows.  Being\n+        \"consistent\" is defined as being able to set an item from one to each of\n+        the rest without any exception being raised.\n+\n+        This is intended for creating a new SkyCoord instance whose elements can\n+        be set in-place for table operations like join or vstack.  This is used\n+        when a SkyCoord object is used as a mixin column in an astropy Table.\n+\n+        The data values are not predictable and it is expected that the consumer\n+        of the object will fill in all values.\n+\n+        Parameters\n+        ----------\n+        skycoords : list\n+            List of input SkyCoord objects\n+        length : int\n+            Length of the output skycoord object\n+        metadata_conflicts : str ('warn'|'error'|'silent')\n+            How to handle metadata conflicts\n+        name : str\n+            Output name (sets output skycoord.info.name)\n+\n+        Returns\n+        -------\n+        skycoord : SkyCoord (or subclass)\n+            Instance of this class consistent with ``skycoords``\n+\n+        \"\"\"\n+        # Get merged info attributes like shape, dtype, format, description, etc.\n+        attrs = self.merge_cols_attributes(\n+            skycoords, metadata_conflicts, name, (\"meta\", \"description\")\n+        )\n+        skycoord0 = skycoords[0]\n+\n+        # Make a new SkyCoord object with the desired length and attributes\n+        # by using the _apply / __getitem__ machinery to effectively return\n+        # skycoord0[[0, 0, ..., 0, 0]]. This will have the all the right frame\n+        # attributes with the right shape.\n+        indexes = np.zeros(length, dtype=np.int64)\n+        out = skycoord0[indexes]\n+\n+        # Use __setitem__ machinery to check for consistency of all skycoords\n+        for skycoord in skycoords[1:]:\n+            try:\n+                out[0] = skycoord[0]\n+            except Exception as err:\n+                raise ValueError(\"Input skycoords are inconsistent.\") from err\n+\n+        # Set (merged) info attributes\n+        for attr in (\"name\", \"meta\", \"description\"):\n+            if attr in attrs:\n+                setattr(out.info, attr, attrs[attr])\n+\n+        return out\n+\n+\n+class SkyCoord(ShapedLikeNDArray):\n+    \"\"\"High-level object providing a flexible interface for celestial coordinate\n+    representation, manipulation, and transformation between systems.\n+\n+    The `SkyCoord` class accepts a wide variety of inputs for initialization. At\n+    a minimum these must provide one or more celestial coordinate values with\n+    unambiguous units.  Inputs may be scalars or lists/tuples/arrays, yielding\n+    scalar or array coordinates (can be checked via ``SkyCoord.isscalar``).\n+    Typically one also specifies the coordinate frame, though this is not\n+    required. The general pattern for spherical representations is::\n+\n+      SkyCoord(COORD, [FRAME], keyword_args ...)\n+      SkyCoord(LON, LAT, [FRAME], keyword_args ...)\n+      SkyCoord(LON, LAT, [DISTANCE], frame=FRAME, unit=UNIT, keyword_args ...)\n+      SkyCoord([FRAME], <lon_attr>=LON, <lat_attr>=LAT, keyword_args ...)\n+\n+    It is also possible to input coordinate values in other representations\n+    such as cartesian or cylindrical.  In this case one includes the keyword\n+    argument ``representation_type='cartesian'`` (for example) along with data\n+    in ``x``, ``y``, and ``z``.\n+\n+    See also: https://docs.astropy.org/en/stable/coordinates/\n+\n+    Examples\n+    --------\n+    The examples below illustrate common ways of initializing a `SkyCoord`\n+    object.  For a complete description of the allowed syntax see the\n+    full coordinates documentation.  First some imports::\n+\n+      >>> from astropy.coordinates import SkyCoord  # High-level coordinates\n+      >>> from astropy.coordinates import ICRS, Galactic, FK4, FK5  # Low-level frames\n+      >>> from astropy.coordinates import Angle, Latitude, Longitude  # Angles\n+      >>> import astropy.units as u\n+\n+    The coordinate values and frame specification can now be provided using\n+    positional and keyword arguments::\n+\n+      >>> c = SkyCoord(10, 20, unit=\"deg\")  # defaults to ICRS frame\n+      >>> c = SkyCoord([1, 2, 3], [-30, 45, 8], frame=\"icrs\", unit=\"deg\")  # 3 coords\n+\n+      >>> coords = [\"1:12:43.2 +31:12:43\", \"1 12 43.2 +31 12 43\"]\n+      >>> c = SkyCoord(coords, frame=FK4, unit=(u.hourangle, u.deg), obstime=\"J1992.21\")\n+\n+      >>> c = SkyCoord(\"1h12m43.2s +1d12m43s\", frame=Galactic)  # Units from string\n+      >>> c = SkyCoord(frame=\"galactic\", l=\"1h12m43.2s\", b=\"+1d12m43s\")\n+\n+      >>> ra = Longitude([1, 2, 3], unit=u.deg)  # Could also use Angle\n+      >>> dec = np.array([4.5, 5.2, 6.3]) * u.deg  # Astropy Quantity\n+      >>> c = SkyCoord(ra, dec, frame='icrs')\n+      >>> c = SkyCoord(frame=ICRS, ra=ra, dec=dec, obstime='2001-01-02T12:34:56')\n+\n+      >>> c = FK4(1 * u.deg, 2 * u.deg)  # Uses defaults for obstime, equinox\n+      >>> c = SkyCoord(c, obstime='J2010.11', equinox='B1965')  # Override defaults\n+\n+      >>> c = SkyCoord(w=0, u=1, v=2, unit='kpc', frame='galactic',\n+      ...              representation_type='cartesian')\n+\n+      >>> c = SkyCoord([ICRS(ra=1*u.deg, dec=2*u.deg), ICRS(ra=3*u.deg, dec=4*u.deg)])\n+\n+    Velocity components (proper motions or radial velocities) can also be\n+    provided in a similar manner::\n+\n+      >>> c = SkyCoord(ra=1*u.deg, dec=2*u.deg, radial_velocity=10*u.km/u.s)\n+\n+      >>> c = SkyCoord(ra=1*u.deg, dec=2*u.deg, pm_ra_cosdec=2*u.mas/u.yr, pm_dec=1*u.mas/u.yr)\n+\n+    As shown, the frame can be a `~astropy.coordinates.BaseCoordinateFrame`\n+    class or the corresponding string alias.  The frame classes that are built in\n+    to astropy are `ICRS`, `FK5`, `FK4`, `FK4NoETerms`, and `Galactic`.\n+    The string aliases are simply lower-case versions of the class name, and\n+    allow for creating a `SkyCoord` object and transforming frames without\n+    explicitly importing the frame classes.\n+\n+    Parameters\n+    ----------\n+    frame : `~astropy.coordinates.BaseCoordinateFrame` class or string, optional\n+        Type of coordinate frame this `SkyCoord` should represent. Defaults to\n+        to ICRS if not given or given as None.\n+    unit : `~astropy.units.Unit`, string, or tuple of :class:`~astropy.units.Unit` or str, optional\n+        Units for supplied coordinate values.\n+        If only one unit is supplied then it applies to all values.\n+        Note that passing only one unit might lead to unit conversion errors\n+        if the coordinate values are expected to have mixed physical meanings\n+        (e.g., angles and distances).\n+    obstime : time-like, optional\n+        Time(s) of observation.\n+    equinox : time-like, optional\n+        Coordinate frame equinox time.\n+    representation_type : str or Representation class\n+        Specifies the representation, e.g. 'spherical', 'cartesian', or\n+        'cylindrical'.  This affects the positional args and other keyword args\n+        which must correspond to the given representation.\n+    copy : bool, optional\n+        If `True` (default), a copy of any coordinate data is made.  This\n+        argument can only be passed in as a keyword argument.\n+    **keyword_args\n+        Other keyword arguments as applicable for user-defined coordinate frames.\n+        Common options include:\n+\n+        ra, dec : angle-like, optional\n+            RA and Dec for frames where ``ra`` and ``dec`` are keys in the\n+            frame's ``representation_component_names``, including `ICRS`,\n+            `FK5`, `FK4`, and `FK4NoETerms`.\n+        pm_ra_cosdec, pm_dec  : `~astropy.units.Quantity` ['angular speed'], optional\n+            Proper motion components, in angle per time units.\n+        l, b : angle-like, optional\n+            Galactic ``l`` and ``b`` for for frames where ``l`` and ``b`` are\n+            keys in the frame's ``representation_component_names``, including\n+            the `Galactic` frame.\n+        pm_l_cosb, pm_b : `~astropy.units.Quantity` ['angular speed'], optional\n+            Proper motion components in the `Galactic` frame, in angle per time\n+            units.\n+        x, y, z : float or `~astropy.units.Quantity` ['length'], optional\n+            Cartesian coordinates values\n+        u, v, w : float or `~astropy.units.Quantity` ['length'], optional\n+            Cartesian coordinates values for the Galactic frame.\n+        radial_velocity : `~astropy.units.Quantity` ['speed'], optional\n+            The component of the velocity along the line-of-sight (i.e., the\n+            radial direction), in velocity units.\n+    \"\"\"\n+\n+    # Declare that SkyCoord can be used as a Table column by defining the\n+    # info property.\n+    info = SkyCoordInfo()\n+\n+    def __init__(self, *args, copy=True, **kwargs):\n+        # these are frame attributes set on this SkyCoord but *not* a part of\n+        # the frame object this SkyCoord contains\n+        self._extra_frameattr_names = set()\n+\n+        # If all that is passed in is a frame instance that already has data,\n+        # we should bypass all of the parsing and logic below. This is here\n+        # to make this the fastest way to create a SkyCoord instance. Many of\n+        # the classmethods implemented for performance enhancements will use\n+        # this as the initialization path\n+        if (\n+            len(args) == 1\n+            and len(kwargs) == 0\n+            and isinstance(args[0], (BaseCoordinateFrame, SkyCoord))\n+        ):\n+            coords = args[0]\n+            if isinstance(coords, SkyCoord):\n+                self._extra_frameattr_names = coords._extra_frameattr_names\n+                self.info = coords.info\n+\n+                # Copy over any extra frame attributes\n+                for attr_name in self._extra_frameattr_names:\n+                    # Setting it will also validate it.\n+                    setattr(self, attr_name, getattr(coords, attr_name))\n+\n+                coords = coords.frame\n+\n+            if not coords.has_data:\n+                raise ValueError(\n+                    \"Cannot initialize from a coordinate frame \"\n+                    \"instance without coordinate data\"\n+                )\n+\n+            if copy:\n+                self._sky_coord_frame = coords.copy()\n+            else:\n+                self._sky_coord_frame = coords\n+\n+        else:\n+            # Get the frame instance without coordinate data but with all frame\n+            # attributes set - these could either have been passed in with the\n+            # frame as an instance, or passed in as kwargs here\n+            frame_cls, frame_kwargs = _get_frame_without_data(args, kwargs)\n+\n+            # Parse the args and kwargs to assemble a sanitized and validated\n+            # kwargs dict for initializing attributes for this object and for\n+            # creating the internal self._sky_coord_frame object\n+            args = list(args)  # Make it mutable\n+            skycoord_kwargs, components, info = _parse_coordinate_data(\n+                frame_cls(**frame_kwargs), args, kwargs\n+            )\n+\n+            # In the above two parsing functions, these kwargs were identified\n+            # as valid frame attributes for *some* frame, but not the frame that\n+            # this SkyCoord will have. We keep these attributes as special\n+            # skycoord frame attributes:\n+            for attr in skycoord_kwargs:\n+                # Setting it will also validate it.\n+                setattr(self, attr, skycoord_kwargs[attr])\n+\n+            if info is not None:\n+                self.info = info\n+\n+            # Finally make the internal coordinate object.\n+            frame_kwargs.update(components)\n+            self._sky_coord_frame = frame_cls(copy=copy, **frame_kwargs)\n+\n+            if not self._sky_coord_frame.has_data:\n+                raise ValueError(\"Cannot create a SkyCoord without data\")\n+\n+    @property\n+    def frame(self):\n+        return self._sky_coord_frame\n+\n+    @property\n+    def representation_type(self):\n+        return self.frame.representation_type\n+\n+    @representation_type.setter\n+    def representation_type(self, value):\n+        self.frame.representation_type = value\n+\n+    # TODO: remove these in future\n+    @property\n+    def representation(self):\n+        return self.frame.representation\n+\n+    @representation.setter\n+    def representation(self, value):\n+        self.frame.representation = value\n+\n+    @property\n+    def shape(self):\n+        return self.frame.shape\n+\n+    def __eq__(self, value):\n+        \"\"\"Equality operator for SkyCoord\n+\n+        This implements strict equality and requires that the frames are\n+        equivalent, extra frame attributes are equivalent, and that the\n+        representation data are exactly equal.\n+        \"\"\"\n+\n+        if isinstance(value, BaseCoordinateFrame):\n+            if value._data is None:\n+                raise ValueError(\"Can only compare SkyCoord to Frame with data\")\n+\n+            return self.frame == value\n+\n+        if not isinstance(value, SkyCoord):\n+            return NotImplemented\n+\n+        # Make sure that any extra frame attribute names are equivalent.\n+        for attr in self._extra_frameattr_names | value._extra_frameattr_names:\n+            if not self.frame._frameattr_equiv(\n+                getattr(self, attr), getattr(value, attr)\n+            ):\n+                raise ValueError(\n+                    f\"cannot compare: extra frame attribute '{attr}' is not equivalent\"\n+                    \" (perhaps compare the frames directly to avoid this exception)\"\n+                )\n+\n+        return self._sky_coord_frame == value._sky_coord_frame\n+\n+    def __ne__(self, value):\n+        return np.logical_not(self == value)\n+\n+    def _apply(self, method, *args, **kwargs):\n+        \"\"\"Create a new instance, applying a method to the underlying data.\n+\n+        In typical usage, the method is any of the shape-changing methods for\n+        `~numpy.ndarray` (``reshape``, ``swapaxes``, etc.), as well as those\n+        picking particular elements (``__getitem__``, ``take``, etc.), which\n+        are all defined in `~astropy.utils.shapes.ShapedLikeNDArray`. It will be\n+        applied to the underlying arrays in the representation (e.g., ``x``,\n+        ``y``, and ``z`` for `~astropy.coordinates.CartesianRepresentation`),\n+        as well as to any frame attributes that have a shape, with the results\n+        used to create a new instance.\n+\n+        Internally, it is also used to apply functions to the above parts\n+        (in particular, `~numpy.broadcast_to`).\n+\n+        Parameters\n+        ----------\n+        method : str or callable\n+            If str, it is the name of a method that is applied to the internal\n+            ``components``. If callable, the function is applied.\n+        *args\n+            Any positional arguments for ``method``.\n+        **kwargs : dict\n+            Any keyword arguments for ``method``.\n+        \"\"\"\n+\n+        def apply_method(value):\n+            if isinstance(value, ShapedLikeNDArray):\n+                return value._apply(method, *args, **kwargs)\n+            else:\n+                if callable(method):\n+                    return method(value, *args, **kwargs)\n+                else:\n+                    return getattr(value, method)(*args, **kwargs)\n+\n+        # create a new but empty instance, and copy over stuff\n+        new = super().__new__(self.__class__)\n+        new._sky_coord_frame = self._sky_coord_frame._apply(method, *args, **kwargs)\n+        new._extra_frameattr_names = self._extra_frameattr_names.copy()\n+        for attr in self._extra_frameattr_names:\n+            value = getattr(self, attr)\n+            if getattr(value, \"shape\", ()):\n+                value = apply_method(value)\n+            elif method == \"copy\" or method == \"flatten\":\n+                # flatten should copy also for a single element array, but\n+                # we cannot use it directly for array scalars, since it\n+                # always returns a one-dimensional array. So, just copy.\n+                value = copy.copy(value)\n+            setattr(new, \"_\" + attr, value)\n+\n+        # Copy other 'info' attr only if it has actually been defined.\n+        # See PR #3898 for further explanation and justification, along\n+        # with Quantity.__array_finalize__\n+        if \"info\" in self.__dict__:\n+            new.info = self.info\n+\n+        return new\n+\n+    def __setitem__(self, item, value):\n+        \"\"\"Implement self[item] = value for SkyCoord\n+\n+        The right hand ``value`` must be strictly consistent with self:\n+        - Identical class\n+        - Equivalent frames\n+        - Identical representation_types\n+        - Identical representation differentials keys\n+        - Identical frame attributes\n+        - Identical \"extra\" frame attributes (e.g. obstime for an ICRS coord)\n+\n+        With these caveats the setitem ends up as effectively a setitem on\n+        the representation data.\n+\n+          self.frame.data[item] = value.frame.data\n+        \"\"\"\n+        if self.__class__ is not value.__class__:\n+            raise TypeError(\n+                \"can only set from object of same class: \"\n+                f\"{self.__class__.__name__} vs. {value.__class__.__name__}\"\n+            )\n+\n+        # Make sure that any extra frame attribute names are equivalent.\n+        for attr in self._extra_frameattr_names | value._extra_frameattr_names:\n+            if not self.frame._frameattr_equiv(\n+                getattr(self, attr), getattr(value, attr)\n+            ):\n+                raise ValueError(f\"attribute {attr} is not equivalent\")\n+\n+        # Set the frame values.  This checks frame equivalence and also clears\n+        # the cache to ensure that the object is not in an inconsistent state.\n+        self._sky_coord_frame[item] = value._sky_coord_frame\n+\n+    def insert(self, obj, values, axis=0):\n+        \"\"\"\n+        Insert coordinate values before the given indices in the object and\n+        return a new Frame object.\n+\n+        The values to be inserted must conform to the rules for in-place setting\n+        of ``SkyCoord`` objects.\n+\n+        The API signature matches the ``np.insert`` API, but is more limited.\n+        The specification of insert index ``obj`` must be a single integer,\n+        and the ``axis`` must be ``0`` for simple insertion before the index.\n+\n+        Parameters\n+        ----------\n+        obj : int\n+            Integer index before which ``values`` is inserted.\n+        values : array-like\n+            Value(s) to insert.  If the type of ``values`` is different\n+            from that of quantity, ``values`` is converted to the matching type.\n+        axis : int, optional\n+            Axis along which to insert ``values``.  Default is 0, which is the\n+            only allowed value and will insert a row.\n+\n+        Returns\n+        -------\n+        out : `~astropy.coordinates.SkyCoord` instance\n+            New coordinate object with inserted value(s)\n+\n+        \"\"\"\n+        # Validate inputs: obj arg is integer, axis=0, self is not a scalar, and\n+        # input index is in bounds.\n+        try:\n+            idx0 = operator.index(obj)\n+        except TypeError:\n+            raise TypeError(\"obj arg must be an integer\")\n+\n+        if axis != 0:\n+            raise ValueError(\"axis must be 0\")\n+\n+        if not self.shape:\n+            raise TypeError(\n+                f\"cannot insert into scalar {self.__class__.__name__} object\"\n+            )\n+\n+        if abs(idx0) > len(self):\n+            raise IndexError(\n+                f\"index {idx0} is out of bounds for axis 0 with size {len(self)}\"\n+            )\n+\n+        # Turn negative index into positive\n+        if idx0 < 0:\n+            idx0 = len(self) + idx0\n+\n+        n_values = len(values) if values.shape else 1\n+\n+        # Finally make the new object with the correct length and set values for the\n+        # three sections, before insert, the insert, and after the insert.\n+        out = self.__class__.info.new_like(\n+            [self], len(self) + n_values, name=self.info.name\n+        )\n+\n+        # Set the output values. This is where validation of `values` takes place to ensure\n+        # that it can indeed be inserted.\n+        out[:idx0] = self[:idx0]\n+        out[idx0 : idx0 + n_values] = values\n+        out[idx0 + n_values :] = self[idx0:]\n+\n+        return out\n+\n+    def is_transformable_to(self, new_frame):\n+        \"\"\"\n+        Determines if this coordinate frame can be transformed to another\n+        given frame.\n+\n+        Parameters\n+        ----------\n+        new_frame : frame class, frame object, or str\n+            The proposed frame to transform into.\n+\n+        Returns\n+        -------\n+        transformable : bool or str\n+            `True` if this can be transformed to ``new_frame``, `False` if\n+            not, or the string 'same' if ``new_frame`` is the same system as\n+            this object but no transformation is defined.\n+\n+        Notes\n+        -----\n+        A return value of 'same' means the transformation will work, but it will\n+        just give back a copy of this object.  The intended usage is::\n+\n+            if coord.is_transformable_to(some_unknown_frame):\n+                coord2 = coord.transform_to(some_unknown_frame)\n+\n+        This will work even if ``some_unknown_frame``  turns out to be the same\n+        frame class as ``coord``.  This is intended for cases where the frame\n+        is the same regardless of the frame attributes (e.g. ICRS), but be\n+        aware that it *might* also indicate that someone forgot to define the\n+        transformation between two objects of the same frame class but with\n+        different attributes.\n+        \"\"\"\n+        # TODO! like matplotlib, do string overrides for modified methods\n+        new_frame = (\n+            _get_frame_class(new_frame) if isinstance(new_frame, str) else new_frame\n+        )\n+        return self.frame.is_transformable_to(new_frame)\n+\n+    def transform_to(self, frame, merge_attributes=True):\n+        \"\"\"Transform this coordinate to a new frame.\n+\n+        The precise frame transformed to depends on ``merge_attributes``.\n+        If `False`, the destination frame is used exactly as passed in.\n+        But this is often not quite what one wants.  E.g., suppose one wants to\n+        transform an ICRS coordinate that has an obstime attribute to FK4; in\n+        this case, one likely would want to use this information. Thus, the\n+        default for ``merge_attributes`` is `True`, in which the precedence is\n+        as follows: (1) explicitly set (i.e., non-default) values in the\n+        destination frame; (2) explicitly set values in the source; (3) default\n+        value in the destination frame.\n+\n+        Note that in either case, any explicitly set attributes on the source\n+        `SkyCoord` that are not part of the destination frame's definition are\n+        kept (stored on the resulting `SkyCoord`), and thus one can round-trip\n+        (e.g., from FK4 to ICRS to FK4 without losing obstime).\n+\n+        Parameters\n+        ----------\n+        frame : str, `BaseCoordinateFrame` class or instance, or `SkyCoord` instance\n+            The frame to transform this coordinate into.  If a `SkyCoord`, the\n+            underlying frame is extracted, and all other information ignored.\n+        merge_attributes : bool, optional\n+            Whether the default attributes in the destination frame are allowed\n+            to be overridden by explicitly set attributes in the source\n+            (see note above; default: `True`).\n+\n+        Returns\n+        -------\n+        coord : `SkyCoord`\n+            A new object with this coordinate represented in the `frame` frame.\n+\n+        Raises\n+        ------\n+        ValueError\n+            If there is no possible transformation route.\n+\n+        \"\"\"\n+        from astropy.coordinates.errors import ConvertError\n+\n+        frame_kwargs = {}\n+\n+        # Frame name (string) or frame class?  Coerce into an instance.\n+        try:\n+            frame = _get_frame_class(frame)()\n+        except Exception:\n+            pass\n+\n+        if isinstance(frame, SkyCoord):\n+            frame = frame.frame  # Change to underlying coord frame instance\n+\n+        if isinstance(frame, BaseCoordinateFrame):\n+            new_frame_cls = frame.__class__\n+            # Get frame attributes, allowing defaults to be overridden by\n+            # explicitly set attributes of the source if ``merge_attributes``.\n+            for attr in frame_transform_graph.frame_attributes:\n+                self_val = getattr(self, attr, None)\n+                frame_val = getattr(frame, attr, None)\n+                if frame_val is not None and not (\n+                    merge_attributes and frame.is_frame_attr_default(attr)\n+                ):\n+                    frame_kwargs[attr] = frame_val\n+                elif self_val is not None and not self.is_frame_attr_default(attr):\n+                    frame_kwargs[attr] = self_val\n+                elif frame_val is not None:\n+                    frame_kwargs[attr] = frame_val\n+        else:\n+            raise ValueError(\n+                \"Transform `frame` must be a frame name, class, or instance\"\n+            )\n+\n+        # Get the composite transform to the new frame\n+        trans = frame_transform_graph.get_transform(self.frame.__class__, new_frame_cls)\n+        if trans is None:\n+            raise ConvertError(\n+                f\"Cannot transform from {self.frame.__class__} to {new_frame_cls}\"\n+            )\n+\n+        # Make a generic frame which will accept all the frame kwargs that\n+        # are provided and allow for transforming through intermediate frames\n+        # which may require one or more of those kwargs.\n+        generic_frame = GenericFrame(frame_kwargs)\n+\n+        # Do the transformation, returning a coordinate frame of the desired\n+        # final type (not generic).\n+        new_coord = trans(self.frame, generic_frame)\n+\n+        # Finally make the new SkyCoord object from the `new_coord` and\n+        # remaining frame_kwargs that are not frame_attributes in `new_coord`.\n+        for attr in set(new_coord.frame_attributes) & set(frame_kwargs.keys()):\n+            frame_kwargs.pop(attr)\n+\n+        # Always remove the origin frame attribute, as that attribute only makes\n+        # sense with a SkyOffsetFrame (in which case it will be stored on the frame).\n+        # See gh-11277.\n+        # TODO: Should it be a property of the frame attribute that it can\n+        # or cannot be stored on a SkyCoord?\n+        frame_kwargs.pop(\"origin\", None)\n+\n+        return self.__class__(new_coord, **frame_kwargs)\n+\n+    def apply_space_motion(self, new_obstime=None, dt=None):\n+        \"\"\"\n+        Compute the position of the source represented by this coordinate object\n+        to a new time using the velocities stored in this object and assuming\n+        linear space motion (including relativistic corrections). This is\n+        sometimes referred to as an \"epoch transformation.\"\n+\n+        The initial time before the evolution is taken from the ``obstime``\n+        attribute of this coordinate.  Note that this method currently does not\n+        support evolving coordinates where the *frame* has an ``obstime`` frame\n+        attribute, so the ``obstime`` is only used for storing the before and\n+        after times, not actually as an attribute of the frame. Alternatively,\n+        if ``dt`` is given, an ``obstime`` need not be provided at all.\n+\n+        Parameters\n+        ----------\n+        new_obstime : `~astropy.time.Time`, optional\n+            The time at which to evolve the position to. Requires that the\n+            ``obstime`` attribute be present on this frame.\n+        dt : `~astropy.units.Quantity`, `~astropy.time.TimeDelta`, optional\n+            An amount of time to evolve the position of the source. Cannot be\n+            given at the same time as ``new_obstime``.\n+\n+        Returns\n+        -------\n+        new_coord : `SkyCoord`\n+            A new coordinate object with the evolved location of this coordinate\n+            at the new time.  ``obstime`` will be set on this object to the new\n+            time only if ``self`` also has ``obstime``.\n+        \"\"\"\n+        from .builtin_frames.icrs import ICRS\n+\n+        if (new_obstime is None) == (dt is None):\n+            raise ValueError(\n+                \"You must specify one of `new_obstime` or `dt`, but not both.\"\n+            )\n+\n+        # Validate that we have velocity info\n+        if \"s\" not in self.frame.data.differentials:\n+            raise ValueError(\"SkyCoord requires velocity data to evolve the position.\")\n+\n+        if \"obstime\" in self.frame.frame_attributes:\n+            raise NotImplementedError(\n+                \"Updating the coordinates in a frame with explicit time dependence is\"\n+                \" currently not supported. If you would like this functionality, please\"\n+                \" open an issue on github:\\nhttps://github.com/astropy/astropy\"\n+            )\n+\n+        if new_obstime is not None and self.obstime is None:\n+            # If no obstime is already on this object, raise an error if a new\n+            # obstime is passed: we need to know the time / epoch at which the\n+            # the position / velocity were measured initially\n+            raise ValueError(\n+                \"This object has no associated `obstime`. apply_space_motion() must\"\n+                \" receive a time difference, `dt`, and not a new obstime.\"\n+            )\n+\n+        # Compute t1 and t2, the times used in the starpm call, which *only*\n+        # uses them to compute a delta-time\n+        t1 = self.obstime\n+        if dt is None:\n+            # self.obstime is not None and new_obstime is not None b/c of above\n+            # checks\n+            t2 = new_obstime\n+        else:\n+            # new_obstime is definitely None b/c of the above checks\n+            if t1 is None:\n+                # MAGIC NUMBER: if the current SkyCoord object has no obstime,\n+                # assume J2000 to do the dt offset. This is not actually used\n+                # for anything except a delta-t in starpm, so it's OK that it's\n+                # not necessarily the \"real\" obstime\n+                t1 = Time(\"J2000\")\n+                new_obstime = None  # we don't actually know the initial obstime\n+                t2 = t1 + dt\n+            else:\n+                t2 = t1 + dt\n+                new_obstime = t2\n+        # starpm wants tdb time\n+        t1 = t1.tdb\n+        t2 = t2.tdb\n+\n+        # proper motion in RA should not include the cos(dec) term, see the\n+        # erfa function eraStarpv, comment (4).  So we convert to the regular\n+        # spherical differentials.\n+        icrsrep = self.icrs.represent_as(SphericalRepresentation, SphericalDifferential)\n+        icrsvel = icrsrep.differentials[\"s\"]\n+\n+        parallax_zero = False\n+        try:\n+            plx = icrsrep.distance.to_value(u.arcsecond, u.parallax())\n+        except u.UnitConversionError:  # No distance: set to 0 by convention\n+            plx = 0.0\n+            parallax_zero = True\n+\n+        try:\n+            rv = icrsvel.d_distance.to_value(u.km / u.s)\n+        except u.UnitConversionError:  # No RV\n+            rv = 0.0\n+\n+        starpm = erfa.pmsafe(\n+            icrsrep.lon.radian,\n+            icrsrep.lat.radian,\n+            icrsvel.d_lon.to_value(u.radian / u.yr),\n+            icrsvel.d_lat.to_value(u.radian / u.yr),\n+            plx,\n+            rv,\n+            t1.jd1,\n+            t1.jd2,\n+            t2.jd1,\n+            t2.jd2,\n+        )\n+\n+        if parallax_zero:\n+            new_distance = None\n+        else:\n+            new_distance = Distance(parallax=starpm[4] << u.arcsec)\n+\n+        icrs2 = ICRS(\n+            ra=u.Quantity(starpm[0], u.radian, copy=False),\n+            dec=u.Quantity(starpm[1], u.radian, copy=False),\n+            pm_ra=u.Quantity(starpm[2], u.radian / u.yr, copy=False),\n+            pm_dec=u.Quantity(starpm[3], u.radian / u.yr, copy=False),\n+            distance=new_distance,\n+            radial_velocity=u.Quantity(starpm[5], u.km / u.s, copy=False),\n+            differential_type=SphericalDifferential,\n+        )\n+\n+        # Update the obstime of the returned SkyCoord, and need to carry along\n+        # the frame attributes\n+        frattrs = {\n+            attrnm: getattr(self, attrnm) for attrnm in self._extra_frameattr_names\n+        }\n+        frattrs[\"obstime\"] = new_obstime\n+        result = self.__class__(icrs2, **frattrs).transform_to(self.frame)\n+\n+        # Without this the output might not have the right differential type.\n+        # Not sure if this fixes the problem or just hides it.  See #11932\n+        result.differential_type = self.differential_type\n+\n+        return result\n+\n+    def _is_name(self, string):\n+        \"\"\"\n+        Returns whether a string is one of the aliases for the frame.\n+        \"\"\"\n+        return self.frame.name == string or (\n+            isinstance(self.frame.name, list) and string in self.frame.name\n+        )\n+\n+    def __getattr__(self, attr):\n+        \"\"\"\n+        Overrides getattr to return coordinates that this can be transformed\n+        to, based on the alias attr in the primary transform graph.\n+        \"\"\"\n+        if \"_sky_coord_frame\" in self.__dict__:\n+            if self._is_name(attr):\n+                return self  # Should this be a deepcopy of self?\n+\n+            # Anything in the set of all possible frame_attr_names is handled\n+            # here. If the attr is relevant for the current frame then delegate\n+            # to self.frame otherwise get it from self._<attr>.\n+            if attr in frame_transform_graph.frame_attributes:\n+                if attr in self.frame.frame_attributes:\n+                    return getattr(self.frame, attr)\n+                else:\n+                    return getattr(self, \"_\" + attr, None)\n+\n+            # Some attributes might not fall in the above category but still\n+            # are available through self._sky_coord_frame.\n+            if not attr.startswith(\"_\") and hasattr(self._sky_coord_frame, attr):\n+                return getattr(self._sky_coord_frame, attr)\n+\n+            # Try to interpret as a new frame for transforming.\n+            frame_cls = frame_transform_graph.lookup_name(attr)\n+            if frame_cls is not None and self.frame.is_transformable_to(frame_cls):\n+                return self.transform_to(attr)\n+\n+        # Fail\n+        raise AttributeError(\n+            f\"'{self.__class__.__name__}' object has no attribute '{attr}'\"\n+        )\n+\n+    def __setattr__(self, attr, val):\n+        # This is to make anything available through __getattr__ immutable\n+        if \"_sky_coord_frame\" in self.__dict__:\n+            if self._is_name(attr):\n+                raise AttributeError(f\"'{attr}' is immutable\")\n+\n+            if not attr.startswith(\"_\") and hasattr(self._sky_coord_frame, attr):\n+                setattr(self._sky_coord_frame, attr, val)\n+                return\n+\n+            frame_cls = frame_transform_graph.lookup_name(attr)\n+            if frame_cls is not None and self.frame.is_transformable_to(frame_cls):\n+                raise AttributeError(f\"'{attr}' is immutable\")\n+\n+        if attr in frame_transform_graph.frame_attributes:\n+            # All possible frame attributes can be set, but only via a private\n+            # variable.  See __getattr__ above.\n+            super().__setattr__(\"_\" + attr, val)\n+            # Validate it\n+            frame_transform_graph.frame_attributes[attr].__get__(self)\n+            # And add to set of extra attributes\n+            self._extra_frameattr_names |= {attr}\n+\n+        else:\n+            # Otherwise, do the standard Python attribute setting\n+            super().__setattr__(attr, val)\n+\n+    def __delattr__(self, attr):\n+        # mirror __setattr__ above\n+        if \"_sky_coord_frame\" in self.__dict__:\n+            if self._is_name(attr):\n+                raise AttributeError(f\"'{attr}' is immutable\")\n+\n+            if not attr.startswith(\"_\") and hasattr(self._sky_coord_frame, attr):\n+                delattr(self._sky_coord_frame, attr)\n+                return\n+\n+            frame_cls = frame_transform_graph.lookup_name(attr)\n+            if frame_cls is not None and self.frame.is_transformable_to(frame_cls):\n+                raise AttributeError(f\"'{attr}' is immutable\")\n+\n+        if attr in frame_transform_graph.frame_attributes:\n+            # All possible frame attributes can be deleted, but need to remove\n+            # the corresponding private variable.  See __getattr__ above.\n+            super().__delattr__(\"_\" + attr)\n+            # Also remove it from the set of extra attributes\n+            self._extra_frameattr_names -= {attr}\n+\n+        else:\n+            # Otherwise, do the standard Python attribute setting\n+            super().__delattr__(attr)\n+\n+    def __dir__(self):\n+        \"\"\"\n+        Override the builtin `dir` behavior to include:\n+        - Transforms available by aliases\n+        - Attribute / methods of the underlying self.frame object\n+        \"\"\"\n+        dir_values = set(super().__dir__())\n+\n+        # determine the aliases that this can be transformed to.\n+        for name in frame_transform_graph.get_names():\n+            frame_cls = frame_transform_graph.lookup_name(name)\n+            if self.frame.is_transformable_to(frame_cls):\n+                dir_values.add(name)\n+\n+        # Add public attributes of self.frame\n+        dir_values.update(\n+            {attr for attr in dir(self.frame) if not attr.startswith(\"_\")}\n+        )\n+\n+        # Add all possible frame attributes\n+        dir_values.update(frame_transform_graph.frame_attributes.keys())\n+\n+        return sorted(dir_values)\n+\n+    def __repr__(self):\n+        clsnm = self.__class__.__name__\n+        coonm = self.frame.__class__.__name__\n+        frameattrs = self.frame._frame_attrs_repr()\n+        if frameattrs:\n+            frameattrs = \": \" + frameattrs\n+\n+        data = self.frame._data_repr()\n+        if data:\n+            data = \": \" + data\n+\n+        return f\"<{clsnm} ({coonm}{frameattrs}){data}>\"\n+\n+    def to_string(self, style=\"decimal\", **kwargs):\n+        \"\"\"\n+        A string representation of the coordinates.\n+\n+        The default styles definitions are::\n+\n+          'decimal': 'lat': {'decimal': True, 'unit': \"deg\"}\n+                     'lon': {'decimal': True, 'unit': \"deg\"}\n+          'dms': 'lat': {'unit': \"deg\"}\n+                 'lon': {'unit': \"deg\"}\n+          'hmsdms': 'lat': {'alwayssign': True, 'pad': True, 'unit': \"deg\"}\n+                    'lon': {'pad': True, 'unit': \"hour\"}\n+\n+        See :meth:`~astropy.coordinates.Angle.to_string` for details and\n+        keyword arguments (the two angles forming the coordinates are are\n+        both :class:`~astropy.coordinates.Angle` instances). Keyword\n+        arguments have precedence over the style defaults and are passed\n+        to :meth:`~astropy.coordinates.Angle.to_string`.\n+\n+        Parameters\n+        ----------\n+        style : {'hmsdms', 'dms', 'decimal'}\n+            The formatting specification to use. These encode the three most\n+            common ways to represent coordinates. The default is `decimal`.\n+        **kwargs\n+            Keyword args passed to :meth:`~astropy.coordinates.Angle.to_string`.\n+        \"\"\"\n+\n+        sph_coord = self.frame.represent_as(SphericalRepresentation)\n+\n+        styles = {\n+            \"hmsdms\": {\n+                \"lonargs\": {\"unit\": u.hour, \"pad\": True},\n+                \"latargs\": {\"unit\": u.degree, \"pad\": True, \"alwayssign\": True},\n+            },\n+            \"dms\": {\"lonargs\": {\"unit\": u.degree}, \"latargs\": {\"unit\": u.degree}},\n+            \"decimal\": {\n+                \"lonargs\": {\"unit\": u.degree, \"decimal\": True},\n+                \"latargs\": {\"unit\": u.degree, \"decimal\": True},\n+            },\n+        }\n+\n+        lonargs = {}\n+        latargs = {}\n+\n+        if style in styles:\n+            lonargs.update(styles[style][\"lonargs\"])\n+            latargs.update(styles[style][\"latargs\"])\n+        else:\n+            raise ValueError(f\"Invalid style.  Valid options are: {','.join(styles)}\")\n+\n+        lonargs.update(kwargs)\n+        latargs.update(kwargs)\n+\n+        if np.isscalar(sph_coord.lon.value):\n+            coord_string = (\n+                f\"{sph_coord.lon.to_string(**lonargs)}\"\n+                f\" {sph_coord.lat.to_string(**latargs)}\"\n+            )\n+        else:\n+            coord_string = []\n+            for lonangle, latangle in zip(sph_coord.lon.ravel(), sph_coord.lat.ravel()):\n+                coord_string += [\n+                    f\"{lonangle.to_string(**lonargs)} {latangle.to_string(**latargs)}\"\n+                ]\n+            if len(sph_coord.shape) > 1:\n+                coord_string = np.array(coord_string).reshape(sph_coord.shape)\n+\n+        return coord_string\n+\n+    def to_table(self):\n+        \"\"\"\n+        Convert this |SkyCoord| to a |QTable|.\n+\n+        Any attributes that have the same length as the |SkyCoord| will be\n+        converted to columns of the |QTable|. All other attributes will be\n+        recorded as metadata.\n+\n+        Returns\n+        -------\n+        `~astropy.table.QTable`\n+            A |QTable| containing the data of this |SkyCoord|.\n+\n+        Examples\n+        --------\n+        >>> sc = SkyCoord(ra=[40, 70]*u.deg, dec=[0, -20]*u.deg,\n+        ...               obstime=Time([2000, 2010], format='jyear'))\n+        >>> t =  sc.to_table()\n+        >>> t\n+        <QTable length=2>\n+           ra     dec   obstime\n+          deg     deg\n+        float64 float64   Time\n+        ------- ------- -------\n+           40.0     0.0  2000.0\n+           70.0   -20.0  2010.0\n+        >>> t.meta\n+        {'representation_type': 'spherical', 'frame': 'icrs'}\n+        \"\"\"\n+        self_as_dict = self.info._represent_as_dict()\n+        tabledata = {}\n+        metadata = {}\n+        # Record attributes that have the same length as self as columns in the\n+        # table, and the other attributes as table metadata.  This matches\n+        # table.serialize._represent_mixin_as_column().\n+        for key, value in self_as_dict.items():\n+            if getattr(value, \"shape\", ())[:1] == (len(self),):\n+                tabledata[key] = value\n+            else:\n+                metadata[key] = value\n+        return QTable(tabledata, meta=metadata)\n+\n+    def is_equivalent_frame(self, other):\n+        \"\"\"\n+        Checks if this object's frame as the same as that of the ``other``\n+        object.\n+\n+        To be the same frame, two objects must be the same frame class and have\n+        the same frame attributes. For two `SkyCoord` objects, *all* of the\n+        frame attributes have to match, not just those relevant for the object's\n+        frame.\n+\n+        Parameters\n+        ----------\n+        other : SkyCoord or BaseCoordinateFrame\n+            The other object to check.\n+\n+        Returns\n+        -------\n+        isequiv : bool\n+            True if the frames are the same, False if not.\n+\n+        Raises\n+        ------\n+        TypeError\n+            If ``other`` isn't a `SkyCoord` or a `BaseCoordinateFrame` or subclass.\n+        \"\"\"\n+        if isinstance(other, BaseCoordinateFrame):\n+            return self.frame.is_equivalent_frame(other)\n+        elif isinstance(other, SkyCoord):\n+            if other.frame.name != self.frame.name:\n+                return False\n+\n+            for fattrnm in frame_transform_graph.frame_attributes:\n+                if not BaseCoordinateFrame._frameattr_equiv(\n+                    getattr(self, fattrnm), getattr(other, fattrnm)\n+                ):\n+                    return False\n+            return True\n+        else:\n+            # not a BaseCoordinateFrame nor a SkyCoord object\n+            raise TypeError(\n+                \"Tried to do is_equivalent_frame on something that isn't frame-like\"\n+            )\n+\n+    # High-level convenience methods\n+    def separation(self, other):\n+        \"\"\"\n+        Computes on-sky separation between this coordinate and another.\n+\n+        .. note::\n+\n+            If the ``other`` coordinate object is in a different frame, it is\n+            first transformed to the frame of this object. This can lead to\n+            unintuitive behavior if not accounted for. Particularly of note is\n+            that ``self.separation(other)`` and ``other.separation(self)`` may\n+            not give the same answer in this case.\n+\n+        For more on how to use this (and related) functionality, see the\n+        examples in :doc:`astropy:/coordinates/matchsep`.\n+\n+        Parameters\n+        ----------\n+        other : `~astropy.coordinates.SkyCoord` or `~astropy.coordinates.BaseCoordinateFrame`\n+            The coordinate to get the separation to.\n+\n+        Returns\n+        -------\n+        sep : `~astropy.coordinates.Angle`\n+            The on-sky separation between this and the ``other`` coordinate.\n+\n+        Notes\n+        -----\n+        The separation is calculated using the Vincenty formula, which\n+        is stable at all locations, including poles and antipodes [1]_.\n+\n+        .. [1] https://en.wikipedia.org/wiki/Great-circle_distance\n+\n+        \"\"\"\n+        from . import Angle\n+        from .angle_utilities import angular_separation\n+\n+        if not self.is_equivalent_frame(other):\n+            try:\n+                kwargs = (\n+                    {\"merge_attributes\": False} if isinstance(other, SkyCoord) else {}\n+                )\n+                other = other.transform_to(self, **kwargs)\n+            except TypeError:\n+                raise TypeError(\n+                    \"Can only get separation to another SkyCoord \"\n+                    \"or a coordinate frame with data\"\n+                )\n+\n+        lon1 = self.spherical.lon\n+        lat1 = self.spherical.lat\n+        lon2 = other.spherical.lon\n+        lat2 = other.spherical.lat\n+\n+        # Get the separation as a Quantity, convert to Angle in degrees\n+        sep = angular_separation(lon1, lat1, lon2, lat2)\n+        return Angle(sep, unit=u.degree)\n+\n+    def separation_3d(self, other):\n+        \"\"\"\n+        Computes three dimensional separation between this coordinate\n+        and another.\n+\n+        For more on how to use this (and related) functionality, see the\n+        examples in :doc:`astropy:/coordinates/matchsep`.\n+\n+        Parameters\n+        ----------\n+        other : `~astropy.coordinates.SkyCoord` or `~astropy.coordinates.BaseCoordinateFrame`\n+            The coordinate to get the separation to.\n+\n+        Returns\n+        -------\n+        sep : `~astropy.coordinates.Distance`\n+            The real-space distance between these two coordinates.\n+\n+        Raises\n+        ------\n+        ValueError\n+            If this or the other coordinate do not have distances.\n+        \"\"\"\n+        if not self.is_equivalent_frame(other):\n+            try:\n+                kwargs = (\n+                    {\"merge_attributes\": False} if isinstance(other, SkyCoord) else {}\n+                )\n+                other = other.transform_to(self, **kwargs)\n+            except TypeError:\n+                raise TypeError(\n+                    \"Can only get separation to another SkyCoord \"\n+                    \"or a coordinate frame with data\"\n+                )\n+\n+        if issubclass(self.data.__class__, UnitSphericalRepresentation):\n+            raise ValueError(\n+                \"This object does not have a distance; cannot compute 3d separation.\"\n+            )\n+        if issubclass(other.data.__class__, UnitSphericalRepresentation):\n+            raise ValueError(\n+                \"The other object does not have a distance; \"\n+                \"cannot compute 3d separation.\"\n+            )\n+\n+        c1 = self.cartesian.without_differentials()\n+        c2 = other.cartesian.without_differentials()\n+        return Distance((c1 - c2).norm())\n+\n+    def spherical_offsets_to(self, tocoord):\n+        r\"\"\"\n+        Computes angular offsets to go *from* this coordinate *to* another.\n+\n+        Parameters\n+        ----------\n+        tocoord : `~astropy.coordinates.BaseCoordinateFrame`\n+            The coordinate to find the offset to.\n+\n+        Returns\n+        -------\n+        lon_offset : `~astropy.coordinates.Angle`\n+            The angular offset in the longitude direction. The definition of\n+            \"longitude\" depends on this coordinate's frame (e.g., RA for\n+            equatorial coordinates).\n+        lat_offset : `~astropy.coordinates.Angle`\n+            The angular offset in the latitude direction. The definition of\n+            \"latitude\" depends on this coordinate's frame (e.g., Dec for\n+            equatorial coordinates).\n+\n+        Raises\n+        ------\n+        ValueError\n+            If the ``tocoord`` is not in the same frame as this one. This is\n+            different from the behavior of the `separation`/`separation_3d`\n+            methods because the offset components depend critically on the\n+            specific choice of frame.\n+\n+        Notes\n+        -----\n+        This uses the sky offset frame machinery, and hence will produce a new\n+        sky offset frame if one does not already exist for this object's frame\n+        class.\n+\n+        See Also\n+        --------\n+        separation :\n+            for the *total* angular offset (not broken out into components).\n+        position_angle :\n+            for the direction of the offset.\n+\n+        \"\"\"\n+        if not self.is_equivalent_frame(tocoord):\n+            raise ValueError(\n+                \"Tried to use spherical_offsets_to with two non-matching frames!\"\n+            )\n+\n+        aframe = self.skyoffset_frame()\n+        acoord = tocoord.transform_to(aframe)\n+\n+        dlon = acoord.spherical.lon.view(Angle)\n+        dlat = acoord.spherical.lat.view(Angle)\n+        return dlon, dlat\n+\n+    def spherical_offsets_by(self, d_lon, d_lat):\n+        \"\"\"\n+        Computes the coordinate that is a specified pair of angular offsets away\n+        from this coordinate.\n+\n+        Parameters\n+        ----------\n+        d_lon : angle-like\n+            The angular offset in the longitude direction. The definition of\n+            \"longitude\" depends on this coordinate's frame (e.g., RA for\n+            equatorial coordinates).\n+        d_lat : angle-like\n+            The angular offset in the latitude direction. The definition of\n+            \"latitude\" depends on this coordinate's frame (e.g., Dec for\n+            equatorial coordinates).\n+\n+        Returns\n+        -------\n+        newcoord : `~astropy.coordinates.SkyCoord`\n+            The coordinates for the location that corresponds to offsetting by\n+            ``d_lat`` in the latitude direction and ``d_lon`` in the longitude\n+            direction.\n+\n+        Notes\n+        -----\n+        This internally uses `~astropy.coordinates.SkyOffsetFrame` to do the\n+        transformation. For a more complete set of transform offsets, use\n+        `~astropy.coordinates.SkyOffsetFrame` or `~astropy.wcs.WCS` manually.\n+        This specific method can be reproduced by doing\n+        ``SkyCoord(SkyOffsetFrame(d_lon, d_lat, origin=self.frame).transform_to(self))``.\n+\n+        See Also\n+        --------\n+        spherical_offsets_to : compute the angular offsets to another coordinate\n+        directional_offset_by : offset a coordinate by an angle in a direction\n+        \"\"\"\n+        from .builtin_frames.skyoffset import SkyOffsetFrame\n+\n+        return self.__class__(\n+            SkyOffsetFrame(d_lon, d_lat, origin=self.frame).transform_to(self)\n+        )\n+\n+    def directional_offset_by(self, position_angle, separation):\n+        \"\"\"\n+        Computes coordinates at the given offset from this coordinate.\n+\n+        Parameters\n+        ----------\n+        position_angle : `~astropy.coordinates.Angle`\n+            position_angle of offset\n+        separation : `~astropy.coordinates.Angle`\n+            offset angular separation\n+\n+        Returns\n+        -------\n+        newpoints : `~astropy.coordinates.SkyCoord`\n+            The coordinates for the location that corresponds to offsetting by\n+            the given `position_angle` and `separation`.\n+\n+        Notes\n+        -----\n+        Returned SkyCoord frame retains only the frame attributes that are for\n+        the resulting frame type.  (e.g. if the input frame is\n+        `~astropy.coordinates.ICRS`, an ``equinox`` value will be retained, but\n+        an ``obstime`` will not.)\n+\n+        For a more complete set of transform offsets, use `~astropy.wcs.WCS`.\n+        `~astropy.coordinates.SkyCoord.skyoffset_frame()` can also be used to\n+        create a spherical frame with (lat=0, lon=0) at a reference point,\n+        approximating an xy cartesian system for small offsets. This method\n+        is distinct in that it is accurate on the sphere.\n+\n+        See Also\n+        --------\n+        position_angle : inverse operation for the ``position_angle`` component\n+        separation : inverse operation for the ``separation`` component\n+\n+        \"\"\"\n+        from . import angle_utilities\n+\n+        slat = self.represent_as(UnitSphericalRepresentation).lat\n+        slon = self.represent_as(UnitSphericalRepresentation).lon\n+\n+        newlon, newlat = angle_utilities.offset_by(\n+            lon=slon, lat=slat, posang=position_angle, distance=separation\n+        )\n+\n+        return SkyCoord(newlon, newlat, frame=self.frame)\n+\n+    def match_to_catalog_sky(self, catalogcoord, nthneighbor=1):\n+        \"\"\"\n+        Finds the nearest on-sky matches of this coordinate in a set of\n+        catalog coordinates.\n+\n+        For more on how to use this (and related) functionality, see the\n+        examples in :doc:`astropy:/coordinates/matchsep`.\n+\n+        Parameters\n+        ----------\n+        catalogcoord : `~astropy.coordinates.SkyCoord` or `~astropy.coordinates.BaseCoordinateFrame`\n+            The base catalog in which to search for matches. Typically this\n+            will be a coordinate object that is an array (i.e.,\n+            ``catalogcoord.isscalar == False``)\n+        nthneighbor : int, optional\n+            Which closest neighbor to search for.  Typically ``1`` is\n+            desired here, as that is correct for matching one set of\n+            coordinates to another. The next likely use case is ``2``,\n+            for matching a coordinate catalog against *itself* (``1``\n+            is inappropriate because each point will find itself as the\n+            closest match).\n+\n+        Returns\n+        -------\n+        idx : int array\n+            Indices into ``catalogcoord`` to get the matched points for\n+            each of this object's coordinates. Shape matches this\n+            object.\n+        sep2d : `~astropy.coordinates.Angle`\n+            The on-sky separation between the closest match for each\n+            element in this object in ``catalogcoord``. Shape matches\n+            this object.\n+        dist3d : `~astropy.units.Quantity` ['length']\n+            The 3D distance between the closest match for each element\n+            in this object in ``catalogcoord``. Shape matches this\n+            object. Unless both this and ``catalogcoord`` have associated\n+            distances, this quantity assumes that all sources are at a\n+            distance of 1 (dimensionless).\n+\n+        Notes\n+        -----\n+        This method requires `SciPy <https://www.scipy.org/>`_ to be\n+        installed or it will fail.\n+\n+        See Also\n+        --------\n+        astropy.coordinates.match_coordinates_sky\n+        SkyCoord.match_to_catalog_3d\n+        \"\"\"\n+        from .matching import match_coordinates_sky\n+\n+        if not (\n+            isinstance(catalogcoord, (SkyCoord, BaseCoordinateFrame))\n+            and catalogcoord.has_data\n+        ):\n+            raise TypeError(\n+                \"Can only get separation to another SkyCoord or a \"\n+                \"coordinate frame with data\"\n+            )\n+\n+        res = match_coordinates_sky(\n+            self, catalogcoord, nthneighbor=nthneighbor, storekdtree=\"_kdtree_sky\"\n+        )\n+        return res\n+\n+    def match_to_catalog_3d(self, catalogcoord, nthneighbor=1):\n+        \"\"\"\n+        Finds the nearest 3-dimensional matches of this coordinate to a set\n+        of catalog coordinates.\n+\n+        This finds the 3-dimensional closest neighbor, which is only different\n+        from the on-sky distance if ``distance`` is set in this object or the\n+        ``catalogcoord`` object.\n+\n+        For more on how to use this (and related) functionality, see the\n+        examples in :doc:`astropy:/coordinates/matchsep`.\n+\n+        Parameters\n+        ----------\n+        catalogcoord : `~astropy.coordinates.SkyCoord` or `~astropy.coordinates.BaseCoordinateFrame`\n+            The base catalog in which to search for matches. Typically this\n+            will be a coordinate object that is an array (i.e.,\n+            ``catalogcoord.isscalar == False``)\n+        nthneighbor : int, optional\n+            Which closest neighbor to search for.  Typically ``1`` is\n+            desired here, as that is correct for matching one set of\n+            coordinates to another.  The next likely use case is\n+            ``2``, for matching a coordinate catalog against *itself*\n+            (``1`` is inappropriate because each point will find\n+            itself as the closest match).\n+\n+        Returns\n+        -------\n+        idx : int array\n+            Indices into ``catalogcoord`` to get the matched points for\n+            each of this object's coordinates. Shape matches this\n+            object.\n+        sep2d : `~astropy.coordinates.Angle`\n+            The on-sky separation between the closest match for each\n+            element in this object in ``catalogcoord``. Shape matches\n+            this object.\n+        dist3d : `~astropy.units.Quantity` ['length']\n+            The 3D distance between the closest match for each element\n+            in this object in ``catalogcoord``. Shape matches this\n+            object.\n+\n+        Notes\n+        -----\n+        This method requires `SciPy <https://www.scipy.org/>`_ to be\n+        installed or it will fail.\n+\n+        See Also\n+        --------\n+        astropy.coordinates.match_coordinates_3d\n+        SkyCoord.match_to_catalog_sky\n+        \"\"\"\n+        from .matching import match_coordinates_3d\n+\n+        if not (\n+            isinstance(catalogcoord, (SkyCoord, BaseCoordinateFrame))\n+            and catalogcoord.has_data\n+        ):\n+            raise TypeError(\n+                \"Can only get separation to another SkyCoord or a \"\n+                \"coordinate frame with data\"\n+            )\n+\n+        res = match_coordinates_3d(\n+            self, catalogcoord, nthneighbor=nthneighbor, storekdtree=\"_kdtree_3d\"\n+        )\n+\n+        return res\n+\n+    def search_around_sky(self, searcharoundcoords, seplimit):\n+        \"\"\"\n+        Searches for all coordinates in this object around a supplied set of\n+        points within a given on-sky separation.\n+\n+        This is intended for use on `~astropy.coordinates.SkyCoord` objects\n+        with coordinate arrays, rather than a scalar coordinate.  For a scalar\n+        coordinate, it is better to use\n+        `~astropy.coordinates.SkyCoord.separation`.\n+\n+        For more on how to use this (and related) functionality, see the\n+        examples in :doc:`astropy:/coordinates/matchsep`.\n+\n+        Parameters\n+        ----------\n+        searcharoundcoords : coordinate-like\n+            The coordinates to search around to try to find matching points in\n+            this `SkyCoord`. This should be an object with array coordinates,\n+            not a scalar coordinate object.\n+        seplimit : `~astropy.units.Quantity` ['angle']\n+            The on-sky separation to search within.\n+\n+        Returns\n+        -------\n+        idxsearcharound : int array\n+            Indices into ``searcharoundcoords`` that match the\n+            corresponding elements of ``idxself``. Shape matches\n+            ``idxself``.\n+        idxself : int array\n+            Indices into ``self`` that match the\n+            corresponding elements of ``idxsearcharound``. Shape matches\n+            ``idxsearcharound``.\n+        sep2d : `~astropy.coordinates.Angle`\n+            The on-sky separation between the coordinates. Shape matches\n+            ``idxsearcharound`` and ``idxself``.\n+        dist3d : `~astropy.units.Quantity` ['length']\n+            The 3D distance between the coordinates. Shape matches\n+            ``idxsearcharound`` and ``idxself``.\n+\n+        Notes\n+        -----\n+        This method requires `SciPy <https://www.scipy.org/>`_ to be\n+        installed or it will fail.\n+\n+        In the current implementation, the return values are always sorted in\n+        the same order as the ``searcharoundcoords`` (so ``idxsearcharound`` is\n+        in ascending order).  This is considered an implementation detail,\n+        though, so it could change in a future release.\n+\n+        See Also\n+        --------\n+        astropy.coordinates.search_around_sky\n+        SkyCoord.search_around_3d\n+        \"\"\"\n+        from .matching import search_around_sky\n+\n+        return search_around_sky(\n+            searcharoundcoords, self, seplimit, storekdtree=\"_kdtree_sky\"\n+        )\n+\n+    def search_around_3d(self, searcharoundcoords, distlimit):\n+        \"\"\"\n+        Searches for all coordinates in this object around a supplied set of\n+        points within a given 3D radius.\n+\n+        This is intended for use on `~astropy.coordinates.SkyCoord` objects\n+        with coordinate arrays, rather than a scalar coordinate.  For a scalar\n+        coordinate, it is better to use\n+        `~astropy.coordinates.SkyCoord.separation_3d`.\n+\n+        For more on how to use this (and related) functionality, see the\n+        examples in :doc:`astropy:/coordinates/matchsep`.\n+\n+        Parameters\n+        ----------\n+        searcharoundcoords : `~astropy.coordinates.SkyCoord` or `~astropy.coordinates.BaseCoordinateFrame`\n+            The coordinates to search around to try to find matching points in\n+            this `SkyCoord`. This should be an object with array coordinates,\n+            not a scalar coordinate object.\n+        distlimit : `~astropy.units.Quantity` ['length']\n+            The physical radius to search within.\n+\n+        Returns\n+        -------\n+        idxsearcharound : int array\n+            Indices into ``searcharoundcoords`` that match the\n+            corresponding elements of ``idxself``. Shape matches\n+            ``idxself``.\n+        idxself : int array\n+            Indices into ``self`` that match the\n+            corresponding elements of ``idxsearcharound``. Shape matches\n+            ``idxsearcharound``.\n+        sep2d : `~astropy.coordinates.Angle`\n+            The on-sky separation between the coordinates. Shape matches\n+            ``idxsearcharound`` and ``idxself``.\n+        dist3d : `~astropy.units.Quantity` ['length']\n+            The 3D distance between the coordinates. Shape matches\n+            ``idxsearcharound`` and ``idxself``.\n+\n+        Notes\n+        -----\n+        This method requires `SciPy <https://www.scipy.org/>`_ to be\n+        installed or it will fail.\n+\n+        In the current implementation, the return values are always sorted in\n+        the same order as the ``searcharoundcoords`` (so ``idxsearcharound`` is\n+        in ascending order).  This is considered an implementation detail,\n+        though, so it could change in a future release.\n+\n+        See Also\n+        --------\n+        astropy.coordinates.search_around_3d\n+        SkyCoord.search_around_sky\n+        \"\"\"\n+        from .matching import search_around_3d\n+\n+        return search_around_3d(\n+            searcharoundcoords, self, distlimit, storekdtree=\"_kdtree_3d\"\n+        )\n+\n+    def position_angle(self, other):\n+        \"\"\"\n+        Computes the on-sky position angle (East of North) between this\n+        `SkyCoord` and another.\n+\n+        Parameters\n+        ----------\n+        other : `SkyCoord`\n+            The other coordinate to compute the position angle to.  It is\n+            treated as the \"head\" of the vector of the position angle.\n+\n+        Returns\n+        -------\n+        pa : `~astropy.coordinates.Angle`\n+            The (positive) position angle of the vector pointing from ``self``\n+            to ``other``.  If either ``self`` or ``other`` contain arrays, this\n+            will be an array following the appropriate `numpy` broadcasting\n+            rules.\n+\n+        Examples\n+        --------\n+        >>> c1 = SkyCoord(0*u.deg, 0*u.deg)\n+        >>> c2 = SkyCoord(1*u.deg, 0*u.deg)\n+        >>> c1.position_angle(c2).degree\n+        90.0\n+        >>> c3 = SkyCoord(1*u.deg, 1*u.deg)\n+        >>> c1.position_angle(c3).degree  # doctest: +FLOAT_CMP\n+        44.995636455344844\n+        \"\"\"\n+        from . import angle_utilities\n+\n+        if not self.is_equivalent_frame(other):\n+            try:\n+                other = other.transform_to(self, merge_attributes=False)\n+            except TypeError:\n+                raise TypeError(\n+                    \"Can only get position_angle to another \"\n+                    \"SkyCoord or a coordinate frame with data\"\n+                )\n+\n+        slat = self.represent_as(UnitSphericalRepresentation).lat\n+        slon = self.represent_as(UnitSphericalRepresentation).lon\n+        olat = other.represent_as(UnitSphericalRepresentation).lat\n+        olon = other.represent_as(UnitSphericalRepresentation).lon\n+\n+        return angle_utilities.position_angle(slon, slat, olon, olat)\n+\n+    def skyoffset_frame(self, rotation=None):\n+        \"\"\"\n+        Returns the sky offset frame with this `SkyCoord` at the origin.\n+\n+        Returns\n+        -------\n+        astrframe : `~astropy.coordinates.SkyOffsetFrame`\n+            A sky offset frame of the same type as this `SkyCoord` (e.g., if\n+            this object has an ICRS coordinate, the resulting frame is\n+            SkyOffsetICRS, with the origin set to this object)\n+        rotation : angle-like\n+            The final rotation of the frame about the ``origin``. The sign of\n+            the rotation is the left-hand rule. That is, an object at a\n+            particular position angle in the un-rotated system will be sent to\n+            the positive latitude (z) direction in the final frame.\n+        \"\"\"\n+        from .builtin_frames.skyoffset import SkyOffsetFrame\n+\n+        return SkyOffsetFrame(origin=self, rotation=rotation)\n+\n+    def get_constellation(self, short_name=False, constellation_list=\"iau\"):\n+        \"\"\"\n+        Determines the constellation(s) of the coordinates this `SkyCoord`\n+        contains.\n+\n+        Parameters\n+        ----------\n+        short_name : bool\n+            If True, the returned names are the IAU-sanctioned abbreviated\n+            names.  Otherwise, full names for the constellations are used.\n+        constellation_list : str\n+            The set of constellations to use.  Currently only ``'iau'`` is\n+            supported, meaning the 88 \"modern\" constellations endorsed by the IAU.\n+\n+        Returns\n+        -------\n+        constellation : str or string array\n+            If this is a scalar coordinate, returns the name of the\n+            constellation.  If it is an array `SkyCoord`, it returns an array of\n+            names.\n+\n+        Notes\n+        -----\n+        To determine which constellation a point on the sky is in, this first\n+        precesses to B1875, and then uses the Delporte boundaries of the 88\n+        modern constellations, as tabulated by\n+        `Roman 1987 <http://cdsarc.u-strasbg.fr/viz-bin/Cat?VI/42>`_.\n+\n+        See Also\n+        --------\n+        astropy.coordinates.get_constellation\n+        \"\"\"\n+        from .funcs import get_constellation\n+\n+        # because of issue #7028, the conversion to a PrecessedGeocentric\n+        # system fails in some cases.  Work around is to  drop the velocities.\n+        # they are not needed here since only position information is used\n+        extra_frameattrs = {nm: getattr(self, nm) for nm in self._extra_frameattr_names}\n+        novel = SkyCoord(\n+            self.realize_frame(self.data.without_differentials()), **extra_frameattrs\n+        )\n+        return get_constellation(novel, short_name, constellation_list)\n+\n+        # the simpler version below can be used when gh-issue #7028 is resolved\n+        # return get_constellation(self, short_name, constellation_list)\n+\n+    # WCS pixel to/from sky conversions\n+    def to_pixel(self, wcs, origin=0, mode=\"all\"):\n+        \"\"\"\n+        Convert this coordinate to pixel coordinates using a `~astropy.wcs.WCS`\n+        object.\n+\n+        Parameters\n+        ----------\n+        wcs : `~astropy.wcs.WCS`\n+            The WCS to use for convert\n+        origin : int\n+            Whether to return 0 or 1-based pixel coordinates.\n+        mode : 'all' or 'wcs'\n+            Whether to do the transformation including distortions (``'all'``) or\n+            only including only the core WCS transformation (``'wcs'``).\n+\n+        Returns\n+        -------\n+        xp, yp : `numpy.ndarray`\n+            The pixel coordinates\n+\n+        See Also\n+        --------\n+        astropy.wcs.utils.skycoord_to_pixel : the implementation of this method\n+        \"\"\"\n+        from astropy.wcs.utils import skycoord_to_pixel\n+\n+        return skycoord_to_pixel(self, wcs=wcs, origin=origin, mode=mode)\n+\n+    @classmethod\n+    def from_pixel(cls, xp, yp, wcs, origin=0, mode=\"all\"):\n+        \"\"\"\n+        Create a new `SkyCoord` from pixel coordinates using an\n+        `~astropy.wcs.WCS` object.\n+\n+        Parameters\n+        ----------\n+        xp, yp : float or ndarray\n+            The coordinates to convert.\n+        wcs : `~astropy.wcs.WCS`\n+            The WCS to use for convert\n+        origin : int\n+            Whether to return 0 or 1-based pixel coordinates.\n+        mode : 'all' or 'wcs'\n+            Whether to do the transformation including distortions (``'all'``) or\n+            only including only the core WCS transformation (``'wcs'``).\n+\n+        Returns\n+        -------\n+        coord : `~astropy.coordinates.SkyCoord`\n+            A new object with sky coordinates corresponding to the input ``xp``\n+            and ``yp``.\n+\n+        See Also\n+        --------\n+        to_pixel : to do the inverse operation\n+        astropy.wcs.utils.pixel_to_skycoord : the implementation of this method\n+        \"\"\"\n+        from astropy.wcs.utils import pixel_to_skycoord\n+\n+        return pixel_to_skycoord(xp, yp, wcs=wcs, origin=origin, mode=mode, cls=cls)\n+\n+    def contained_by(self, wcs, image=None, **kwargs):\n+        \"\"\"\n+        Determines if the SkyCoord is contained in the given wcs footprint.\n+\n+        Parameters\n+        ----------\n+        wcs : `~astropy.wcs.WCS`\n+            The coordinate to check if it is within the wcs coordinate.\n+        image : array\n+            Optional.  The image associated with the wcs object that the cooordinate\n+            is being checked against. If not given the naxis keywords will be used\n+            to determine if the coordinate falls within the wcs footprint.\n+        **kwargs\n+            Additional arguments to pass to `~astropy.coordinates.SkyCoord.to_pixel`\n+\n+        Returns\n+        -------\n+        response : bool\n+            True means the WCS footprint contains the coordinate, False means it does not.\n+        \"\"\"\n+\n+        if image is not None:\n+            ymax, xmax = image.shape\n+        else:\n+            xmax, ymax = wcs._naxis\n+\n+        import warnings\n+\n+        with warnings.catch_warnings():\n+            #  Suppress warnings since they just mean we didn't find the coordinate\n+            warnings.simplefilter(\"ignore\")\n+            try:\n+                x, y = self.to_pixel(wcs, **kwargs)\n+            except Exception:\n+                return False\n+\n+        return (x < xmax) & (x > 0) & (y < ymax) & (y > 0)\n+\n+    def radial_velocity_correction(\n+        self, kind=\"barycentric\", obstime=None, location=None\n+    ):\n+        \"\"\"\n+        Compute the correction required to convert a radial velocity at a given\n+        time and place on the Earth's Surface to a barycentric or heliocentric\n+        velocity.\n+\n+        Parameters\n+        ----------\n+        kind : str\n+            The kind of velocity correction.  Must be 'barycentric' or\n+            'heliocentric'.\n+        obstime : `~astropy.time.Time` or None, optional\n+            The time at which to compute the correction.  If `None`, the\n+            ``obstime`` frame attribute on the `SkyCoord` will be used.\n+        location : `~astropy.coordinates.EarthLocation` or None, optional\n+            The observer location at which to compute the correction.  If\n+            `None`, the  ``location`` frame attribute on the passed-in\n+            ``obstime`` will be used, and if that is None, the ``location``\n+            frame attribute on the `SkyCoord` will be used.\n+\n+        Raises\n+        ------\n+        ValueError\n+            If either ``obstime`` or ``location`` are passed in (not ``None``)\n+            when the frame attribute is already set on this `SkyCoord`.\n+        TypeError\n+            If ``obstime`` or ``location`` aren't provided, either as arguments\n+            or as frame attributes.\n+\n+        Returns\n+        -------\n+        vcorr : `~astropy.units.Quantity` ['speed']\n+            The  correction with a positive sign.  I.e., *add* this\n+            to an observed radial velocity to get the barycentric (or\n+            heliocentric) velocity. If m/s precision or better is needed,\n+            see the notes below.\n+\n+        Notes\n+        -----\n+        The barycentric correction is calculated to higher precision than the\n+        heliocentric correction and includes additional physics (e.g time dilation).\n+        Use barycentric corrections if m/s precision is required.\n+\n+        The algorithm here is sufficient to perform corrections at the mm/s level, but\n+        care is needed in application. The barycentric correction returned uses the optical\n+        approximation v = z * c. Strictly speaking, the barycentric correction is\n+        multiplicative and should be applied as::\n+\n+          >>> from astropy.time import Time\n+          >>> from astropy.coordinates import SkyCoord, EarthLocation\n+          >>> from astropy.constants import c\n+          >>> t = Time(56370.5, format='mjd', scale='utc')\n+          >>> loc = EarthLocation('149d33m00.5s','-30d18m46.385s',236.87*u.m)\n+          >>> sc = SkyCoord(1*u.deg, 2*u.deg)\n+          >>> vcorr = sc.radial_velocity_correction(kind='barycentric', obstime=t, location=loc)  # doctest: +REMOTE_DATA\n+          >>> rv = rv + vcorr + rv * vcorr / c  # doctest: +SKIP\n+\n+        Also note that this method returns the correction velocity in the so-called\n+        *optical convention*::\n+\n+          >>> vcorr = zb * c  # doctest: +SKIP\n+\n+        where ``zb`` is the barycentric correction redshift as defined in section 3\n+        of Wright & Eastman (2014). The application formula given above follows from their\n+        equation (11) under assumption that the radial velocity ``rv`` has also been defined\n+        using the same optical convention. Note, this can be regarded as a matter of\n+        velocity definition and does not by itself imply any loss of accuracy, provided\n+        sufficient care has been taken during interpretation of the results. If you need\n+        the barycentric correction expressed as the full relativistic velocity (e.g., to provide\n+        it as the input to another software which performs the application), the\n+        following recipe can be used::\n+\n+          >>> zb = vcorr / c  # doctest: +REMOTE_DATA\n+          >>> zb_plus_one_squared = (zb + 1) ** 2  # doctest: +REMOTE_DATA\n+          >>> vcorr_rel = c * (zb_plus_one_squared - 1) / (zb_plus_one_squared + 1)  # doctest: +REMOTE_DATA\n+\n+        or alternatively using just equivalencies::\n+\n+          >>> vcorr_rel = vcorr.to(u.Hz, u.doppler_optical(1*u.Hz)).to(vcorr.unit, u.doppler_relativistic(1*u.Hz))  # doctest: +REMOTE_DATA\n+\n+        See also `~astropy.units.equivalencies.doppler_optical`,\n+        `~astropy.units.equivalencies.doppler_radio`, and\n+        `~astropy.units.equivalencies.doppler_relativistic` for more information on\n+        the velocity conventions.\n+\n+        The default is for this method to use the builtin ephemeris for\n+        computing the sun and earth location.  Other ephemerides can be chosen\n+        by setting the `~astropy.coordinates.solar_system_ephemeris` variable,\n+        either directly or via ``with`` statement.  For example, to use the JPL\n+        ephemeris, do::\n+\n+          >>> from astropy.coordinates import solar_system_ephemeris\n+          >>> sc = SkyCoord(1*u.deg, 2*u.deg)\n+          >>> with solar_system_ephemeris.set('jpl'):  # doctest: +REMOTE_DATA\n+          ...     rv += sc.radial_velocity_correction(obstime=t, location=loc)  # doctest: +SKIP\n+\n+        \"\"\"\n+        # has to be here to prevent circular imports\n+        from .solar_system import get_body_barycentric_posvel\n+\n+        # location validation\n+        timeloc = getattr(obstime, \"location\", None)\n+        if location is None:\n+            if self.location is not None:\n+                location = self.location\n+                if timeloc is not None:\n+                    raise ValueError(\n+                        \"`location` cannot be in both the passed-in `obstime` and this\"\n+                        \" `SkyCoord` because it is ambiguous which is meant for the\"\n+                        \" radial_velocity_correction.\"\n+                    )\n+            elif timeloc is not None:\n+                location = timeloc\n+            else:\n+                raise TypeError(\n+                    \"Must provide a `location` to radial_velocity_correction, either as\"\n+                    \" a SkyCoord frame attribute, as an attribute on the passed in\"\n+                    \" `obstime`, or in the method call.\"\n+                )\n+\n+        elif self.location is not None or timeloc is not None:\n+            raise ValueError(\n+                \"Cannot compute radial velocity correction if `location` argument is\"\n+                \" passed in and there is also a  `location` attribute on this SkyCoord\"\n+                \" or the passed-in `obstime`.\"\n+            )\n+\n+        # obstime validation\n+        coo_at_rv_obstime = self  # assume we need no space motion for now\n+        if obstime is None:\n+            obstime = self.obstime\n+            if obstime is None:\n+                raise TypeError(\n+                    \"Must provide an `obstime` to radial_velocity_correction, either as\"\n+                    \" a SkyCoord frame attribute or in the method call.\"\n+                )\n+        elif self.obstime is not None and self.frame.data.differentials:\n+            # we do need space motion after all\n+            coo_at_rv_obstime = self.apply_space_motion(obstime)\n+        elif self.obstime is None:\n+            # warn the user if the object has differentials set\n+            if \"s\" in self.data.differentials:\n+                warnings.warn(\n+                    \"SkyCoord has space motion, and therefore the specified \"\n+                    \"position of the SkyCoord may not be the same as \"\n+                    \"the `obstime` for the radial velocity measurement. \"\n+                    \"This may affect the rv correction at the order of km/s\"\n+                    \"for very high proper motions sources. If you wish to \"\n+                    \"apply space motion of the SkyCoord to correct for this\"\n+                    \"the `obstime` attribute of the SkyCoord must be set\",\n+                    AstropyUserWarning,\n+                )\n+\n+        pos_earth, v_earth = get_body_barycentric_posvel(\"earth\", obstime)\n+        if kind == \"barycentric\":\n+            v_origin_to_earth = v_earth\n+        elif kind == \"heliocentric\":\n+            v_sun = get_body_barycentric_posvel(\"sun\", obstime)[1]\n+            v_origin_to_earth = v_earth - v_sun\n+        else:\n+            raise ValueError(\n+                \"`kind` argument to radial_velocity_correction must \"\n+                f\"be 'barycentric' or 'heliocentric', but got '{kind}'\"\n+            )\n+\n+        gcrs_p, gcrs_v = location.get_gcrs_posvel(obstime)\n+        # transforming to GCRS is not the correct thing to do here, since we don't want to\n+        # include aberration (or light deflection)? Instead, only apply parallax if necessary\n+        icrs_cart = coo_at_rv_obstime.icrs.cartesian\n+        icrs_cart_novel = icrs_cart.without_differentials()\n+        if self.data.__class__ is UnitSphericalRepresentation:\n+            targcart = icrs_cart_novel\n+        else:\n+            # skycoord has distances so apply parallax\n+            obs_icrs_cart = pos_earth + gcrs_p\n+            targcart = icrs_cart_novel - obs_icrs_cart\n+            targcart /= targcart.norm()\n+\n+        if kind == \"barycentric\":\n+            beta_obs = (v_origin_to_earth + gcrs_v) / speed_of_light\n+            gamma_obs = 1 / np.sqrt(1 - beta_obs.norm() ** 2)\n+            gr = location.gravitational_redshift(obstime)\n+            # barycentric redshift according to eq 28 in Wright & Eastmann (2014),\n+            # neglecting Shapiro delay and effects of the star's own motion\n+            zb = gamma_obs * (1 + beta_obs.dot(targcart)) / (1 + gr / speed_of_light)\n+            # try and get terms corresponding to stellar motion.\n+            if icrs_cart.differentials:\n+                try:\n+                    ro = self.icrs.cartesian\n+                    beta_star = ro.differentials[\"s\"].to_cartesian() / speed_of_light\n+                    # ICRS unit vector at coordinate epoch\n+                    ro = ro.without_differentials()\n+                    ro /= ro.norm()\n+                    zb *= (1 + beta_star.dot(ro)) / (1 + beta_star.dot(targcart))\n+                except u.UnitConversionError:\n+                    warnings.warn(\n+                        \"SkyCoord contains some velocity information, but not enough to\"\n+                        \" calculate the full space motion of the source, and so this\"\n+                        \" has been ignored for the purposes of calculating the radial\"\n+                        \" velocity correction. This can lead to errors on the order of\"\n+                        \" metres/second.\",\n+                        AstropyUserWarning,\n+                    )\n+\n+            zb = zb - 1\n+            return zb * speed_of_light\n+        else:\n+            # do a simpler correction ignoring time dilation and gravitational redshift\n+            # this is adequate since Heliocentric corrections shouldn't be used if\n+            # cm/s precision is required.\n+            return targcart.dot(v_origin_to_earth + gcrs_v)\n+\n+    # Table interactions\n+    @classmethod\n+    def guess_from_table(cls, table, **coord_kwargs):\n+        r\"\"\"\n+        A convenience method to create and return a new `SkyCoord` from the data\n+        in an astropy Table.\n+\n+        This method matches table columns that start with the case-insensitive\n+        names of the the components of the requested frames (including\n+        differentials), if they are also followed by a non-alphanumeric\n+        character. It will also match columns that *end* with the component name\n+        if a non-alphanumeric character is *before* it.\n+\n+        For example, the first rule means columns with names like\n+        ``'RA[J2000]'`` or ``'ra'`` will be interpreted as ``ra`` attributes for\n+        `~astropy.coordinates.ICRS` frames, but ``'RAJ2000'`` or ``'radius'``\n+        are *not*. Similarly, the second rule applied to the\n+        `~astropy.coordinates.Galactic` frame means that a column named\n+        ``'gal_l'`` will be used as the the ``l`` component, but ``gall`` or\n+        ``'fill'`` will not.\n+\n+        The definition of alphanumeric here is based on Unicode's definition\n+        of alphanumeric, except without ``_`` (which is normally considered\n+        alphanumeric).  So for ASCII, this means the non-alphanumeric characters\n+        are ``<space>_!\"#$%&'()*+,-./\\:;<=>?@[]^`{|}~``).\n+\n+        Parameters\n+        ----------\n+        table : `~astropy.table.Table` or subclass\n+            The table to load data from.\n+        **coord_kwargs\n+            Any additional keyword arguments are passed directly to this class's\n+            constructor.\n+\n+        Returns\n+        -------\n+        newsc : `~astropy.coordinates.SkyCoord` or subclass\n+            The new `SkyCoord` (or subclass) object.\n+\n+        Raises\n+        ------\n+        ValueError\n+            If more than one match is found in the table for a component,\n+            unless the additional matches are also valid frame component names.\n+            If a \"coord_kwargs\" is provided for a value also found in the table.\n+\n+        \"\"\"\n+        _frame_cls, _frame_kwargs = _get_frame_without_data([], coord_kwargs)\n+        frame = _frame_cls(**_frame_kwargs)\n+        coord_kwargs[\"frame\"] = coord_kwargs.get(\"frame\", frame)\n+\n+        representation_component_names = set(\n+            frame.get_representation_component_names()\n+        ).union(set(frame.get_representation_component_names(\"s\")))\n+\n+        comp_kwargs = {}\n+        for comp_name in representation_component_names:\n+            # this matches things like 'ra[...]'' but *not* 'rad'.\n+            # note that the \"_\" must be in there explicitly, because\n+            # \"alphanumeric\" usually includes underscores.\n+            starts_with_comp = comp_name + r\"(\\W|\\b|_)\"\n+            # this part matches stuff like 'center_ra', but *not*\n+            # 'aura'\n+            ends_with_comp = r\".*(\\W|\\b|_)\" + comp_name + r\"\\b\"\n+            # the final regex ORs together the two patterns\n+            rex = re.compile(\n+                rf\"({starts_with_comp})|({ends_with_comp})\", re.IGNORECASE | re.UNICODE\n+            )\n+\n+            # find all matches\n+            matches = {col_name for col_name in table.colnames if rex.match(col_name)}\n+\n+            # now need to select among matches, also making sure we don't have\n+            # an exact match with another component\n+            if len(matches) == 0:  # no matches\n+                continue\n+            elif len(matches) == 1:  # only one match\n+                col_name = matches.pop()\n+            else:  # more than 1 match\n+                # try to sieve out other components\n+                matches -= representation_component_names - {comp_name}\n+                # if there's only one remaining match, it worked.\n+                if len(matches) == 1:\n+                    col_name = matches.pop()\n+                else:\n+                    raise ValueError(\n+                        f'Found at least two matches for component \"{comp_name}\":'\n+                        f' \"{matches}\". Cannot guess coordinates from a table with this'\n+                        \" ambiguity.\"\n+                    )\n+\n+            comp_kwargs[comp_name] = table[col_name]\n+\n+        for k, v in comp_kwargs.items():\n+            if k in coord_kwargs:\n+                raise ValueError(\n+                    f'Found column \"{v.name}\" in table, but it was already provided as'\n+                    ' \"{k}\" keyword to guess_from_table function.'\n+                )\n+            else:\n+                coord_kwargs[k] = v\n+\n+        return cls(**coord_kwargs)\n+\n+    # Name resolve\n+    @classmethod\n+    def from_name(cls, name, frame=\"icrs\", parse=False, cache=True):\n+        \"\"\"\n+        Given a name, query the CDS name resolver to attempt to retrieve\n+        coordinate information for that object. The search database, sesame\n+        url, and  query timeout can be set through configuration items in\n+        ``astropy.coordinates.name_resolve`` -- see docstring for\n+        `~astropy.coordinates.get_icrs_coordinates` for more\n+        information.\n+\n+        Parameters\n+        ----------\n+        name : str\n+            The name of the object to get coordinates for, e.g. ``'M42'``.\n+        frame : str or `BaseCoordinateFrame` class or instance\n+            The frame to transform the object to.\n+        parse : bool\n+            Whether to attempt extracting the coordinates from the name by\n+            parsing with a regex. For objects catalog names that have\n+            J-coordinates embedded in their names, e.g.,\n+            'CRTS SSS100805 J194428-420209', this may be much faster than a\n+            Sesame query for the same object name. The coordinates extracted\n+            in this way may differ from the database coordinates by a few\n+            deci-arcseconds, so only use this option if you do not need\n+            sub-arcsecond accuracy for coordinates.\n+        cache : bool, optional\n+            Determines whether to cache the results or not. To update or\n+            overwrite an existing value, pass ``cache='update'``.\n+\n+        Returns\n+        -------\n+        coord : SkyCoord\n+            Instance of the SkyCoord class.\n+        \"\"\"\n+\n+        from .name_resolve import get_icrs_coordinates\n+\n+        icrs_coord = get_icrs_coordinates(name, parse, cache=cache)\n+        icrs_sky_coord = cls(icrs_coord)\n+        if frame in (\"icrs\", icrs_coord.__class__):\n+            return icrs_sky_coord\n+        else:\n+            return icrs_sky_coord.transform_to(frame)\ndiff --git a/test_sky_coord.py b/test_sky_coord.py\nnew file mode 100644\nindex 000000000..860908ec8\n--- /dev/null\n+++ b/test_sky_coord.py\n@@ -0,0 +1,13 @@\n+import astropy.coordinates as coord\n+\n+class custom_coord(coord.SkyCoord):\n+    @property\n+    def prop(self):\n+        try:\n+    raise AttributeError(f'custom_coord object has no attribute random_attr')\n+except AttributeError:\n+    raise AttributeError(f'custom_coord object has no attribute random_attr')\n+except AttributeError: raise AttributeError(f'custom_coord object has no attribute random_attr')\n+\n+c = custom_coord('00h42m30s', '+41d12m00s', frame='icrs')\n+print(c.prop)\n"}
{"model_name_or_path": "llama", "instance_id": "astropy__astropy-14182", "model_patch": "diff --git a/astropy/io/ascii/rst.py b/astropy/io/ascii/rst.py\nindex abdeba8ef..2414cb9ff 100644\n--- a/astropy/io/ascii/rst.py\n+++ b/astropy/io/ascii/rst.py\n@@ -57,10 +57,13 @@ class RST(FixedWidth):\n     data_class = SimpleRSTData\n     header_class = SimpleRSTHeader\n \n-    def __init__(self):\n+    def __init__(self, header_rows=None):\n+        self.header_rows = header_rows\n         super().__init__(delimiter_pad=None, bookend=False)\n \n     def write(self, lines):\n+        if self.header_rows:\n+            lines = [self.header_rows] + super().write(tbl)\n         lines = super().write(lines)\n         lines = [lines[1]] + lines + [lines[1]]\n         return lines\ndiff --git a/test_rst_writer.py b/test_rst_writer.py\nnew file mode 100644\nindex 000000000..7c401e5d0\n--- /dev/null\n+++ b/test_rst_writer.py\n@@ -0,0 +1,6 @@\n+from astropy.io.ascii import RST\n+from astropy.table import QTable\n+\n+tbl = QTable({'wave': [350,950], 'response': [0.7, 1.2]})\n+rst_writer = RST(header_rows=[\"name\", \"unit\"])\n+rst_writer.write(tbl)\n"}
{"model_name_or_path": "llama", "instance_id": "astropy__astropy-14309", "model_patch": ""}
